{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoy Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">\n",
    "To be decided:<br>\n",
    "\n",
    "### Prompts:\n",
    "\n",
    "- Use contextual prompting to query both scenarios after another?<br>\n",
    "    - Sticks to original study, but Decoy Effect is not applied like that in the real world.<br>\n",
    "    <br>\n",
    "- If not: Even mention removal of decoy in the second prompt? -> mimics original study design & shows if answers tend to approximate uniform distribution\n",
    "    - Is this already a sort of priming? <br>\n",
    "<br>\n",
    "------------------\n",
    "- Maybe set n globally and not in each run_decoy call<br>\n",
    "<br>\n",
    "- Huge deviations in runtime of cells: 50x5 function calls for GPT-3.5-Turbo can take ~5 min up to ~120 min (24.11.2023)<br>\n",
    "<br>\n",
    "- Rewrite decoy function to also count X, Q, Y? Or stick to two functions to avoid miscount. \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to recreate some findings concerning the **Decoy Effect**. Specifically, we recreate the event described in https://thestrategystory.com/2020/10/02/economist-magazine-a-story-of-clever-decoy-pricing/ with numbers taken from https://en.wikipedia.org/wiki/Decoy_effect.\n",
    "\n",
    "As of right now (25.11.2023), querying each prompt 50 times for 5 temperature values over 8 prompts and the two openai 2 models, we issue **4000 API calls**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer options for this experiment are literal copies of the original study. Only the words \"priced at __$\" were added to each option. Furthermore, their wording remains the same\n",
    "through the entire experiment, being: \n",
    "-  A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "-  B: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "-  C: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "\n",
    "\n",
    "#### From Ariely's Book \"Predictably irrational\":\n",
    "\n",
    "\"When I gave these options to 100 students at MIT's Sloan\n",
    "School of Management, they opted as follows:\n",
    "1. Internet-only subscription for $59—16 students\n",
    "2. Print-only subscription for $125—zero students\n",
    "3. Print-and-Internet subscription for $ 125—84 students\"\n",
    "\n",
    "(page 5)\n",
    "\n",
    "\"And the absence of the decoy\n",
    "had them choosing differently, with 32 for print-and-Internet\n",
    "and 68 for Internet-only\"\n",
    "\n",
    "(page 6)\n",
    "\n",
    "|Answer option          | Scenario 1 | Scenario 2 (no 2nd option)|\n",
    "|-----------------------|--------------|-----------|\n",
    "| Online subscription   |     16%      |  68%       |\n",
    "| Print subscribtion    |      0%     | 0%        |\n",
    "| Combination           |     84%   | 32%        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the prompts used for the experiment\n",
    "\n",
    "We now formulate 8 different prompts: \n",
    "\n",
    "First of all, we present the model with the original situation i.e. 3 answer options. To recreate the second scenario of the study, we tell the model that the second (decoy) option has now been removed. \n",
    "Furthermore we **prime** the model play the role of a marker researcher, who knows about the decoy effect, and query the model with both study situationbs again.\n",
    "\n",
    "Afterwards, in order to research possible biases induced by either the answer letters themselves (A, B, C) or the order of the answers, we correct for this and prompt the model 4 times again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "        A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "        B: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "        C: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "        Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "        Answer: I would choose option \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "        A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "        B: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$. \n",
    "        Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "        Answer: I would choose option \"\"\"\n",
    "\n",
    "# Removed original option B and made option C the new option B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "        You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "        A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "        B: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "        C: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "        Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "        Answer: I would choose option \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "         B: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "         Answer: I would choose option \"\"\"\n",
    "\n",
    "# Removed original option B and made option C the new option B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming and reordering answer options\n",
    "\n",
    "Following the approach of Mendler-Dünner et al. (2023), we do not only reorder the answers but also label them with letters, that are less common in the English language.\n",
    "- A (online) -> Y\n",
    "- B (print) -> Q\n",
    "- C (combination) -> X\n",
    "\n",
    "Afterwards option 1 is put last. Sticking to our original question design, the order would now be: B, C, A.\n",
    "- N (print)\n",
    "- T (combination)\n",
    "- W (online)\n",
    "\n",
    "**-> Use decoy_function2() for these prompts!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         Q: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "         Answer: I would choose option \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_6 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "         Answer: I would choose option \"\"\"\n",
    "\n",
    "# Removed option Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_7 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         Q: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "         Answer: I would choose option \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temoprarily adjusted answer optionds to QXY \n",
    "prompt_8 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\n",
    "         Answer: I would choose option \"\"\"\n",
    "\n",
    "# Removed option Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Helpful dictionaries \n",
    "\n",
    "The experiments we will run in this notebook are very similar in study design, and for same cases, also similar in the results we expect. We therefore need to make sure, that we associate the results with the correct study design. That is why the following dictionaries are implemented to look up e.g. what model was used for an experiment.\n",
    "\n",
    "They will also be used inside the functions that call the API multiple times and output some information about the experiment in order to identify it correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that returns the literal prompt for a given experiment id (used in function call). key: experiment_id, value: prompt\n",
    "experiment_prompts_dict = {\n",
    "    \"1_1\": prompt_1,\n",
    "    \"1_2\": prompt_2,\n",
    "    \"1_3\": prompt_3,\n",
    "    \"1_4\": prompt_4,\n",
    "    \"1_5\": prompt_5,\n",
    "    \"1_6\": prompt_6,\n",
    "    \"1_7\": prompt_7,\n",
    "    \"1_8\": prompt_8,\n",
    "    \"2_1\": prompt_1,\n",
    "    \"2_2\": prompt_2,\n",
    "    \"2_3\": prompt_3,\n",
    "    \"2_4\": prompt_4,\n",
    "    \"2_5\": prompt_5,\n",
    "    \"2_6\": prompt_6,\n",
    "    \"2_7\": prompt_7,\n",
    "    \"2_8\": prompt_8,\n",
    "}\n",
    "\n",
    "# The following dictionary is only used for a check in the function calls.\n",
    "# It returns the variable name of the prompt that was used in the experiment. key: experiment_id, value: prompt_name\n",
    "prompt_ids_dict = {\n",
    "    \"1_1\": \"prompt_1\",\n",
    "    \"1_2\": \"prompt_2\",\n",
    "    \"1_3\": \"prompt_3\",\n",
    "    \"1_4\": \"prompt_4\",\n",
    "    \"1_5\": \"prompt_5\",\n",
    "    \"1_6\": \"prompt_6\",\n",
    "    \"1_7\": \"prompt_7\",\n",
    "    \"1_8\": \"prompt_8\",\n",
    "    \"2_1\": \"prompt_1\",\n",
    "    \"2_2\": \"prompt_2\",\n",
    "    \"2_3\": \"prompt_3\",\n",
    "    \"2_4\": \"prompt_4\",\n",
    "    \"2_5\": \"prompt_5\",\n",
    "    \"2_6\": \"prompt_6\",\n",
    "    \"2_7\": \"prompt_7\",\n",
    "    \"2_8\": \"prompt_8\",\n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary to look up which model to use for a given experiment id (used in function call). key: experiment id, value: model name\n",
    "model_dict = {\n",
    "    \"1_1\": \"gpt-3.5-turbo\",\n",
    "    \"1_2\": \"gpt-3.5-turbo\",\n",
    "    \"1_3\": \"gpt-3.5-turbo\",\n",
    "    \"1_4\": \"gpt-3.5-turbo\",\n",
    "    \"1_5\": \"gpt-3.5-turbo\",\n",
    "    \"1_6\": \"gpt-3.5-turbo\",\n",
    "    \"1_7\": \"gpt-3.5-turbo\",\n",
    "    \"1_8\": \"gpt-3.5-turbo\",\n",
    "    \"2_1\": \"gpt-4-1106-preview\",\n",
    "    \"2_2\": \"gpt-4-1106-preview\",\n",
    "    \"2_3\": \"gpt-4-1106-preview\",\n",
    "    \"2_4\": \"gpt-4-1106-preview\",\n",
    "    \"2_5\": \"gpt-4-1106-preview\",\n",
    "    \"2_6\": \"gpt-4-1106-preview\",\n",
    "    \"2_7\": \"gpt-4-1106-preview\",\n",
    "    \"2_8\": \"gpt-4-1106-preview\",\n",
    "    }\n",
    "\n",
    "\n",
    "# Dictionary to look up, what the study design of each experiment was. key: experiment id, value: experiment design \n",
    "experiment_dict = {\n",
    "    \"1_1\": f\"Experiment 1_1 contains all answer options, is unprimed and uses {model_dict['1_1']}.\",\n",
    "    \"1_2\": f\"Experiment 1_2 has the decoy removed, is unprimed and uses {model_dict['1_2']}.\",\n",
    "    \"1_3\": f\"Experiment 1_3 contains all answer options, is primed and uses {model_dict['1_3']}.\",\n",
    "    \"1_4\": f\"Experiment 1_4 has the decoy removed, is primed and uses {model_dict['1_4']}.\",\n",
    "    \"1_5\": f\"Experiment 1_5 contains all answer options renamed and reordered, is unprimed and uses {model_dict['1_5']}.\",\n",
    "    \"1_6\": f\"Experiment 1_6 has the decoy removed, answer options renamed and reordered, is unprimed and uses {model_dict['1_6']}.\",\n",
    "    \"1_7\": f\"Experiment 1_7 contains all answer options renamed and reordered, is primed and uses {model_dict['1_7']}.\",\n",
    "    \"1_8\": f\"Experiment 1_8 has the decoy removed, answer options renamed and reordered, is primed and uses {model_dict['1_8']}.\",\n",
    "    \"2_1\": f\"Experiment 2_1 contains all answer options, is unprimed and uses {model_dict['2_1']}.\",\n",
    "    \"2_2\": f\"Experiment 2_2 has the decoy removed, is unprimed and uses {model_dict['2_2']}.\",\n",
    "    \"2_3\": f\"Experiment 2_3 contains all answer options, is primed and uses {model_dict['2_3']}.\",\n",
    "    \"2_4\": f\"Experiment 2_4 has the decoy removed, is primed and uses {model_dict['2_4']}.\",\n",
    "    \"2_5\": f\"Experiment 2_5 contains all answer options renamed and reordered, is unprimed and uses {model_dict['2_5']}.\",\n",
    "    \"2_6\": f\"Experiment 2_6 has the decoy removed, answer options renamed and reordered, is unprimed and uses {model_dict['2_6']}.\",\n",
    "    \"2_7\": f\"Experiment 2_7 contains all answer options renamed and reordered, is primed and uses {model_dict['2_7']}.\",\n",
    "    \"2_8\": f\"Experiment 2_8 has the decoy removed, answer options renamed and reordered, is primed and uses {model_dict['2_8']}.\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up the original results of the experiments. key: experiment id, value: original result\n",
    "results_dict = {\n",
    "    \"1_1\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"1_2\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"1_3\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"1_4\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"1_5\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"1_6\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"1_7\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"1_8\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"2_1\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"2_2\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"2_3\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"2_4\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"2_5\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"2_6\": \"A: 68%, B: 0%, C: 32%\",\n",
    "    \"2_7\": \"A: 16%, B: 0%, C: 84%\",\n",
    "    \"2_8\": \"A: 68%, B: 0%, C: 32%\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-wise function\n",
    "\n",
    "The following functions are implemented test-wise with the goal of discarding the decoy_function2 and keeping the workflow more general. Depending on what the experiment id is, answers will be counted according to the survey design. \n",
    "\n",
    "In some prompts, answer options are removed while in others, they are renamed. Using the count_answers() function, we make the results more easily comparable, since p(A), p(B) and p(C) will always reflect the probabilty of the underlying answer text being chosen, not the letter of the answer option itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_answers(answers: list, experiment_id: str):\n",
    "    if experiment_id in [\"1_1\", \"1_3\",\"2_1\", \"2_3\"]:\n",
    "        A = answers.count(\"A\")\n",
    "        B = answers.count(\"B\")\n",
    "        C = answers.count(\"C\")\n",
    "    elif experiment_id in [\"1_2\", \"1_4\", \"2_2\", \"2_4\"]:\n",
    "        A = answers.count(\"A\")\n",
    "        B = 0 # Option B was removed\n",
    "        C = answers.count(\"B\") # makes comparison of results over prompts easier \n",
    "    elif experiment_id in [\"1_5\", \"1_7\", \"2_5\", \"2_7\"]:\n",
    "        A = answers.count(\"Y\")\n",
    "        B = answers.count(\"Q\")\n",
    "        C = answers.count(\"X\")\n",
    "    elif experiment_id in [\"1_6\", \"1_8\", \"2_6\", \"2_8\"]:\n",
    "        A = answers.count(\"Y\")\n",
    "        B = 0 # Option Q was removed\n",
    "        C = answers.count(\"X\")\n",
    "    return A, B, C\n",
    "\n",
    "def correct_answers(answers: list, experiment_id: str):\n",
    "    if experiment_id in [\"1_1\", \"1_3\",\"2_1\", \"2_3\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\", \"C\"])\n",
    "    elif experiment_id in [\"1_2\", \"1_4\", \"2_2\", \"2_4\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\"])\n",
    "    elif experiment_id in [\"1_5\", \"1_7\", \"2_5\", \"2_7\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"Y\", \"Q\", \"X\"])\n",
    "    elif experiment_id in [\"1_6\", \"1_8\", \"2_6\", \"2_8\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"Y\", \"X\"])\n",
    "    return len_correct  # to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_id, n, temperature = 1, max_tokens = 1):\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT multiple times with a survey having answers designed as: A, B, C.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        n (int): Number of queries to be made\n",
    "        temperature (int): Degree of randomness with range 0 (deterministic) to 2 (random)\n",
    "        max_tokens (int): Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results (list): List containing count of answers for each option, also containing experiment_id, temperature and number of observations\n",
    "        probs (list): List containing probability of each option being chosen, also containing experiment_id, temeperature and number of observations\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = model_dict[experiment_id], \n",
    "            max_tokens = max_tokens,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"user\", \"content\": experiment_prompts_dict[experiment_id]},\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "    # Count the answers\n",
    "    A, B, C = count_answers(answers, experiment_id) # if/else statement of function deals with different answer options in different experiments\n",
    "    \n",
    "    # Count of correct answers\n",
    "    len_correct = int(correct_answers(answers, experiment_id)) # if/else of function makes sure that we count the correct answers according to the experiment id \n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = [experiment_id, temperature, A, B, C, len_correct]\n",
    "\n",
    "    # Calculate probabilities\n",
    "    p_a = f\"{(A / (len_correct + 0.000000001)) * 100:.2f}%\"\n",
    "    p_b = f\"{(B / (len_correct + 0.000000001)) * 100:.2f}%\"\n",
    "    p_c = f\"{(C / (len_correct + 0.000000001)) * 100:.2f}%\"\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = [experiment_id, temperature, p_a, p_b, p_c, len_correct]\n",
    "    # Print progress\n",
    "    print(f\"Experiment {experiment_id} with {n} observations, using {prompt_ids_dict[experiment_id]} and temperature {temperature} completed.\")\n",
    "\n",
    "    return results, probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_loop(experiment_id: str, temperature_list: list = [0, 0.5, 1, 1.5, 2], n: int = 50, max_tokens: int = 1):\n",
    "    \"\"\"\n",
    "    Function to run an experiment over different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty lists for storing results\n",
    "    results_list = []\n",
    "    probs_list = []\n",
    "    \n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results, probs = run_experiment(experiment_id = experiment_id, n = n, temperature = temperature, max_tokens = max_tokens) \n",
    "        results_list.append(results)\n",
    "        probs_list.append(probs)\n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index([\"Experiment\", \"Temp\", \"p(A)\", \"p(B)\", \"p(C)\", \"Obs.\"]))\n",
    "    probs_df = pd.DataFrame(probs_list).transpose().set_index(pd.Index([\"Experiment\", \"Temp\", \"p(A)\", \"p(B)\", \"p(C)\", \"Obs.\"]))\n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"{experiment_dict[experiment_id]} In this run, a total of {n*len(temperature_list)} requests were made using {prompt_ids_dict[experiment_id]}.\"\n",
    "    # Print information about the experiment\n",
    "    print(check)\n",
    "    # Print original results \n",
    "    print(f\"The original results were {results_dict[experiment_id]}.\")\n",
    "\n",
    "    \n",
    "    return results_df, probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1_4 with 5 observations, using prompt_4 and temperature 0 completed.\n",
      "Experiment 1_4 with 5 observations, using prompt_4 and temperature 0.5 completed.\n",
      "Experiment 1_4 with 5 observations, using prompt_4 and temperature 1 completed.\n",
      "Experiment 1_4 with 5 observations, using prompt_4 and temperature 1.5 completed.\n",
      "Experiment 1_4 with 5 observations, using prompt_4 and temperature 2 completed.\n",
      "Experiment 1_4 has the decoy removed, is primed and uses gpt-3.5-turbo. In this run, a total of 25 requests were made using prompt_4.\n",
      "The original results were A: 68%, B: 0%, C: 32%.\n"
     ]
    }
   ],
   "source": [
    "test_results, test_probs = temperature_loop(experiment_id = \"1_4\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 5, max_tokens = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1_4 with 5 observations, using prompt_4 and temperature 1.0 completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1_4', 1.0, '0.00%', '0.00%', '100.00%', 5]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results, test_probs = run_experiment(experiment_id = \"1_4\", n = 5, temperature = 1.0, max_tokens = 1)\n",
    "test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a market researcher that knows about the Decoy Effect in pricing. \\n         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\\n         A: For 59$: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997.\\n         B: For 125$: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997.\\n         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\\n         Answer: I would choose option '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_prompts_dict[\"1_4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up functions to repeatedly prompt ChatGPT\n",
    "\n",
    "- Functions to query 1 prompt n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoy_function(experiment_id, n, temperature = 1, max_tokens = 1):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT multiple times with a survey having answers designed as: A, B, C.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        n (int): Number of queries to be made\n",
    "        temperature (int): Degree of randomness with range 0 (deterministic) to 2 (random)\n",
    "        max_tokens (int): Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results (list): List containing count of answers for each option, also containing experiment_id, temperature and number of observations\n",
    "        probs (list): List containing probability of each option being chosen, also containing experiment_id, temeperature and number of observations\n",
    "    \"\"\"\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = model_dict[experiment_id], \n",
    "            max_tokens = max_tokens,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"user\", \"content\": experiment_prompts_dict[experiment_id]},\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "\n",
    "    # Counting results\n",
    "    A = answers.count(\"A\")\n",
    "    B = answers.count(\"B\")\n",
    "    C = answers.count(\"C\")\n",
    "\n",
    "    # Count of \"correct\" answers, sums over indicator function thack checks if answer is either A, B or C\n",
    "    len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\", \"C\"])\n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = [experiment_id, temperature, A, B, C, len_correct]\n",
    "\n",
    "    # Getting percentage each answer\n",
    "    p_a = f\"{(A / (len_correct + 0.000000001)) * 100:.2f}%\"\n",
    "    p_b = f\"{(B / (len_correct + 0.000000001)) * 100:.2f}%\"\n",
    "    p_c = f\"{(C / (len_correct + 0.000000001)) * 100:.2f}%\"\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = [experiment_id, temperature, p_a, p_b, p_c, len_correct]\n",
    "    \n",
    "    # Give out results\n",
    "    return answers, results, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is almost identical to the original one, but deals with answer options that are renamed as A = Y, B = Q, C = X.\n",
    "# We apply this \"conversion\" so that the results are comparable to the ones obtained with the original function.\n",
    "# Prompts 5-8 are used for this function.\n",
    "def decoy_function2(experiment_id, n, temperature = 1, max_tokens = 1):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT multiple times with a survey having answers designed as: Y, Q, X.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        n (int): Number of queries to be made\n",
    "        temperature (int): Degree of randomness with range 0 (deterministic) to 2 (random)\n",
    "        max_tokens (int): Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results (list): List containing count of answers for each option, also containing experiment_id, temperature and number of observations\n",
    "        probs (list): List containing probability of each option being chosen, also containing experiment_id, temeperature and number of observations\n",
    "    \"\"\"\n",
    "\n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = model_dict[experiment_id], \n",
    "            max_tokens = max_tokens,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"user\", \"content\": experiment_prompts_dict[experiment_id]},\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "    \n",
    "    # Counting results\n",
    "    A = answers.count(\"Y\") ######################################### CHANGED\n",
    "    B = answers.count(\"Q\")\n",
    "    C = answers.count(\"X\")\n",
    "\n",
    "    # Count of \"correct\" answers, sums over indicator function thack checks if answer is either W, N, or T\n",
    "    len_correct = sum(1 for ans in answers if ans in [\"Y\", \"Q\", \"X\"])############################################# CHANGED\n",
    "    \n",
    "    # Collecting results in a list\n",
    "    results = [experiment_id, temperature, A, B, C, len_correct]\n",
    "\n",
    "    # Getting percentage each answer\n",
    "    p_w = f\"{(A / len_correct) * 100:.2f}%\"\n",
    "    p_b = f\"{(B / len_correct) * 100:.2f}%\"\n",
    "    p_c = f\"{(C / len_correct) * 100:.2f}%\"\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = [experiment_id, temperature, p_w, p_b, p_c, len_correct] \n",
    "\n",
    "    # Give out results\n",
    "    return answers, results, probs ############################################# CHANGED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop over temperature values, querying each prompt n times for every temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop decoy function over temperature values\n",
    "def run_decoy(function, experiment_id, temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1):\n",
    "    \"\"\"\n",
    "    Function to run an experiment with different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty lists for storing results\n",
    "    results_list = []\n",
    "    probs_list = []\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        answers, results, probs = function(experiment_id = experiment_id, n = n, temperature = temperature, max_tokens = max_tokens) ############################################# CHANGED\n",
    "        results_list.append(results)\n",
    "        probs_list.append(probs)\n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index([\"Experiment\", \"Temp\", \"p(A)\", \"p(B)\", \"p(C)\", \"Obs.\"]))\n",
    "    probs_df = pd.DataFrame(probs_list).transpose().set_index(pd.Index([\"Experiment\", \"Temp\", \"p(A)\", \"p(B)\", \"p(C)\", \"Obs.\"]))\n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"In this experiment, {n} requests were made per temperature value using model {model_dict[experiment_id]} and {prompt_ids_dict[experiment_id]}.\"\n",
    "    print(check)\n",
    "    \n",
    "    return results_df, probs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For high values of temperature we (rarely) still get \"incorrect\" answers i.e. not in the form of \"A\", \"B\", or \"C\".\n",
    "Using the following approach, the computed percentages will now only reflect the distribution of answers among the \"correctly\" answered questions and add up to 100%:\n",
    "\n",
    "\n",
    "- len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\", \"C\"]) # instead of len(answers)\n",
    "\n",
    "\n",
    "From my experience with this notebook, among 50 repeated requests for a given prompt, setting the temperature value to max (2) only 1 or 2 answers were not A, B, or C.\n",
    "Therefore we can safely assume that the distribution of answers among the \"correctly\" answered questions is not affected by the presence of these outliers and this approach is valid.\n",
    "Furthermore, for each experiment, we can still see the answer count in the results dataframe as a check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to plot distribution of answer probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df):\n",
    "    \n",
    "    # Get experiment id and model name for plot title from dictionaries\n",
    "    experiment_id = df.iloc[0, 0]\n",
    "    model = model_dict[experiment_id]\n",
    "    \n",
    "    X = df.loc[\"Temp\"]\n",
    "    p_a = df.loc[\"p(A)\"].str.rstrip('%').astype('float')  # Convert percentages to float\n",
    "    p_b = df.loc[\"p(B)\"].str.rstrip('%').astype('float')\n",
    "    p_c = df.loc[\"p(C)\"].str.rstrip('%').astype('float')\n",
    "\n",
    "    X_axis = np.arange(len(X)) \n",
    "\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.bar(X_axis- 0.25, p_a, 0.25, label = 'p(A)', color = \"#8C1515\") \n",
    "    ax.bar(X_axis, p_b, 0.25,  label = 'p(B)', color = \"#507FAB\") \n",
    "    ax.bar(X_axis+ 0.25 , p_c,  0.25, label = 'p(C)', color = '#D9A84A')\n",
    "\n",
    "    ax.set_xticks(X_axis, X)\n",
    "    ax.set_xlabel(\"Temperature\")\n",
    "    ax.set_ylabel(\"Probability (%)\")\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.set_title(f\"Distribution of answers per temperature value for experiment {experiment_id} using {model}\")\n",
    "    ax.legend()  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different LLMs\n",
    "\n",
    "The results variables will be structured as: results_model-id_prompt-id.\n",
    "\n",
    "We will refer to \"GPT-3.5-turbo\" as model 1 and \"GPT-4-1106-preview\" as model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: GPT-3.5-Turbo (Model training ended in September 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple test of repeated prompting function for fixed temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_2', 1, '0.00%', '0.00%', '100.00%', 5]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_5, probs_5 = decoy_function(experiment_id = \"2_2\", n = 5, temperature = 1, max_tokens = 1)\n",
    "probs_5\n",
    "\n",
    "# experiment_id, temp, p_a, p_b, p_c (in original survey), n_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple test of function to loop over temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1_1 contains all answer options, is unprimed and uses gpt-3.5-turbo.\n",
      "In this experiment, 3 requests were made per temperature value using model gpt-3.5-turbo and prompt_1.\n",
      "                  0        1        2       3       4\n",
      "Experiment      1_1      1_1      1_1     1_1     1_1\n",
      "Temp            0.0      0.5      1.0     1.5     2.0\n",
      "p(A)          0.00%    0.00%    0.00%   0.00%  50.00%\n",
      "p(B)          0.00%    0.00%    0.00%  33.33%  50.00%\n",
      "p(C)        100.00%  100.00%  100.00%  66.67%   0.00%\n",
      "Obs.              3        3        3       3       2\n"
     ]
    }
   ],
   "source": [
    "# Print study design to get an overview\n",
    "print(experiment_dict[\"1_1\"])\n",
    "\n",
    "# Call the function \n",
    "results, probs = run_decoy(decoy_function, experiment_id = \"1_1\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 3, max_tokens = 1)\n",
    "\n",
    "# Display probability dataframe\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.00%</td>\n",
       "      <td>6.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.00%</td>\n",
       "      <td>8.00%</td>\n",
       "      <td>14.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>94.00%</td>\n",
       "      <td>86.00%</td>\n",
       "      <td>79.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1       2       3       4\n",
       "Experiment      1_1      1_1     1_1     1_1     1_1\n",
       "Temp            0.0      0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%    0.00%   0.00%   6.00%   6.12%\n",
       "p(B)          0.00%    0.00%   6.00%   8.00%  14.29%\n",
       "p(C)        100.00%  100.00%  94.00%  86.00%  79.59%\n",
       "Obs.             50       50      50      50      49"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call function\n",
    "results_1_1, probs_1_1 = run_decoy(decoy_function, experiment_id = \"1_1\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "# Display results\n",
    "probs_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_2</td>\n",
       "      <td>1_2</td>\n",
       "      <td>1_2</td>\n",
       "      <td>1_2</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.00%</td>\n",
       "      <td>18.00%</td>\n",
       "      <td>30.00%</td>\n",
       "      <td>46.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>96.00%</td>\n",
       "      <td>82.00%</td>\n",
       "      <td>70.00%</td>\n",
       "      <td>51.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4\n",
       "Experiment      1_2     1_2     1_2     1_2     1_2\n",
       "Temp            0.0     0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%   4.00%  18.00%  30.00%  46.81%\n",
       "p(B)          0.00%   0.00%   0.00%   0.00%   2.13%\n",
       "p(C)        100.00%  96.00%  82.00%  70.00%  51.06%\n",
       "Obs.             50      50      50      50      47"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_2, probs_1_2 = run_decoy(decoy_function, experiment_id = \"1_2\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.00%</td>\n",
       "      <td>2.04%</td>\n",
       "      <td>22.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>16.00%</td>\n",
       "      <td>12.24%</td>\n",
       "      <td>22.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>98.00%</td>\n",
       "      <td>78.00%</td>\n",
       "      <td>85.71%</td>\n",
       "      <td>54.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4\n",
       "Experiment      1_3     1_3     1_3     1_3     1_3\n",
       "Temp            0.0     0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%   0.00%   6.00%   2.04%  22.92%\n",
       "p(B)          0.00%   2.00%  16.00%  12.24%  22.92%\n",
       "p(C)        100.00%  98.00%  78.00%  85.71%  54.17%\n",
       "Obs.             50      50      50      49      48"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_3, probs_1_3 = run_decoy(decoy_function, experiment_id = \"1_3\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'C', 'C', 'B', 'C', 'C', 'C', 'A', 'C', 'B']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers, results, probs = decoy_function(experiment_id = \"1_3\", n = 10, temperature = 2, max_tokens = 5)\n",
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_4</td>\n",
       "      <td>1_4</td>\n",
       "      <td>1_4</td>\n",
       "      <td>1_4</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>8.00%</td>\n",
       "      <td>18.00%</td>\n",
       "      <td>30.00%</td>\n",
       "      <td>19.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>82.00%</td>\n",
       "      <td>70.00%</td>\n",
       "      <td>78.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4\n",
       "Experiment      1_4     1_4     1_4     1_4     1_4\n",
       "Temp            0.0     0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%   8.00%  18.00%  30.00%  19.57%\n",
       "p(B)          0.00%   0.00%   0.00%   0.00%   2.17%\n",
       "p(C)        100.00%  92.00%  82.00%  70.00%  78.26%\n",
       "Obs.             50      50      50      50      46"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_4, probs_1_4 = run_decoy(decoy_function, experiment_id = \"1_4\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_5</td>\n",
       "      <td>1_5</td>\n",
       "      <td>1_5</td>\n",
       "      <td>1_5</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.00%</td>\n",
       "      <td>14.29%</td>\n",
       "      <td>22.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.04%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>94.00%</td>\n",
       "      <td>83.67%</td>\n",
       "      <td>77.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1       2       3       4\n",
       "Experiment      1_5      1_5     1_5     1_5     1_5\n",
       "Temp            0.0      0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%    0.00%   6.00%  14.29%  22.22%\n",
       "p(B)          0.00%    0.00%   0.00%   2.04%   0.00%\n",
       "p(C)        100.00%  100.00%  94.00%  83.67%  77.78%\n",
       "Obs.             50       50      50      49      45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_5, probs_1_5 = run_decoy(decoy_function2, experiment_id = \"1_5\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_6</td>\n",
       "      <td>1_6</td>\n",
       "      <td>1_6</td>\n",
       "      <td>1_6</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>10.00%</td>\n",
       "      <td>22.00%</td>\n",
       "      <td>37.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>78.00%</td>\n",
       "      <td>62.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1       2       3       4\n",
       "Experiment      1_6      1_6     1_6     1_6     1_6\n",
       "Temp            0.0      0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%    0.00%  10.00%  22.00%  37.50%\n",
       "p(B)          0.00%    0.00%   0.00%   0.00%   0.00%\n",
       "p(C)        100.00%  100.00%  90.00%  78.00%  62.50%\n",
       "Obs.             50       50      50      50      48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_6, probs_1_6 = run_decoy(decoy_function2, experiment_id = \"1_6\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_7.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_7</td>\n",
       "      <td>1_7</td>\n",
       "      <td>1_7</td>\n",
       "      <td>1_7</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>2.04%</td>\n",
       "      <td>7.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>8.00%</td>\n",
       "      <td>18.00%</td>\n",
       "      <td>36.73%</td>\n",
       "      <td>26.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>80.00%</td>\n",
       "      <td>61.22%</td>\n",
       "      <td>66.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4\n",
       "Experiment      1_7     1_7     1_7     1_7     1_7\n",
       "Temp            0.0     0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%   0.00%   2.00%   2.04%   7.14%\n",
       "p(B)          0.00%   8.00%  18.00%  36.73%  26.19%\n",
       "p(C)        100.00%  92.00%  80.00%  61.22%  66.67%\n",
       "Obs.             50      50      50      49      42"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_7, probs_1_7 = run_decoy(decoy_function2, experiment_id = \"1_7\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-3.5-turbo and prompt_8.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_8</td>\n",
       "      <td>1_8</td>\n",
       "      <td>1_8</td>\n",
       "      <td>1_8</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>8.00%</td>\n",
       "      <td>22.00%</td>\n",
       "      <td>26.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>98.00%</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>78.00%</td>\n",
       "      <td>73.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4\n",
       "Experiment      1_8     1_8     1_8     1_8     1_8\n",
       "Temp            0.0     0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%   2.00%   8.00%  22.00%  26.19%\n",
       "p(B)          0.00%   0.00%   0.00%   0.00%   0.00%\n",
       "p(C)        100.00%  98.00%  92.00%  78.00%  73.81%\n",
       "Obs.             50      50      50      50      42"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_8, probs_1_8 = run_decoy(decoy_function2, experiment_id = \"1_8\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_1_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: GPT-4-1106-preview (Model training ended in April 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>97.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2        3       4\n",
       "Experiment      2_1      2_1      2_1      2_1     2_1\n",
       "Temp            0.0      0.5      1.0      1.5     2.0\n",
       "p(A)          0.00%    0.00%    0.00%    0.00%   2.08%\n",
       "p(B)          0.00%    0.00%    0.00%    0.00%   0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  100.00%  97.92%\n",
       "Obs.             50       50       50       50      48"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_1, probs_2_1 = run_decoy(decoy_function, experiment_id = \"2_1\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_2</td>\n",
       "      <td>2_2</td>\n",
       "      <td>2_2</td>\n",
       "      <td>2_2</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2        3        4\n",
       "Experiment      2_2      2_2      2_2      2_2      2_2\n",
       "Temp            0.0      0.5      1.0      1.5      2.0\n",
       "p(A)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(B)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  100.00%  100.00%\n",
       "Obs.             50       50       50       50       50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_2, probs_2_2 = run_decoy(decoy_function, experiment_id = \"2_2\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_3</td>\n",
       "      <td>2_3</td>\n",
       "      <td>2_3</td>\n",
       "      <td>2_3</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2        3        4\n",
       "Experiment      2_3      2_3      2_3      2_3      2_3\n",
       "Temp            0.0      0.5      1.0      1.5      2.0\n",
       "p(A)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(B)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  100.00%  100.00%\n",
       "Obs.             50       50       50       50       49"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_3, probs_2_3 = run_decoy(decoy_function, experiment_id = \"2_3\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_4</td>\n",
       "      <td>2_4</td>\n",
       "      <td>2_4</td>\n",
       "      <td>2_4</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>8.00%</td>\n",
       "      <td>10.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>98.00%</td>\n",
       "      <td>92.00%</td>\n",
       "      <td>89.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1       2       3       4\n",
       "Experiment      2_4      2_4     2_4     2_4     2_4\n",
       "Temp            0.0      0.5     1.0     1.5     2.0\n",
       "p(A)          0.00%    0.00%   2.00%   8.00%  10.42%\n",
       "p(B)          0.00%    0.00%   0.00%   0.00%   0.00%\n",
       "p(C)        100.00%  100.00%  98.00%  92.00%  89.58%\n",
       "Obs.             50       50      50      50      48"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_4, probs_2_4 = run_decoy(decoy_function, experiment_id = \"2_4\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_5</td>\n",
       "      <td>2_5</td>\n",
       "      <td>2_5</td>\n",
       "      <td>2_5</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2        3        4\n",
       "Experiment      2_5      2_5      2_5      2_5      2_5\n",
       "Temp            0.0      0.5      1.0      1.5      2.0\n",
       "p(A)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(B)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  100.00%  100.00%\n",
       "Obs.             50       50       50       50       48"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_5, probs_2_5 = run_decoy(decoy_function2, experiment_id = \"2_5\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_6</td>\n",
       "      <td>2_6</td>\n",
       "      <td>2_6</td>\n",
       "      <td>2_6</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.00%</td>\n",
       "      <td>12.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>96.00%</td>\n",
       "      <td>88.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2       3       4\n",
       "Experiment      2_6      2_6      2_6     2_6     2_6\n",
       "Temp            0.0      0.5      1.0     1.5     2.0\n",
       "p(A)          0.00%    0.00%    0.00%   4.00%  12.00%\n",
       "p(B)          0.00%    0.00%    0.00%   0.00%   0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  96.00%  88.00%\n",
       "Obs.             50       50       50      50      50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_6, probs_2_6 = run_decoy(decoy_function2, experiment_id = \"2_6\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 50 requests were made per temperature value using model gpt-4-1106-preview and prompt_7.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_7</td>\n",
       "      <td>2_7</td>\n",
       "      <td>2_7</td>\n",
       "      <td>2_7</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2        3        4\n",
       "Experiment      2_7      2_7      2_7      2_7      2_7\n",
       "Temp            0.0      0.5      1.0      1.5      2.0\n",
       "p(A)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(B)          0.00%    0.00%    0.00%    0.00%    0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  100.00%  100.00%\n",
       "Obs.             50       50       50       50       45"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_7, probs_2_7 = run_decoy(decoy_function2, experiment_id = \"2_7\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 50, max_tokens = 1)\n",
    "probs_2_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this experiment, 20 requests were made per temperature value using model gpt-4-1106-preview and prompt_8.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>2_8</td>\n",
       "      <td>2_8</td>\n",
       "      <td>2_8</td>\n",
       "      <td>2_8</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>15.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>84.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1        2        3       4\n",
       "Experiment      2_8      2_8      2_8      2_8     2_8\n",
       "Temp            0.0      0.5      1.0      1.5     2.0\n",
       "p(A)          0.00%    0.00%    0.00%    0.00%  15.79%\n",
       "p(B)          0.00%    0.00%    0.00%    0.00%   0.00%\n",
       "p(C)        100.00%  100.00%  100.00%  100.00%  84.21%\n",
       "Obs.             20       20       20       19      19"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_8, probs_2_8 = run_decoy(decoy_function2, experiment_id = \"2_8\", temperature_list = [0, 0.5, 1, 1.5, 2], n = 20, max_tokens = 1)\n",
    "probs_2_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(probs_2_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if priming actually works\n",
    "answer = []\n",
    "response = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        max_tokens = 100,\n",
    "        temperature = 1, # range is 0 to 2\n",
    "        messages = [\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Do you know about the Decoy Effect?\"\"\"},\n",
    "                   ])\n",
    "# Store the answer in the list\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivated by the I-bias experiment, we now examine whether labeling bias can be mitigated by using\n",
    "letters that have similar frequency in written English. Therefore, instead of assigning to choices the\n",
    "labels “A”, “B”, etc. we assign the following labels: “R”, “S”, “N”, “L”, “O”, “T”, “M”, “P”, “W”, “U”, “Y”,\n",
    "“V” - Mendler-Dünner paper "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
