{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoy Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\"temperature - A measure of how often the model outputs a less likely token. The higher the temperature, the more random (and usually creative) the output. This, however, is not the same as “truthfulness”. For most factual use cases such as data extraction, and truthful Q&A, the temperature of 0 is best.\" (https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to recreate some findings concerning the **Decoy Effect** used in pricing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer options for this experiment are literal copies of the original study. Only the words \"priced at __$\" were added to each option. Furthermore, their wording remains the same\n",
    "through the entire experiment, being: \n",
    "-  A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "-  B: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "-  C: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "\n",
    "\n",
    "#### From Ariely's Book \"Predictably irrational\":\n",
    "\n",
    "\"When I gave these options to 100 students at MIT's Sloan\n",
    "School of Management, they opted as follows:\n",
    "1. Internet-only subscription for $59—16 students\n",
    "2. Print-only subscription for $125—zero students\n",
    "3. Print-and-Internet subscription for $ 125—84 students\"\n",
    "\n",
    "(page 5)\n",
    "\n",
    "\"And the absence of the decoy\n",
    "had them choosing differently, with 32 for print-and-Internet\n",
    "and 68 for Internet-only\"\n",
    "\n",
    "(page 6)\n",
    "\n",
    "|Answer option          | Scenario 1 | Scenario 2 (no 2nd option)|\n",
    "|-----------------------|--------------|-----------|\n",
    "| Online subscription   |     16%      |  68%       |\n",
    "| Print subscribtion    |      0%     | 0%        |\n",
    "| Combination           |     84%   | 32%        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import replicate\n",
    "from ast import literal_eval\n",
    "import plotly.graph_objects as go\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style \n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the prompts used for the experiment\n",
    "\n",
    "We now formulate 8 different prompts: \n",
    "\n",
    "First of all, we present the model with the original situation i.e. 3 answer options. To recreate the second scenario of the study, we tell the model that the second (decoy) option has now been removed. \n",
    "Furthermore we **prime** the model play the role of a marker researcher, who knows about the decoy effect, and query the model with both study situationbs again.\n",
    "\n",
    "Afterwards, in order to research possible biases induced by either the answer letters themselves (A, B, C) or the order of the answers, we correct for this and prompt the model 4 times again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_1 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "        A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "        B: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "        C: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "        Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_2 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "        A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "        B: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$. \n",
    "        Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Removed original option B and made option C the new option B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_3 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "        You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "        A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "        B: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "        C: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "        Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_4 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         A: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$.\n",
    "         B: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Removed original option B and made option C the new option B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming and reordering answer options\n",
    "\n",
    "Following the approach of Mendler-Dünner et al. (2023), we do not only reorder the answers but also label them with letters, that are less common in the English language.\n",
    "- A (online) -> Y\n",
    "- B (print) -> Q\n",
    "- C (combination) -> X\n",
    "\n",
    "Afterwards option 1 is put last. Sticking to our original question design, the order would now be: B, C, A.\n",
    "- N (print)\n",
    "- T (combination)\n",
    "- W (online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_5 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         Q: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_6 = \"\"\"You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Removed option Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_7 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         Q: One-year subscription to the print edition of The Economist, priced at 125$.\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompt_8 = \"\"\"You are a market researcher that knows about the Decoy Effect in pricing. \n",
    "         You are presented with the following subscription alternatives for the \"The Economist\" magazine:\n",
    "         X: One-year subscription to the print edition of The Economist and online access to all articles from The Economist since 1997, priced at 125$.\n",
    "         Y: One-year subscription to Economist.com. Includes online access to all articles from The Economist since 1997, priced at 59$. \n",
    "         Which alternative would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Removed option Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save prompts to use them in the Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prompts = [DE_prompt_1, DE_prompt_2, DE_prompt_3, DE_prompt_4, DE_prompt_5, DE_prompt_6, DE_prompt_7, DE_prompt_8]\n",
    "with open ('Dashboard/src/data/Input/DE_prompts.pkl', 'wb') as file:\n",
    "    pickle.dump(DE_prompts, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Helpful dictionaries \n",
    "\n",
    "The experiments we will run in this notebook are very similar in study design, and for same cases, also similar in the results we expect. We therefore need to make sure, that we associate the results with the correct study design. That is why the following dictionaries are implemented to look up e.g. what model was used for an experiment.\n",
    "\n",
    "They will also be used inside the functions that call the API multiple times and output some information about the experiment in order to identify it correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that returns the literal prompt for a given experiment id (used in function call). key: experiment_id, value: prompt\n",
    "DE_experiment_prompts_dict = {\n",
    "    \"DE_1_1\": DE_prompts[0],\n",
    "    \"DE_1_2\": DE_prompts[1],\n",
    "    \"DE_1_3\": DE_prompts[2],\n",
    "    \"DE_1_4\": DE_prompts[3],\n",
    "    \"DE_1_5\": DE_prompts[4],\n",
    "    \"DE_1_6\": DE_prompts[5],\n",
    "    \"DE_1_7\": DE_prompts[6],\n",
    "    \"DE_1_8\": DE_prompts[7],\n",
    "    \"DE_2_1\": DE_prompts[0],\n",
    "    \"DE_2_2\": DE_prompts[1],\n",
    "    \"DE_2_3\": DE_prompts[2],\n",
    "    \"DE_2_4\": DE_prompts[3],\n",
    "    \"DE_2_5\": DE_prompts[4],\n",
    "    \"DE_2_6\": DE_prompts[5],\n",
    "    \"DE_2_7\": DE_prompts[6],\n",
    "    \"DE_2_8\": DE_prompts[7],\n",
    "    \"DE_3_1\": DE_prompts[0],\n",
    "    \"DE_3_2\": DE_prompts[1],\n",
    "    \"DE_3_3\": DE_prompts[2],\n",
    "    \"DE_3_4\": DE_prompts[3],\n",
    "    \"DE_3_5\": DE_prompts[4],\n",
    "    \"DE_3_6\": DE_prompts[5],\n",
    "    \"DE_3_7\": DE_prompts[6],\n",
    "    \"DE_3_8\": DE_prompts[7],\n",
    "}\n",
    "\n",
    "# The following dictionary is only used for a check in the function calls.\n",
    "# It returns the variable name of the prompt that was used in the experiment. key: experiment_id, value: prompt_name\n",
    "DE_prompt_ids_dict = {\n",
    "    \"DE_1_1\": \"DE_prompts[0]\",\n",
    "    \"DE_1_2\": \"DE_prompts[1]\",\n",
    "    \"DE_1_3\": \"DE_prompts[2]\",\n",
    "    \"DE_1_4\": \"DE_prompts[3]\",\n",
    "    \"DE_1_5\": \"DE_prompts[4]\",\n",
    "    \"DE_1_6\": \"DE_prompts[5]\",\n",
    "    \"DE_1_7\": \"DE_prompts[6]\",\n",
    "    \"DE_1_8\": \"DE_prompts[7]\",\n",
    "    \"DE_2_1\": \"DE_prompts[0]\",\n",
    "    \"DE_2_2\": \"DE_prompts[1]\",\n",
    "    \"DE_2_3\": \"DE_prompts[2]\",\n",
    "    \"DE_2_4\": \"DE_prompts[3]\",\n",
    "    \"DE_2_5\": \"DE_prompts[4]\",\n",
    "    \"DE_2_6\": \"DE_prompts[5]\",\n",
    "    \"DE_2_7\": \"DE_prompts[6]\",\n",
    "    \"DE_2_8\": \"DE_prompts[7]\",\n",
    "    \"DE_3_1\": \"DE_prompts[0]\",\n",
    "    \"DE_3_2\": \"DE_prompts[1]\",\n",
    "    \"DE_3_3\": \"DE_prompts[2]\",\n",
    "    \"DE_3_4\": \"DE_prompts[3]\",\n",
    "    \"DE_3_5\": \"DE_prompts[4]\",\n",
    "    \"DE_3_6\": \"DE_prompts[5]\",\n",
    "    \"DE_3_7\": \"DE_prompts[6]\",\n",
    "    \"DE_3_8\": \"DE_prompts[7]\",\n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary to look up which model to use for a given experiment id (used in function call). key: experiment id, value: model name\n",
    "DE_model_dict = {\n",
    "    \"DE_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_3\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_4\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_5\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_6\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_7\": \"gpt-3.5-turbo\",\n",
    "    \"DE_1_8\": \"gpt-3.5-turbo\",\n",
    "    \"DE_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_3\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_4\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_5\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_6\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_7\": \"gpt-4-1106-preview\",\n",
    "    \"DE_2_8\": \"gpt-4-1106-preview\",\n",
    "    \"DE_3_1\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_2\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_3\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_4\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_5\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_6\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_7\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    \"DE_3_8\": 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
    "    }\n",
    "\n",
    "# Dictionary to look up the original results of the experiments. key: experiment id, value: original result\n",
    "DE_og_results_dict = {\n",
    "    \"DE_1_1\": [16, 0, 84], \n",
    "    \"DE_1_2\": [68, 0, 32], \n",
    "    \"DE_1_3\": [16, 0, 84],\n",
    "    \"DE_1_4\": [68, 0, 32],\n",
    "    \"DE_1_5\": [16, 0, 84],\n",
    "    \"DE_1_6\": [68, 0, 32],\n",
    "    \"DE_1_7\": [16, 0, 84],\n",
    "    \"DE_1_8\": [68, 0, 32],\n",
    "    \"DE_2_1\": [16, 0, 84],\n",
    "    \"DE_2_2\": [68, 0, 32],\n",
    "    \"DE_2_3\": [16, 0, 84],\n",
    "    \"DE_2_4\": [68, 0, 32],\n",
    "    \"DE_2_5\": [16, 0, 84],\n",
    "    \"DE_2_6\": [68, 0, 32],\n",
    "    \"DE_2_7\": [16, 0, 84],\n",
    "    \"DE_2_8\": [68, 0, 32],\n",
    "    \"DE_3_1\": [16, 0, 84],\n",
    "    \"DE_3_2\": [68, 0, 32],\n",
    "    \"DE_3_3\": [16, 0, 84],\n",
    "    \"DE_3_4\": [68, 0, 32],\n",
    "    \"DE_3_5\": [16, 0, 84],\n",
    "    \"DE_3_6\": [68, 0, 32],\n",
    "    \"DE_3_7\": [16, 0, 84],\n",
    "    \"DE_3_8\": [68, 0, 32],\n",
    "}\n",
    "\n",
    "# Dictionary to look up number of original answers. key: experiment id, value: number of original answers (only necessary for dashboard)\n",
    "DE_answercount_dict = {\n",
    "    \"DE_1_1\": 100,\n",
    "    \"DE_1_2\": 100,\n",
    "    \"DE_1_3\": 100,\n",
    "    \"DE_1_4\": 100,\n",
    "    \"DE_1_5\": 100,\n",
    "    \"DE_1_6\": 100,\n",
    "    \"DE_1_7\": 100,\n",
    "    \"DE_1_8\": 100,\n",
    "    \"DE_2_1\": 100,\n",
    "    \"DE_2_2\": 100,\n",
    "    \"DE_2_3\": 100,\n",
    "    \"DE_2_4\": 100,\n",
    "    \"DE_2_5\": 100,\n",
    "    \"DE_2_6\": 100,\n",
    "    \"DE_2_7\": 100,\n",
    "    \"DE_2_8\": 100,\n",
    "    \"DE_3_1\": 100,\n",
    "    \"DE_3_2\": 100,\n",
    "    \"DE_3_3\": 100,\n",
    "    \"DE_3_4\": 100,\n",
    "    \"DE_3_5\": 100,\n",
    "    \"DE_3_6\": 100,\n",
    "    \"DE_3_7\": 100,\n",
    "    \"DE_3_8\": 100,\n",
    "}\n",
    "\n",
    "# Dictionary to look up the scenario of each experiment. key: experiment id, value: scenario (1: With Decoy, 2: Without Decoy)\n",
    "DE_scenario_dict = {\n",
    "    \"DE_1_1\": 1,\n",
    "    \"DE_1_2\": 2,\n",
    "    \"DE_1_3\": 1,\n",
    "    \"DE_1_4\": 2,\n",
    "    \"DE_1_5\": 1,\n",
    "    \"DE_1_6\": 2,\n",
    "    \"DE_1_7\": 1,\n",
    "    \"DE_1_8\": 2,\n",
    "    \"DE_2_1\": 1,\n",
    "    \"DE_2_2\": 2,\n",
    "    \"DE_2_3\": 1,\n",
    "    \"DE_2_4\": 2,\n",
    "    \"DE_2_5\": 1,\n",
    "    \"DE_2_6\": 2,\n",
    "    \"DE_2_7\": 1,\n",
    "    \"DE_2_8\": 2,\n",
    "    \"DE_3_1\": 1,\n",
    "    \"DE_3_2\": 2,\n",
    "    \"DE_3_3\": 1,\n",
    "    \"DE_3_4\": 2,\n",
    "    \"DE_3_5\": 1,\n",
    "    \"DE_3_6\": 2,\n",
    "    \"DE_3_7\": 1,\n",
    "    \"DE_3_8\": 2,\n",
    "}\n",
    "\n",
    "# Dictionary to look up, whether the experiment was primed or not. key: experiment id, value: priming (1: Primed, 0: Unprimed)\n",
    "DE_priming_dict = {\n",
    "    \"DE_1_1\": 0,\n",
    "    \"DE_1_2\": 0,\n",
    "    \"DE_1_3\": 1,\n",
    "    \"DE_1_4\": 1,\n",
    "    \"DE_1_5\": 0,\n",
    "    \"DE_1_6\": 0,\n",
    "    \"DE_1_7\": 1,\n",
    "    \"DE_1_8\": 1,\n",
    "    \"DE_2_1\": 0,\n",
    "    \"DE_2_2\": 0,\n",
    "    \"DE_2_3\": 1,\n",
    "    \"DE_2_4\": 1,\n",
    "    \"DE_2_5\": 0,\n",
    "    \"DE_2_6\": 0,\n",
    "    \"DE_2_7\": 1,\n",
    "    \"DE_2_8\": 1,\n",
    "    \"DE_3_1\": 0,\n",
    "    \"DE_3_2\": 0,\n",
    "    \"DE_3_3\": 1,\n",
    "    \"DE_3_4\": 1,\n",
    "    \"DE_3_5\": 0,\n",
    "    \"DE_3_6\": 0,\n",
    "    \"DE_3_7\": 1,\n",
    "    \"DE_3_8\": 1,\n",
    "}\n",
    "\n",
    "# Dictionary to look up, whether answers were renamed and reordered or not. key: experiment id, value: indicator (1: Renamed and reordered, 0: Not renamed and reordered)\n",
    "DE_reorder_dict = {\n",
    "    \"DE_1_1\": 0,\n",
    "    \"DE_1_2\": 0,\n",
    "    \"DE_1_3\": 0,\n",
    "    \"DE_1_4\": 0,\n",
    "    \"DE_1_5\": 1,\n",
    "    \"DE_1_6\": 1,\n",
    "    \"DE_1_7\": 1,\n",
    "    \"DE_1_8\": 1,\n",
    "    \"DE_2_1\": 0,\n",
    "    \"DE_2_2\": 0,\n",
    "    \"DE_2_3\": 0,\n",
    "    \"DE_2_4\": 0,\n",
    "    \"DE_2_5\": 1,\n",
    "    \"DE_2_6\": 1,\n",
    "    \"DE_2_7\": 1,\n",
    "    \"DE_2_8\": 1,\n",
    "    \"DE_3_1\": 0,\n",
    "    \"DE_3_2\": 0,\n",
    "    \"DE_3_3\": 0,\n",
    "    \"DE_3_4\": 0,\n",
    "    \"DE_3_5\": 1,\n",
    "    \"DE_3_6\": 1,\n",
    "    \"DE_3_7\": 1,\n",
    "    \"DE_3_8\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect dictionaries and save for use in Dashboard\n",
    "DE_dictionaries = [DE_experiment_prompts_dict, DE_prompt_ids_dict, DE_model_dict, DE_og_results_dict, DE_answercount_dict, DE_scenario_dict, DE_priming_dict, DE_reorder_dict]\n",
    "with open ('Dashboard/src/data/Input/DE_dictionaries.pkl', 'wb') as file:\n",
    "    pickle.dump(DE_dictionaries, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions \n",
    "\n",
    "The following functions are introduced in order to emulate a survey for our pre-implemented prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count answers depending on prompt design which is reflected in the experiment id\n",
    "def DE_count_answers(answers: list, experiment_id: str):\n",
    "    if experiment_id in [\"DE_1_1\", \"DE_1_3\",\"DE_2_1\", \"DE_2_3\", \"DE_3_1\", \"DE_3_3\"]:\n",
    "        A = answers.count(\"A\")\n",
    "        B = answers.count(\"B\")\n",
    "        C = answers.count(\"C\")\n",
    "    elif experiment_id in [\"DE_1_2\", \"DE_1_4\", \"DE_2_2\", \"DE_2_4\", \"DE_3_2\", \"DE_3_4\"]:\n",
    "        A = answers.count(\"A\")\n",
    "        B = 0 # Option B was removed\n",
    "        C = answers.count(\"B\") # makes comparison of results over prompts easier \n",
    "    elif experiment_id in [\"DE_1_5\", \"DE_1_7\", \"DE_2_5\", \"DE_2_7\", \"DE_3_5\", \"DE_3_7\"]:\n",
    "        A = answers.count(\"Y\")\n",
    "        B = answers.count(\"Q\")\n",
    "        C = answers.count(\"X\")\n",
    "    elif experiment_id in [\"DE_1_6\", \"DE_1_8\", \"DE_2_6\", \"DE_2_8\", \"DE_3_6\", \"DE_3_8\"]:\n",
    "        A = answers.count(\"Y\")\n",
    "        B = 0 # Option Q was removed\n",
    "        C = answers.count(\"X\")\n",
    "    return A, B, C\n",
    "\n",
    "# Function to count correct answers depending on prompt design which is reflected in the experiment id (used for percentages)\n",
    "def DE_correct_answers(answers: list, experiment_id: str):\n",
    "    if experiment_id in [\"DE_1_1\", \"DE_1_3\",\"DE_2_1\", \"DE_2_3\", \"DE_3_1\", \"DE_3_3\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\", \"C\"])\n",
    "    elif experiment_id in [\"DE_1_2\", \"DE_1_4\", \"DE_2_2\", \"DE_2_4\", \"DE_3_2\", \"DE_3_4\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\"])\n",
    "    elif experiment_id in [\"DE_1_5\", \"DE_1_7\", \"DE_2_5\", \"DE_2_7\", \"DE_3_5\", \"DE_3_7\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"Y\", \"Q\", \"X\"])\n",
    "    elif experiment_id in [\"DE_1_6\", \"DE_1_8\", \"DE_2_6\", \"DE_2_8\", \"DE_3_6\", \"DE_3_8\"]:\n",
    "        len_correct = sum(1 for ans in answers if ans in [\"Y\", \"X\"])\n",
    "    return len_correct  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Functions to query 1 prompt n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a single experiment n times\n",
    "def DE_run_experiment(experiment_id: int, n: int,  progress_bar, temperature: int):\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT multiple times with a survey having answers designed as: A, B, C.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        n (int): Number of queries to be made\n",
    "        temperature (int): Degree of randomness with range 0 (deterministic) to 2 (random)\n",
    "        max_tokens (int): Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results (list): List containing count of answers for each option, also containing experiment_id, temperature and number of observations\n",
    "        probs (list): List containing probability of each option being chosen, also containing experiment_id, temeperature and number of observations\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = DE_model_dict[experiment_id], \n",
    "            max_tokens = 5,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Only answer with the letter of the alternative you would choose without any reasoning.\"},\n",
    "            {\"role\": \"user\", \"content\": DE_experiment_prompts_dict[experiment_id]},\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Count the answers\n",
    "    A, B, C = DE_count_answers(answers, experiment_id) \n",
    "    \n",
    "    # Count of correct answers\n",
    "    len_correct = int(DE_correct_answers(answers, experiment_id)) \n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = [experiment_id, temperature, A, B, C, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "                DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], DE_og_results_dict[experiment_id], DE_answercount_dict[experiment_id]]\n",
    "    \n",
    "    # Getting percentage of each answer\n",
    "    p_a = f\"{(A / len_correct) * 100 if len_correct != 0 else 0:.2f}%\"\n",
    "    p_b = f\"{(B / len_correct) * 100 if len_correct != 0 else 0:.2f}%\"\n",
    "    p_c = f\"{(C / len_correct) * 100 if len_correct != 0 else 0:.2f}%\"\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = [experiment_id, temperature, p_a, p_b, p_c, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "              DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], DE_og_results_dict[experiment_id], DE_answercount_dict[experiment_id]]\n",
    "\n",
    "\n",
    "    return results, probs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for dashboard  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_run_experiment_dashboard(experiment_id: int, n: int, temperature: int, openai_key):\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT multiple times with a survey having answers designed as: A, B, C.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        n (int): Number of queries to be made\n",
    "        temperature (int): Degree of randomness with range 0 (deterministic) to 2 (random)\n",
    "        max_tokens (int): Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results (list): List containing count of answers for each option, also containing experiment_id, temperature and number of observations\n",
    "        probs (list): List containing probability of each option being chosen, also containing experiment_id, temeperature and number of observations\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    client = OpenAI(api_key=openai_key)\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = DE_model_dict[experiment_id], \n",
    "            max_tokens = 5,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Only answer with the letter of the alternative you would choose without any reasoning.\"},\n",
    "            {\"role\": \"user\", \"content\": DE_experiment_prompts_dict[experiment_id]},\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "    # Count the answers\n",
    "    A, B, C = DE_count_answers(answers, experiment_id)\n",
    "    \n",
    "    # Count of correct answers\n",
    "    len_correct = int(DE_correct_answers(answers, experiment_id)) \n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = pd.DataFrame([experiment_id, temperature, A, B, C, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "                             DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], DE_og_results_dict[experiment_id], DE_answercount_dict[experiment_id]])\n",
    "    results = results.set_index(pd.Index([\"Experiment\", \"Temp\", \"A\", \"B\", \"C\", \"Obs.\", \"Model\", \"Scenario\", \"Priming\", \"Reorder\", \"Original\", \"Original_count\"]))\n",
    "    results = results.transpose()\n",
    "    \n",
    "   # Getting percentage of each answer\n",
    "    p_a = (A / len_correct) * 100 if len_correct != 0 else 0\n",
    "    p_b = (B / len_correct) * 100 if len_correct != 0 else 0\n",
    "    p_c = (C / len_correct) * 100 if len_correct != 0 else 0\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = pd.DataFrame([experiment_id, temperature, p_a, p_b, p_c, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "                           DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], f\"{DE_og_results_dict[experiment_id]}\", DE_answercount_dict[experiment_id]])\n",
    "    probs = probs.set_index(pd.Index([\"Experiment\", \"Temp\", \"A\", \"B\", \"C\", \"Obs.\", \"Model\", \"Scenario\", \"Priming\", \"Reorder\", \"Original\", \"Original_count\"]))\n",
    "    probs = probs.transpose()\n",
    "\n",
    "    return results, probs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to query 1 prompt n times (LLama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_run_experiment_llama(experiment_id, n, progress_bar, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            DE_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\": \"Only answer with the letter of the alternative you would choose without any reasoning.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 2, \n",
    "                \"prompt\": DE_experiment_prompts_dict[experiment_id]\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Count the answers\n",
    "    A, B, C = DE_count_answers(answers, experiment_id) # if/else statement of function deals with different answer options in different experiments\n",
    "    \n",
    "    # Count of correct answers\n",
    "    len_correct = int(DE_correct_answers(answers, experiment_id)) # if/else of function makes sure that we count the correct answers according to the experiment id \n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = [experiment_id, temperature, A, B, C, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "                DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], DE_og_results_dict[experiment_id], DE_answercount_dict[experiment_id]]\n",
    "\n",
    "    # Getting percentage of each answer\n",
    "    p_a = f\"{(A / len_correct) * 100 if len_correct != 0 else 0:.2f}%\"\n",
    "    p_b = f\"{(B / len_correct) * 100 if len_correct != 0 else 0:.2f}%\"\n",
    "    p_c = f\"{(C / len_correct) * 100 if len_correct != 0 else 0:.2f}%\"\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = [experiment_id, temperature, p_a, p_b, p_c, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "              DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], DE_og_results_dict[experiment_id], DE_answercount_dict[experiment_id]]\n",
    "    \n",
    "    # Give out results\n",
    "    return results, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for dashboard  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_run_experiment_llama_dashboard(experiment_id, n, temperature, replicate_token):\n",
    "    answers = []\n",
    "    replicate = Client(api_token = replicate_token)\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            DE_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\": \"Only answer with the letter of the alternative you would choose without any reasoning.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 2, \n",
    "                \"prompt\": DE_experiment_prompts_dict[experiment_id]\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "    # Count the answers\n",
    "    A, B, C = DE_count_answers(answers, experiment_id) # if/else statement of function deals with different answer options in different experiments\n",
    "    \n",
    "    # Count of correct answers\n",
    "    len_correct = int(DE_correct_answers(answers, experiment_id)) # if/else of function makes sure that we count the correct answers according to the experiment id \n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = pd.DataFrame([experiment_id, temperature, A, B, C, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "                             DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id], DE_og_results_dict[experiment_id], DE_answercount_dict[experiment_id]])\n",
    "    results = results.set_index(pd.Index([\"Experiment\", \"Temp\", \"A\", \"B\", \"C\", \"Obs.\", \"Model\", \"Scenario\", \"Priming\", \"Reorder\", \"Original\", \"Original_count\"]))\n",
    "    results = results.transpose()\n",
    "\n",
    "   # Getting percentage of each answer\n",
    "    p_a = (A / len_correct) * 100 if len_correct != 0 else 0\n",
    "    p_b = (B / len_correct) * 100 if len_correct != 0 else 0\n",
    "    p_c = (C / len_correct) * 100 if len_correct != 0 else 0\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = pd.DataFrame([experiment_id, temperature, p_a, p_b, p_c, len_correct, DE_model_dict[experiment_id], DE_scenario_dict[experiment_id],\n",
    "                           DE_priming_dict[experiment_id], DE_reorder_dict[experiment_id],  f\"{DE_og_results_dict[experiment_id]}\", DE_answercount_dict[experiment_id]])\n",
    "    probs = probs.set_index(pd.Index([\"Experiment\", \"Temp\", \"A\", \"B\", \"C\", \"Obs.\", \"Model\", \"Scenario\", \"Priming\", \"Reorder\", \"Original\", \"Original_count\"]))\n",
    "    probs = probs.transpose()\n",
    "    # Give out results\n",
    "    return results, probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop run_experiment() over a list of temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run 1 experiment over different temperature values\n",
    "def DE_temperature_loop(function, experiment_id: str, temperature_list: list = [0, 0.5, 1, 1.5, 2], n: int = 50):\n",
    "    \"\"\"\n",
    "    Function to run an experiment over different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty lists for storing results\n",
    "    results_list = []\n",
    "    probs_list = []\n",
    "    # Initialize progress bar -> used as input for run_experiment()\n",
    "    progress_bar = tqdm(range(n*len(temperature_list)))\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results, probs = function(experiment_id = experiment_id, n = n, temperature = temperature, progress_bar = progress_bar) \n",
    "        results_list.append(results)\n",
    "        probs_list.append(probs)\n",
    "    \n",
    "    # Stop progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index(\n",
    "        [\"Experiment\", \"Temp\", \"A\", \"B\", \"C\", \"Obs.\", \"Model\", \"Scenario\", \"Priming\", \"Reorder\", \"Original\", \"Original_count\"]))\n",
    "    probs_df = pd.DataFrame(probs_list).transpose().set_index(pd.Index(\n",
    "        [\"Experiment\", \"Temp\", \"A\" \"B\", \"C\", \"Obs.\", \"Model\", \"Scenario\", \"Priming\", \"Reorder\", \"Original\", \"Original_count\"]))\n",
    "      \n",
    "    return results_df, probs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to plot distribution of answer probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot distribution of answer probabilities\n",
    "def DE_plot_results(df: pd.DataFrame):\n",
    "    \n",
    "    # Get experiment id and model name for plot title from dictionaries\n",
    "    experiment_id = df.iloc[0, 0]\n",
    "    model = DE_model_dict[experiment_id]\n",
    "    \n",
    "    X = df.loc[\"Temp\"]\n",
    "    p_a = df.loc[\"p(A)\"].str.rstrip('%').astype('float')  # Convert percentages to float\n",
    "    p_b = df.loc[\"p(B)\"].str.rstrip('%').astype('float')\n",
    "    p_c = df.loc[\"p(C)\"].str.rstrip('%').astype('float')\n",
    "\n",
    "    X_axis = np.arange(len(X)) \n",
    "\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.bar(X_axis- 0.25, p_a, 0.25, label = 'p(A)', color = \"#8C1515\") \n",
    "    ax.bar(X_axis, p_b, 0.25,  label = 'p(B)', color = \"#507FAB\") \n",
    "    ax.bar(X_axis+ 0.25 , p_c,  0.25, label = 'p(C)', color = '#D9A84A')\n",
    "\n",
    "    ax.set_xticks(X_axis, X)\n",
    "    ax.set_xlabel(\"Temperature\")\n",
    "    ax.set_ylabel(\"Probability (%)\")\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.set_title(f\"Distribution of answers per temperature value for experiment {experiment_id} using {model}\")\n",
    "    ax.legend()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different LLMs\n",
    "\n",
    "The design of our experiment IDs in this context will be:\n",
    "\n",
    "- model_scenario\n",
    "\n",
    "With models being: \n",
    "- 1: GPT-3.5-Turbo \n",
    "- 2: GPT-4-1106-Preview \n",
    "- 3: Meta's Llama model.\n",
    "\n",
    "And the scenarios being:\n",
    "- 1: Unprimed & all answer options\n",
    "- 2: Unprimed & Decoy removed\n",
    "- 3: Primed & all answer options\n",
    "- 4: Primed & second option (decoy) removed\n",
    "- 5: Unprimed & all answer options, renamed & reordered\n",
    "- 6: Unprimed & second option (decoy) removed, renamed & reordered\n",
    "- 7: Primed & all answer options, renamed & reordered\n",
    "- 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: GPT-3.5-Turbo (Model training ended in September 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of requests per temperature value\n",
    "N = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "results_1_1, probs_1_1 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_1\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)\n",
    "# Display results\n",
    "probs_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_2, probs_1_2 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_2\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_3, probs_1_3 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_3\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_4, probs_1_4 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_4\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_5, probs_1_5 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_5\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_6, probs_1_6 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_6\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_7, probs_1_7 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_7\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_8, probs_1_8 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_1_8\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: GPT-4-1106-preview (Model training ended in April 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of requests per temperature value\n",
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_1, probs_2_1 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_1\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_2, probs_2_2 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_2\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_3, probs_2_3 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_3\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_4, probs_2_4 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_4\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_5, probs_2_5 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_5\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_6, probs_2_6 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_6\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_7, probs_2_7 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_7\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_8, probs_2_8 = DE_temperature_loop(DE_run_experiment, experiment_id = \"DE_2_8\", temperature_list = [0, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: LLama-2-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of requests per temperature value\n",
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 1: Unprimed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_1, probs_3_1 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_1\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 2: Unprimed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_2, probs_3_2 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_2\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 3: Primed & all answer options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_3, probs_3_3 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_3\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 4: Primed & second option (decoy) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_4, probs_3_4 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_4\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 5: Unprimed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_5, probs_3_5 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_5\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 6: Unprimed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_6, probs_3_6 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_6\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 7: Primed & all answer options, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_7, probs_3_7 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_7\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt 8: Primed & second option (decoy) removed, renamed & reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_8, probs_3_8 = DE_temperature_loop(DE_run_experiment_llama, experiment_id = \"DE_3_8\", temperature_list = [0.01, 0.5, 1, 1.5, 2], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all results in one dataframe\n",
    "DE_probs = pd.concat([probs_1_1, probs_1_2, probs_1_3, probs_1_4, probs_1_5, probs_1_6, probs_1_7, probs_1_8,\n",
    "                      probs_2_1, probs_2_2, probs_2_3, probs_2_4, probs_2_5, probs_2_6, probs_2_7, probs_2_8,\n",
    "                      probs_3_1, probs_3_2, probs_3_3, probs_3_4, probs_3_5, probs_3_6, probs_3_7, probs_3_8], axis = 1).transpose()\n",
    "# Rename LLama model\n",
    "DE_probs['Model'] = DE_probs['Model'].replace('meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3', \n",
    "                                  'llama-2-70b')\n",
    "# Demonstrate results\n",
    "DE_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform probabilities to float for plotting\n",
    "DE_probs[\"p(A)\"] = DE_probs[\"p(A)\"].str.rstrip('%').astype('float')\n",
    "DE_probs[\"p(B)\"] = DE_probs[\"p(B)\"].str.rstrip('%').astype('float')\n",
    "DE_probs[\"p(C)\"] = DE_probs[\"p(C)\"].str.rstrip('%').astype('float')\n",
    "DE_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally save to .csv-file\n",
    "DE_probs.to_csv(\"Dashboard/src/data/Output/DE_probs.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_id</th>\n",
       "      <th>Temp</th>\n",
       "      <th>p(A)</th>\n",
       "      <th>p(B)</th>\n",
       "      <th>p(C)</th>\n",
       "      <th>Obs.</th>\n",
       "      <th>Model</th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Priming</th>\n",
       "      <th>Reorder</th>\n",
       "      <th>Original</th>\n",
       "      <th>Original_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE_1_1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 0, 84]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE_1_1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 0, 84]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE_1_1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 0, 84]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE_1_1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>7.22</td>\n",
       "      <td>18.56</td>\n",
       "      <td>74.23</td>\n",
       "      <td>97</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 0, 84]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE_1_1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.59</td>\n",
       "      <td>17.65</td>\n",
       "      <td>71.76</td>\n",
       "      <td>85</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 0, 84]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>DE_3_8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 0, 32]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>DE_3_8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 0, 32]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>DE_3_8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 0, 32]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>DE_3_8</td>\n",
       "      <td>1.50</td>\n",
       "      <td>84.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.56</td>\n",
       "      <td>45</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 0, 32]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>DE_3_8</td>\n",
       "      <td>2.00</td>\n",
       "      <td>78.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.62</td>\n",
       "      <td>37</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 0, 32]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiment_id  Temp    p(A)   p(B)    p(C)  Obs.          Model  Scenario  \\\n",
       "0          DE_1_1  0.00    0.00   0.00  100.00   100  gpt-3.5-turbo         1   \n",
       "1          DE_1_1  0.50    0.00   1.00   99.00   100  gpt-3.5-turbo         1   \n",
       "2          DE_1_1  1.00    6.00   5.00   89.00   100  gpt-3.5-turbo         1   \n",
       "3          DE_1_1  1.50    7.22  18.56   74.23    97  gpt-3.5-turbo         1   \n",
       "4          DE_1_1  2.00   10.59  17.65   71.76    85  gpt-3.5-turbo         1   \n",
       "..            ...   ...     ...    ...     ...   ...            ...       ...   \n",
       "115        DE_3_8  0.01  100.00   0.00    0.00    50    llama-2-70b         2   \n",
       "116        DE_3_8  0.50  100.00   0.00    0.00    50    llama-2-70b         2   \n",
       "117        DE_3_8  1.00  100.00   0.00    0.00    50    llama-2-70b         2   \n",
       "118        DE_3_8  1.50   84.44   0.00   15.56    45    llama-2-70b         2   \n",
       "119        DE_3_8  2.00   78.38   0.00   21.62    37    llama-2-70b         2   \n",
       "\n",
       "     Priming  Reorder     Original  Original_count  \n",
       "0          0        0  [16, 0, 84]             100  \n",
       "1          0        0  [16, 0, 84]             100  \n",
       "2          0        0  [16, 0, 84]             100  \n",
       "3          0        0  [16, 0, 84]             100  \n",
       "4          0        0  [16, 0, 84]             100  \n",
       "..       ...      ...          ...             ...  \n",
       "115        1        1  [68, 0, 32]             100  \n",
       "116        1        1  [68, 0, 32]             100  \n",
       "117        1        1  [68, 0, 32]             100  \n",
       "118        1        1  [68, 0, 32]             100  \n",
       "119        1        1  [68, 0, 32]             100  \n",
       "\n",
       "[120 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DE_probs = pd.read_csv(\"Dashboard/src/data/Output/DE_probs.csv\")\n",
    "DE_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Temp</th>\n",
       "      <th>p(A)</th>\n",
       "      <th>p(B)</th>\n",
       "      <th>p(C)</th>\n",
       "      <th>Obs.</th>\n",
       "      <th>Model</th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Priming</th>\n",
       "      <th>Reorder</th>\n",
       "      <th>Original</th>\n",
       "      <th>Original_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE_1_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[16, 0, 84]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment  Temp  p(A)  p(B)   p(C)  Obs.          Model  Scenario  Priming  \\\n",
       "0     DE_1_1   0.0   0.0   0.0  100.0   100  gpt-3.5-turbo         1        0   \n",
       "\n",
       "   Reorder     Original  Original_count  \n",
       "0        0  [16, 0, 84]             100  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "scenario = 1\n",
    "priming = 0\n",
    "reorder = 0\n",
    "temperature = 0\n",
    "df = DE_probs[(DE_probs[\"Model\"] == model) & (DE_probs[\"Scenario\"] == scenario) & (DE_probs[\"Priming\"] == priming) & (DE_probs[\"Reorder\"] == reorder) & (DE_probs[\"Temp\"] == temperature)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_plot_results(df):\n",
    "\n",
    "    # Transpose for plotting\n",
    "    df = df.transpose()  \n",
    "    # Get language model name\n",
    "    model = df.loc[\"Model\"].iloc[0]\n",
    "    if model == 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3':\n",
    "        model = \"llama-2-70b\" \n",
    "    # Get temperature value\n",
    "    temperature = df.loc[\"Temp\"].iloc[0]\n",
    "    # Get number of observations per temperature value\n",
    "    n_observations = df.loc[\"Obs.\"].iloc[0]\n",
    "    # Get original answer probabilities\n",
    "    og_answers = df.loc[\"Original\"].apply(literal_eval).iloc[0]\n",
    "    # Get number of original answers\n",
    "    n_original = df.loc[\"Original_count\"].iloc[0]\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            name = \"Model answers\",\n",
    "            x = [\"A\", \"B\", \"C\"],\n",
    "            y = [df.loc[\"A\"].iloc[0], df.loc[\"B\"].iloc[0], df.loc[\"C\"].iloc[0]],\n",
    "            customdata = [n_observations, n_observations, n_observations], \n",
    "            hovertemplate = \"Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>\",\n",
    "            marker_color = \"rgb(55, 83, 109)\"\n",
    "        ),\n",
    "        go.Bar(\n",
    "            name = \"Original answers\",\n",
    "            x = [\"A\", \"B\", \"C\"],\n",
    "            y = [og_answers[0], og_answers[1], og_answers[2]],\n",
    "            customdata = [n_original, n_original, n_original],\n",
    "            hovertemplate = \"Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>\",\n",
    "            marker_color = \"rgb(26, 118, 255)\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    fig.update_layout(\n",
    "    barmode = 'group',\n",
    "    xaxis = dict(\n",
    "        title = \"Answer options\",  \n",
    "        title_font=dict(size=18),  \n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title=\"Share (%)\",  \n",
    "        title_font=dict(size=18), \n",
    "    ),\n",
    "    title = dict(\n",
    "        text=f\"Distribution of answers for temperature {temperature}, using model {model}\",\n",
    "        x = 0.5, # Center alignment horizontally\n",
    "        y = 0.87,  # Vertical alignment\n",
    "        font=dict(size=22),  \n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=1.01,  \n",
    "        y=0.9,\n",
    "        font=dict(family='Arial', size=12, color='black'),\n",
    "        bordercolor='black',  \n",
    "        borderwidth=2,  \n",
    "    ),\n",
    "    bargap = 0.3  # Gap between temperature values\n",
    ")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          100,
          100,
          100
         ],
         "hovertemplate": "Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>",
         "marker": {
          "color": "rgb(55, 83, 109)"
         },
         "name": "Model answers",
         "type": "bar",
         "x": [
          "p(A)",
          "p(B)",
          "p(C)"
         ],
         "y": [
          0,
          0,
          100
         ]
        },
        {
         "customdata": [
          100,
          100,
          100
         ],
         "hovertemplate": "Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>",
         "marker": {
          "color": "rgb(26, 118, 255)"
         },
         "name": "Original answers",
         "type": "bar",
         "x": [
          "p(A)",
          "p(B)",
          "p(C)"
         ],
         "y": [
          16,
          0,
          84
         ]
        }
       ],
       "layout": {
        "bargap": 0.3,
        "barmode": "group",
        "legend": {
         "bordercolor": "black",
         "borderwidth": 2,
         "font": {
          "color": "black",
          "family": "Arial",
          "size": 12
         },
         "x": 1.01,
         "y": 0.9
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 22
         },
         "text": "Distribution of answers for temperature 0.0, using model gpt-3.5-turbo",
         "x": 0.5,
         "y": 0.87
        },
        "xaxis": {
         "title": {
          "font": {
           "size": 18
          },
          "text": "Answer options"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 18
          },
          "text": "Probability (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DE_plot_results(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
