{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Utility 3 \n",
    "\n",
    "This notebook aims to recreate some of the empirical findings of Thaler, R. (1985). Mental accounting and consumer choice. Marketing Science, 4(3), 199-214. \n",
    "Specifically we are interested in whether LLMs' responses are similar to the original responses in **section 3** of the paper, regarding the Hockey Ticket Question.\n",
    "However, this time, we will change the numbers mentioned in the prompts. (Anchoring heuristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In order to run this notebook an openAI API key, as well as Replicate API token are required.  \n",
    "Further they have to be set as environment variables named OPENAI_API_KEY and REPLICATE_API_TOKEN respectively.\n",
    "\n",
    "Throughout the process of this project, adjustments have been made to this notebook, therefore the original outputs are no longer included.   \n",
    "For test purposes, the notebook was re-run with a very low number of iterations per prompt and every export of prompts, dictionaries or results was commented out.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import replicate\n",
    "from ast import literal_eval\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get openAI API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Setting up prompts for the experiment\n",
    "\n",
    "\n",
    "\n",
    "- LLMs used in the experiment:\n",
    "    - GPT-3.5-Turbo         (ID = 1)\n",
    "    - GPT-4-1106-Preview    (ID = 2)\n",
    "    - LLama-70b             (ID = 3)\n",
    "\n",
    "We can differentiate between the following scenario combinations:\n",
    "\n",
    "- Actual ticket price:\n",
    "    - $5 * pi                (ID = 1)\n",
    "    - $5 * 10                (ID = 2)\n",
    "\n",
    "- Initial costs:\n",
    "    - free                  (ID = 1)\n",
    "    - actual price          (ID = 2)\n",
    "    - double actual price   (ID = 3)\n",
    "- Current market price:\n",
    "    - actual price                (ID = 1)\n",
    "    - double actual price         (ID = 2)\n",
    "- Selling to:\n",
    "    - Friend                (ID = 1)\n",
    "    - Stranger              (ID = 2)\n",
    "\n",
    "\n",
    "\n",
    "Similar to the Prospect Theory and Decoy Effect notebooks, we will use experiment IDs to run the study. The IDs will be constructed as:\n",
    "\n",
    "*TU_model__actualprice_initialcosts_currentprice_buyer*\n",
    "\n",
    "Therefore, TU3_2_2_2_1_2 would mean we used GPT-4-1106-Preview, an actual ticket price of $50, initial costs of $50, a current market price of $50 as well and we are selling to a stranger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original price from study\n",
    "original_price = 5\n",
    "actual_price = np.round(original_price * np.pi,2) # to give odd number \n",
    "\n",
    "# Set up list of initial costs\n",
    "initial_costs = [\"but you were given your tickets for free by a friend.\", \"which is what you paid for each ticket.\", f\"but you paid ${actual_price * 2} each for your tickets when you bought them.\"]\n",
    "\n",
    "# Set up list of current ticket prices\n",
    "orientation_prices = [f\"${actual_price}\", f\"${actual_price * 2}\"]\n",
    "\n",
    "# Set up list of potential buyers in a scenario\n",
    "potential_buyers = [\"friend?\", \"stranger?\"]\n",
    "\n",
    "TU3_prompts_pi = []\n",
    "for costs in initial_costs:\n",
    "    for orientation_price in orientation_prices:\n",
    "        for potential_buyer in potential_buyers:\n",
    "            prompt = f\"\"\"Imagine that you are going to a soldout Cornell hockey playoff game, and you have an extra ticket to sell or give away. The price marked on the ticket is ${actual_price} {costs}\n",
    "            You get to the game early to make sure you get rid of the ticket. An informal survey of people selling tickets indicates that the going price is {orientation_price}. \n",
    "            You find someone who wants the ticket and takes out his wallet to pay you. He asks, how much you want for the ticket. \n",
    "            Assume that there is no law against charging a price higher than that marked on the ticket. What price do you ask for, if he is a {potential_buyer}\"\"\"\n",
    "            TU3_prompts_pi.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original price from study\n",
    "original_price = 5\n",
    "actual_price = original_price * 10 \n",
    "\n",
    "# Set up list of initial costs\n",
    "initial_costs = [\"but you were given your tickets for free by a friend.\", \"which is what you paid for each ticket.\", f\"but you paid ${actual_price * 2} each for your tickets when you bought them.\"]\n",
    "\n",
    "# Set up list of current ticket prices\n",
    "orientation_prices = [f\"{actual_price}\", f\"{actual_price * 2}\"]\n",
    "\n",
    "# Set up list of potential buyers in a scenario\n",
    "potential_buyers = [\"friend?\", \"stranger?\"]\n",
    "\n",
    "TU3_prompts_10 = []\n",
    "for costs in initial_costs:\n",
    "    for orientation_price in orientation_prices:\n",
    "        for potential_buyer in potential_buyers:\n",
    "            prompt = f\"\"\"Imagine that you are going to a soldout Cornell hockey playoff game, and you have an extra ticket to sell or give away. The price marked on the ticket is ${actual_price} {costs}\n",
    "            You get to the game early to make sure you get rid of the ticket. An informal survey of people selling tickets indicates that the going price is ${orientation_price}. \n",
    "            You find someone who wants the ticket and takes out his wallet to pay you. He asks, how much you want for the ticket. \n",
    "            Assume that there is no law against charging a price higher than that marked on the ticket. What price do you ask for, if he is a {potential_buyer}\"\"\"\n",
    "            TU3_prompts_10.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prompts for use in Dashboard\n",
    "TU3_prompts = TU3_prompts_pi + TU3_prompts_10\n",
    "#with open('Dashboard/src/data/Input/TU3_prompts.pkl', 'wb') as f:\n",
    "#    pickle.dump(TU3_prompts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TU3_prompts[0]: 5 x pi, free, 5 x pi, friend -> **_1_1_1_1** (Configuration 1)\n",
    "- TU3_prompts[1]: 5 x pi, free, 5 x pi, stranger -> **_1_1_1_2** (Configuration 2)\n",
    "- TU3_prompts[2]: 5 x pi, free, 5 x pi x 2, friend -> **_1_1_2_1** (Configuration 3)\n",
    "- TU3_prompts[3]: 5 x pi, free, 5 x pi x 2, stranger -> **_1_1_2_2** (Configuration 4)\n",
    "- TU3_prompts[4]: 5 x pi, 5 x pi, 5 x pi, friend -> **_1_2_1_1** (Configuration 5) \n",
    "- TU3_prompts[5]: 5 x pi, 5 x pi, 5 x pi, stranger -> **_1_2_1_2** (Configuration 6)\n",
    "- TU3_prompts[6]: 5 x pi, 5 x pi, 5 x pi x 2, friend ->**_1_2_2_1** (Configuration 7)\n",
    "- TU3_prompts[7]: 5 x pi, 5 x pi, 5 x pi x 2, stranger ->**_1_2_2_2** (Configuration 8)\n",
    "- TU3_prompts[8]: 5 x pi, 5 x pi x 2, 5 x pi, friend ->**_1_3_1_1** (Configuration 9)\n",
    "- TU3_prompts[9]: 5 x pi, 5 x pi x 2, 5 x pi, stranger ->**_1_3_1_2** (Configuration 10)\n",
    "- TU3_prompts[10]: 5 x pi, 5 x pi x 2, 5 x pi x 2x friend -> **_1_3_2_1** (Configuration 11)\n",
    "- TU3_prompts[11]: 5 x pi, 5 x pi x 2, 5 x pi x 2x stranger -> **_1_3_2_2** (Configuration 12)\n",
    "- TU3_prompts[12]: 50, free, 50, friend -> **_2_1_1_1** (Configuration 13)\n",
    "- TU3_prompts[13]: 50, free, 50, stranger -> **_2_1_1_2** (Configuration 14)\n",
    "- TU3_prompts[14]: 50, free, 100, friend -> **_2_1_2_1** (Configuration 15)\n",
    "- TU3_prompts[15]: 50, free, 100, stranger -> **_2_1_2_2**(Configuration 16)\n",
    "- TU_prompts[16]: 50, 50, 50, friend -> **_2_2_1_1** (Configuration 17)\n",
    "- TU_prompts[17]: 50, 50, 50, stranger -> **_2_2_1_2** (Configuration 18)\n",
    "- TU_prompts[18]: 50, 50, 100, friend -> **_2_2_2_1** (Configuration 19)\n",
    "- TU_prompts[19]: 50, 50, 100, stranger -> **_2_2_2_2** (Configuration 20)\n",
    "- TU_prompts[20]: 50, 100, 50, friend -> **_2_3_1_1** (Configuration 21)\n",
    "- TU_prompts[21]: 50, 100, 50, stranger -> **_2_3_1_2** (Configuration 22)\n",
    "- TU_prompts[22]: 50, 100, 100, friend -> **_2_3_2_1**(Configuration 23)\n",
    "- TU_prompts[23]: 50, 100, 100, stranger -> **_2_3_2_2** (Configuration 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Dictionaries to extract information about the different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to look up prompt for a given experiment id. key: experiment id, value: prompt\n",
    "TU3_experiment_prompts_dict = {\n",
    "    \"TU3_1_1_1_1_1\": TU3_prompts[0],\n",
    "    \"TU3_1_1_1_1_2\": TU3_prompts[1],\n",
    "    \"TU3_1_1_1_2_1\": TU3_prompts[2],\n",
    "    \"TU3_1_1_1_2_2\": TU3_prompts[3],\n",
    "    \"TU3_1_1_2_1_1\": TU3_prompts[4],\n",
    "    \"TU3_1_1_2_1_2\": TU3_prompts[5],\n",
    "    \"TU3_1_1_2_2_1\": TU3_prompts[6],\n",
    "    \"TU3_1_1_2_2_2\": TU3_prompts[7],\n",
    "    \"TU3_1_1_3_1_1\": TU3_prompts[8],\n",
    "    \"TU3_1_1_3_1_2\": TU3_prompts[9],\n",
    "    \"TU3_1_1_3_2_1\": TU3_prompts[10],\n",
    "    \"TU3_1_1_3_2_2\": TU3_prompts[11],\n",
    "    \"TU3_1_2_1_1_1\": TU3_prompts[12],\n",
    "    \"TU3_1_2_1_1_2\": TU3_prompts[13],\n",
    "    \"TU3_1_2_1_2_1\": TU3_prompts[14],\n",
    "    \"TU3_1_2_1_2_2\": TU3_prompts[15],\n",
    "    \"TU3_1_2_2_1_1\": TU3_prompts[16],\n",
    "    \"TU3_1_2_2_1_2\": TU3_prompts[17],\n",
    "    \"TU3_1_2_2_2_1\": TU3_prompts[18],\n",
    "    \"TU3_1_2_2_2_2\": TU3_prompts[19],\n",
    "    \"TU3_1_2_3_1_1\": TU3_prompts[20],\n",
    "    \"TU3_1_2_3_1_2\": TU3_prompts[21],\n",
    "    \"TU3_1_2_3_2_1\": TU3_prompts[22],\n",
    "    \"TU3_1_2_3_2_2\": TU3_prompts[23],\n",
    "    \"TU3_2_1_1_1_1\": TU3_prompts[0],\n",
    "    \"TU3_2_1_1_1_2\": TU3_prompts[1],\n",
    "    \"TU3_2_1_1_2_1\": TU3_prompts[2],\n",
    "    \"TU3_2_1_1_2_2\": TU3_prompts[3],\n",
    "    \"TU3_2_1_2_1_1\": TU3_prompts[4],\n",
    "    \"TU3_2_1_2_1_2\": TU3_prompts[5],\n",
    "    \"TU3_2_1_2_2_1\": TU3_prompts[6],\n",
    "    \"TU3_2_1_2_2_2\": TU3_prompts[7],\n",
    "    \"TU3_2_1_3_1_1\": TU3_prompts[8],\n",
    "    \"TU3_2_1_3_1_2\": TU3_prompts[9],\n",
    "    \"TU3_2_1_3_2_1\": TU3_prompts[10],\n",
    "    \"TU3_2_1_3_2_2\": TU3_prompts[11],\n",
    "    \"TU3_2_2_1_1_1\": TU3_prompts[12],\n",
    "    \"TU3_2_2_1_1_2\": TU3_prompts[13],\n",
    "    \"TU3_2_2_1_2_1\": TU3_prompts[14],\n",
    "    \"TU3_2_2_1_2_2\": TU3_prompts[15],\n",
    "    \"TU3_2_2_2_1_1\": TU3_prompts[16],\n",
    "    \"TU3_2_2_2_1_2\": TU3_prompts[17],\n",
    "    \"TU3_2_2_2_2_1\": TU3_prompts[18],\n",
    "    \"TU3_2_2_2_2_2\": TU3_prompts[19],\n",
    "    \"TU3_2_2_3_1_1\": TU3_prompts[20],\n",
    "    \"TU3_2_2_3_1_2\": TU3_prompts[21],\n",
    "    \"TU3_2_2_3_2_1\": TU3_prompts[22],\n",
    "    \"TU3_2_2_3_2_2\": TU3_prompts[23],\n",
    "    \"TU3_3_1_1_1_1\": TU3_prompts[0],\n",
    "    \"TU3_3_1_1_1_2\": TU3_prompts[1],\n",
    "    \"TU3_3_1_1_2_1\": TU3_prompts[2],\n",
    "    \"TU3_3_1_1_2_2\": TU3_prompts[3],\n",
    "    \"TU3_3_1_2_1_1\": TU3_prompts[4],\n",
    "    \"TU3_3_1_2_1_2\": TU3_prompts[5],\n",
    "    \"TU3_3_1_2_2_1\": TU3_prompts[6],\n",
    "    \"TU3_3_1_2_2_2\": TU3_prompts[7],\n",
    "    \"TU3_3_1_3_1_1\": TU3_prompts[8],\n",
    "    \"TU3_3_1_3_1_2\": TU3_prompts[9],\n",
    "    \"TU3_3_1_3_2_1\": TU3_prompts[10],\n",
    "    \"TU3_3_1_3_2_2\": TU3_prompts[11],\n",
    "    \"TU3_3_2_1_1_1\": TU3_prompts[12],\n",
    "    \"TU3_3_2_1_1_2\": TU3_prompts[13],\n",
    "    \"TU3_3_2_1_2_1\": TU3_prompts[14],\n",
    "    \"TU3_3_2_1_2_2\": TU3_prompts[15],\n",
    "    \"TU3_3_2_2_1_1\": TU3_prompts[16],\n",
    "    \"TU3_3_2_2_1_2\": TU3_prompts[17],\n",
    "    \"TU3_3_2_2_2_1\": TU3_prompts[18],\n",
    "    \"TU3_3_2_2_2_2\": TU3_prompts[19],\n",
    "    \"TU3_3_2_3_1_1\": TU3_prompts[20],\n",
    "    \"TU3_3_2_3_1_2\": TU3_prompts[21],\n",
    "    \"TU3_3_2_3_2_1\": TU3_prompts[22],\n",
    "    \"TU3_3_2_3_2_2\": TU3_prompts[23],    \n",
    "}\n",
    "\n",
    "# Dictionary to look up model for a given experiment id. key: experiment id, value: model\n",
    "TU3_model_dict = {\n",
    "    \"TU3_1_1_1_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_1_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_1_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_1_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_2_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_2_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_2_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_2_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_3_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_3_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_3_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_1_3_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_1_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_1_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_1_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_1_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_2_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_2_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_2_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_2_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_3_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_3_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_3_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_1_2_3_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU3_2_1_1_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_1_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_1_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_1_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_2_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_2_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_2_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_2_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_3_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_3_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_3_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_1_3_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_1_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_1_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_1_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_1_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_2_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_2_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_2_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_2_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_3_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_3_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_3_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_2_2_3_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU3_3_1_1_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_1_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_1_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_1_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_2_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_2_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_2_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_2_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_3_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_3_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_3_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_1_3_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_1_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_1_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_1_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_1_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_2_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_2_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_2_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_2_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_3_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_3_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_3_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU3_3_2_3_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",    \n",
    "}\n",
    "\n",
    "# Dictionary to look up prompt id for a given experiment id. key: experiment id, value: prompt id\n",
    "TU3_prompt_ids_dict = {\n",
    "    \"TU3_1_1_1_1_1\": \"TU3_prompts[0]\",\n",
    "    \"TU3_1_1_1_1_2\": \"TU3_prompts[1]\",\n",
    "    \"TU3_1_1_1_2_1\": \"TU3_prompts[2]\",\n",
    "    \"TU3_1_1_1_2_2\": \"TU3_prompts[3]\",\n",
    "    \"TU3_1_1_2_1_1\": \"TU3_prompts[4]\",\n",
    "    \"TU3_1_1_2_1_2\": \"TU3_prompts[5]\",\n",
    "    \"TU3_1_1_2_2_1\": \"TU3_prompts[6]\",\n",
    "    \"TU3_1_1_2_2_2\": \"TU3_prompts[7]\",\n",
    "    \"TU3_1_1_3_1_1\": \"TU3_prompts[8]\",\n",
    "    \"TU3_1_1_3_1_2\": \"TU3_prompts[9]\",\n",
    "    \"TU3_1_1_3_2_1\": \"TU3_prompts[10]\",\n",
    "    \"TU3_1_1_3_2_2\": \"TU3_prompts[11]\",\n",
    "    \"TU3_1_2_1_1_1\": \"TU3_prompts[12]\",\n",
    "    \"TU3_1_2_1_1_2\": \"TU3_prompts[13]\",\n",
    "    \"TU3_1_2_1_2_1\": \"TU3_prompts[14]\",\n",
    "    \"TU3_1_2_1_2_2\": \"TU3_prompts[15]\",\n",
    "    \"TU3_1_2_2_1_1\": \"TU3_prompts[16]\",\n",
    "    \"TU3_1_2_2_1_2\": \"TU3_prompts[17]\",\n",
    "    \"TU3_1_2_2_2_1\": \"TU3_prompts[18]\",\n",
    "    \"TU3_1_2_2_2_2\": \"TU3_prompts[19]\",\n",
    "    \"TU3_1_2_3_1_1\": \"TU3_prompts[20]\",\n",
    "    \"TU3_1_2_3_1_2\": \"TU3_prompts[21]\",\n",
    "    \"TU3_1_2_3_2_1\": \"TU3_prompts[22]\",\n",
    "    \"TU3_1_2_3_2_2\": \"TU3_prompts[23]\",\n",
    "    \"TU3_2_1_1_1_1\": \"TU3_prompts[0]\",\n",
    "    \"TU3_2_1_1_1_2\": \"TU3_prompts[1]\",\n",
    "    \"TU3_2_1_1_2_1\": \"TU3_prompts[2]\",\n",
    "    \"TU3_2_1_1_2_2\": \"TU3_prompts[3]\",\n",
    "    \"TU3_2_1_2_1_1\": \"TU3_prompts[4]\",\n",
    "    \"TU3_2_1_2_1_2\": \"TU3_prompts[5]\",\n",
    "    \"TU3_2_1_2_2_1\": \"TU3_prompts[6]\",\n",
    "    \"TU3_2_1_2_2_2\": \"TU3_prompts[7]\",\n",
    "    \"TU3_2_1_3_1_1\": \"TU3_prompts[8]\",\n",
    "    \"TU3_2_1_3_1_2\": \"TU3_prompts[9]\",\n",
    "    \"TU3_2_1_3_2_1\": \"TU3_prompts[10]\",\n",
    "    \"TU3_2_1_3_2_2\": \"TU3_prompts[11]\",\n",
    "    \"TU3_2_2_1_1_1\": \"TU3_prompts[12]\",\n",
    "    \"TU3_2_2_1_1_2\": \"TU3_prompts[13]\",\n",
    "    \"TU3_2_2_1_2_1\": \"TU3_prompts[14]\",\n",
    "    \"TU3_2_2_1_2_2\": \"TU3_prompts[15]\",\n",
    "    \"TU3_2_2_2_1_1\": \"TU3_prompts[16]\",\n",
    "    \"TU3_2_2_2_1_2\": \"TU3_prompts[17]\",\n",
    "    \"TU3_2_2_2_2_1\": \"TU3_prompts[18]\",\n",
    "    \"TU3_2_2_2_2_2\": \"TU3_prompts[19]\",\n",
    "    \"TU3_2_2_3_1_1\": \"TU3_prompts[20]\",\n",
    "    \"TU3_2_2_3_1_2\": \"TU3_prompts[21]\",\n",
    "    \"TU3_2_2_3_2_1\": \"TU3_prompts[22]\",\n",
    "    \"TU3_2_2_3_2_2\": \"TU3_prompts[23]\",\n",
    "    \"TU3_3_1_1_1_1\": \"TU3_prompts[0]\",\n",
    "    \"TU3_3_1_1_1_2\": \"TU3_prompts[1]\",\n",
    "    \"TU3_3_1_1_2_1\": \"TU3_prompts[2]\",\n",
    "    \"TU3_3_1_1_2_2\": \"TU3_prompts[3]\",\n",
    "    \"TU3_3_1_2_1_1\": \"TU3_prompts[4]\",\n",
    "    \"TU3_3_1_2_1_2\": \"TU3_prompts[5]\",\n",
    "    \"TU3_3_1_2_2_1\": \"TU3_prompts[6]\",\n",
    "    \"TU3_3_1_2_2_2\": \"TU3_prompts[7]\",\n",
    "    \"TU3_3_1_3_1_1\": \"TU3_prompts[8]\",\n",
    "    \"TU3_3_1_3_1_2\": \"TU3_prompts[9]\",\n",
    "    \"TU3_3_1_3_2_1\": \"TU3_prompts[10]\",\n",
    "    \"TU3_3_1_3_2_2\": \"TU3_prompts[11]\",\n",
    "    \"TU3_3_2_1_1_1\": \"TU3_prompts[12]\",\n",
    "    \"TU3_3_2_1_1_2\": \"TU3_prompts[13]\",\n",
    "    \"TU3_3_2_1_2_1\": \"TU3_prompts[14]\",\n",
    "    \"TU3_3_2_1_2_2\": \"TU3_prompts[15]\",\n",
    "    \"TU3_3_2_2_1_1\": \"TU3_prompts[16]\",\n",
    "    \"TU3_3_2_2_1_2\": \"TU3_prompts[17]\",\n",
    "    \"TU3_3_2_2_2_1\": \"TU3_prompts[18]\",\n",
    "    \"TU3_3_2_2_2_2\": \"TU3_prompts[19]\",\n",
    "    \"TU3_3_2_3_1_1\": \"TU3_prompts[20]\",\n",
    "    \"TU3_3_2_3_1_2\": \"TU3_prompts[21]\",\n",
    "    \"TU3_3_2_3_2_1\": \"TU3_prompts[22]\",\n",
    "    \"TU3_3_2_3_2_2\": \"TU3_prompts[23]\",    \n",
    "}\n",
    "\n",
    "# Dictionary to look up actual priced marked on ticket for a given experiment id. key: experiment id, value: actual price\n",
    "TU3_actual_price_dict = {\n",
    "    \"TU3_1_1_1_1_1\": 15.71,\n",
    "    \"TU3_1_1_1_1_2\": 15.71,\n",
    "    \"TU3_1_1_1_2_1\": 15.71,\n",
    "    \"TU3_1_1_1_2_2\": 15.71,\n",
    "    \"TU3_1_1_2_1_1\": 15.71,\n",
    "    \"TU3_1_1_2_1_2\": 15.71,\n",
    "    \"TU3_1_1_2_2_1\": 15.71,\n",
    "    \"TU3_1_1_2_2_2\": 15.71,\n",
    "    \"TU3_1_1_3_1_1\": 15.71,\n",
    "    \"TU3_1_1_3_1_2\": 15.71,\n",
    "    \"TU3_1_1_3_2_1\": 15.71,\n",
    "    \"TU3_1_1_3_2_2\": 15.71,\n",
    "    \"TU3_1_2_1_1_1\": 50,\n",
    "    \"TU3_1_2_1_1_2\": 50,\n",
    "    \"TU3_1_2_1_2_1\": 50,\n",
    "    \"TU3_1_2_1_2_2\": 50,\n",
    "    \"TU3_1_2_2_1_1\": 50,\n",
    "    \"TU3_1_2_2_1_2\": 50,\n",
    "    \"TU3_1_2_2_2_1\": 50,\n",
    "    \"TU3_1_2_2_2_2\": 50,\n",
    "    \"TU3_1_2_3_1_1\": 50,\n",
    "    \"TU3_1_2_3_1_2\": 50,\n",
    "    \"TU3_1_2_3_2_1\": 50,\n",
    "    \"TU3_1_2_3_2_2\": 50,\n",
    "    \"TU3_2_1_1_1_1\": 15.71,\n",
    "    \"TU3_2_1_1_1_2\": 15.71,\n",
    "    \"TU3_2_1_1_2_1\": 15.71,\n",
    "    \"TU3_2_1_1_2_2\": 15.71,\n",
    "    \"TU3_2_1_2_1_1\": 15.71,\n",
    "    \"TU3_2_1_2_1_2\": 15.71,\n",
    "    \"TU3_2_1_2_2_1\": 15.71,\n",
    "    \"TU3_2_1_2_2_2\": 15.71,\n",
    "    \"TU3_2_1_3_1_1\": 15.71,\n",
    "    \"TU3_2_1_3_1_2\": 15.71,\n",
    "    \"TU3_2_1_3_2_1\": 15.71,\n",
    "    \"TU3_2_1_3_2_2\": 15.71,\n",
    "    \"TU3_2_2_1_1_1\": 50,\n",
    "    \"TU3_2_2_1_1_2\": 50,\n",
    "    \"TU3_2_2_1_2_1\": 50,\n",
    "    \"TU3_2_2_1_2_2\": 50,\n",
    "    \"TU3_2_2_2_1_1\": 50,\n",
    "    \"TU3_2_2_2_1_2\": 50,\n",
    "    \"TU3_2_2_2_2_1\": 50,\n",
    "    \"TU3_2_2_2_2_2\": 50,\n",
    "    \"TU3_2_2_3_1_1\": 50,\n",
    "    \"TU3_2_2_3_1_2\": 50,\n",
    "    \"TU3_2_2_3_2_1\": 50,\n",
    "    \"TU3_2_2_3_2_2\": 50,\n",
    "    \"TU3_3_1_1_1_1\": 15.71,\n",
    "    \"TU3_3_1_1_1_2\": 15.71,\n",
    "    \"TU3_3_1_1_2_1\": 15.71,\n",
    "    \"TU3_3_1_1_2_2\": 15.71,\n",
    "    \"TU3_3_1_2_1_1\": 15.71,\n",
    "    \"TU3_3_1_2_1_2\": 15.71,\n",
    "    \"TU3_3_1_2_2_1\": 15.71,\n",
    "    \"TU3_3_1_2_2_2\": 15.71,\n",
    "    \"TU3_3_1_3_1_1\": 15.71,\n",
    "    \"TU3_3_1_3_1_2\": 15.71,\n",
    "    \"TU3_3_1_3_2_1\": 15.71,\n",
    "    \"TU3_3_1_3_2_2\": 15.71,\n",
    "    \"TU3_3_2_1_1_1\": 50,\n",
    "    \"TU3_3_2_1_1_2\": 50,\n",
    "    \"TU3_3_2_1_2_1\": 50,\n",
    "    \"TU3_3_2_1_2_2\": 50,\n",
    "    \"TU3_3_2_2_1_1\": 50,\n",
    "    \"TU3_3_2_2_1_2\": 50,\n",
    "    \"TU3_3_2_2_2_1\": 50,\n",
    "    \"TU3_3_2_2_2_2\": 50,\n",
    "    \"TU3_3_2_3_1_1\": 50,\n",
    "    \"TU3_3_2_3_1_2\": 50,\n",
    "    \"TU3_3_2_3_2_1\": 50,\n",
    "    \"TU3_3_2_3_2_2\": 50,    \n",
    "}\n",
    "\n",
    "# Dictionary to look up price paid for the ticket: key: experiment id, value: price paid\n",
    "TU3_initial_costs_dict = {\n",
    "    \"TU3_1_1_1_1_1\": 0,\n",
    "    \"TU3_1_1_1_1_2\": 0,\n",
    "    \"TU3_1_1_1_2_1\": 0,\n",
    "    \"TU3_1_1_1_2_2\": 0,\n",
    "    \"TU3_1_1_2_1_1\": 15.71,\n",
    "    \"TU3_1_1_2_1_2\": 15.71,\n",
    "    \"TU3_1_1_2_2_1\": 15.71,\n",
    "    \"TU3_1_1_2_2_2\": 15.71,\n",
    "    \"TU3_1_1_3_1_1\": 31.42,\n",
    "    \"TU3_1_1_3_1_2\": 31.42,\n",
    "    \"TU3_1_1_3_2_1\": 31.42,\n",
    "    \"TU3_1_1_3_2_2\": 31.42,\n",
    "    \"TU3_1_2_1_1_1\": 0,\n",
    "    \"TU3_1_2_1_1_2\": 0,\n",
    "    \"TU3_1_2_1_2_1\": 0,\n",
    "    \"TU3_1_2_1_2_2\": 0,\n",
    "    \"TU3_1_2_2_1_1\": 50,\n",
    "    \"TU3_1_2_2_1_2\": 50,\n",
    "    \"TU3_1_2_2_2_1\": 50,\n",
    "    \"TU3_1_2_2_2_2\": 50,\n",
    "    \"TU3_1_2_3_1_1\": 100,\n",
    "    \"TU3_1_2_3_1_2\": 100,\n",
    "    \"TU3_1_2_3_2_1\": 100,\n",
    "    \"TU3_1_2_3_2_2\": 100,\n",
    "    \"TU3_2_1_1_1_1\": 0,\n",
    "    \"TU3_2_1_1_1_2\": 0,\n",
    "    \"TU3_2_1_1_2_1\": 0,\n",
    "    \"TU3_2_1_1_2_2\": 0,\n",
    "    \"TU3_2_1_2_1_1\": 15.71,\n",
    "    \"TU3_2_1_2_1_2\": 15.71,\n",
    "    \"TU3_2_1_2_2_1\": 15.71,\n",
    "    \"TU3_2_1_2_2_2\": 15.71,\n",
    "    \"TU3_2_1_3_1_1\": 31.42,\n",
    "    \"TU3_2_1_3_1_2\": 31.42,\n",
    "    \"TU3_2_1_3_2_1\": 31.42,\n",
    "    \"TU3_2_1_3_2_2\": 31.42,\n",
    "    \"TU3_2_2_1_1_1\": 0,\n",
    "    \"TU3_2_2_1_1_2\": 0,\n",
    "    \"TU3_2_2_1_2_1\": 0,\n",
    "    \"TU3_2_2_1_2_2\": 0,\n",
    "    \"TU3_2_2_2_1_1\": 50,\n",
    "    \"TU3_2_2_2_1_2\": 50,\n",
    "    \"TU3_2_2_2_2_1\": 50,\n",
    "    \"TU3_2_2_2_2_2\": 50,\n",
    "    \"TU3_2_2_3_1_1\": 100,\n",
    "    \"TU3_2_2_3_1_2\": 100,\n",
    "    \"TU3_2_2_3_2_1\": 100,\n",
    "    \"TU3_2_2_3_2_2\": 100,\n",
    "    \"TU3_3_1_1_1_1\": 0,\n",
    "    \"TU3_3_1_1_1_2\": 0,\n",
    "    \"TU3_3_1_1_2_1\": 0,\n",
    "    \"TU3_3_1_1_2_2\": 0,\n",
    "    \"TU3_3_1_2_1_1\": 15.71,\n",
    "    \"TU3_3_1_2_1_2\": 15.71,\n",
    "    \"TU3_3_1_2_2_1\": 15.71,\n",
    "    \"TU3_3_1_2_2_2\": 15.71,\n",
    "    \"TU3_3_1_3_1_1\": 31.42,\n",
    "    \"TU3_3_1_3_1_2\": 31.42,\n",
    "    \"TU3_3_1_3_2_1\": 31.42,\n",
    "    \"TU3_3_1_3_2_2\": 31.42,\n",
    "    \"TU3_3_2_1_1_1\": 0,\n",
    "    \"TU3_3_2_1_1_2\": 0,\n",
    "    \"TU3_3_2_1_2_1\": 0,\n",
    "    \"TU3_3_2_1_2_2\": 0,\n",
    "    \"TU3_3_2_2_1_1\": 50,\n",
    "    \"TU3_3_2_2_1_2\": 50,\n",
    "    \"TU3_3_2_2_2_1\": 50,\n",
    "    \"TU3_3_2_2_2_2\": 50,\n",
    "    \"TU3_3_2_3_1_1\": 100,\n",
    "    \"TU3_3_2_3_1_2\": 100,\n",
    "    \"TU3_3_2_3_2_1\": 100,\n",
    "    \"TU3_3_2_3_2_2\": 100,   \n",
    "}  \n",
    "\n",
    "# Dictionary to look up current market price for the ticket. key: experiment id, value: current market price\n",
    "TU3_orientation_price_dict = {\n",
    "    \"TU3_1_1_1_1_1\": 15.71,\n",
    "    \"TU3_1_1_1_1_2\": 15.71,\n",
    "    \"TU3_1_1_1_2_1\": 31.42,\n",
    "    \"TU3_1_1_1_2_2\": 31.42,\n",
    "    \"TU3_1_1_2_1_1\": 15.71,\n",
    "    \"TU3_1_1_2_1_2\": 15.71,\n",
    "    \"TU3_1_1_2_2_1\": 31.42,\n",
    "    \"TU3_1_1_2_2_2\": 31.42,\n",
    "    \"TU3_1_1_3_1_1\": 15.71,\n",
    "    \"TU3_1_1_3_1_2\": 15.71,\n",
    "    \"TU3_1_1_3_2_1\": 31.42,\n",
    "    \"TU3_1_1_3_2_2\": 31.42,\n",
    "    \"TU3_1_2_1_1_1\": 50,\n",
    "    \"TU3_1_2_1_1_2\": 50,\n",
    "    \"TU3_1_2_1_2_1\": 100,\n",
    "    \"TU3_1_2_1_2_2\": 100,\n",
    "    \"TU3_1_2_2_1_1\": 50,\n",
    "    \"TU3_1_2_2_1_2\": 50,\n",
    "    \"TU3_1_2_2_2_1\": 100,\n",
    "    \"TU3_1_2_2_2_2\": 100,\n",
    "    \"TU3_1_2_3_1_1\": 50,\n",
    "    \"TU3_1_2_3_1_2\": 50,\n",
    "    \"TU3_1_2_3_2_1\": 100,\n",
    "    \"TU3_1_2_3_2_2\": 100,\n",
    "    \"TU3_2_1_1_1_1\": 15.71,\n",
    "    \"TU3_2_1_1_1_2\": 15.71,\n",
    "    \"TU3_2_1_1_2_1\": 31.42,\n",
    "    \"TU3_2_1_1_2_2\": 31.42,\n",
    "    \"TU3_2_1_2_1_1\": 15.71,\n",
    "    \"TU3_2_1_2_1_2\": 15.71,\n",
    "    \"TU3_2_1_2_2_1\": 31.42,\n",
    "    \"TU3_2_1_2_2_2\": 31.42,\n",
    "    \"TU3_2_1_3_1_1\": 15.71,\n",
    "    \"TU3_2_1_3_1_2\": 15.71,\n",
    "    \"TU3_2_1_3_2_1\": 31.42,\n",
    "    \"TU3_2_1_3_2_2\": 31.42,\n",
    "    \"TU3_2_2_1_1_1\": 50,\n",
    "    \"TU3_2_2_1_1_2\": 50,\n",
    "    \"TU3_2_2_1_2_1\": 100,\n",
    "    \"TU3_2_2_1_2_2\": 100,\n",
    "    \"TU3_2_2_2_1_1\": 50,\n",
    "    \"TU3_2_2_2_1_2\": 50,\n",
    "    \"TU3_2_2_2_2_1\": 100,\n",
    "    \"TU3_2_2_2_2_2\": 100,\n",
    "    \"TU3_2_2_3_1_1\": 50,\n",
    "    \"TU3_2_2_3_1_2\": 50,\n",
    "    \"TU3_2_2_3_2_1\": 100,\n",
    "    \"TU3_2_2_3_2_2\": 100,\n",
    "    \"TU3_3_1_1_1_1\": 15.71,\n",
    "    \"TU3_3_1_1_1_2\": 15.71,\n",
    "    \"TU3_3_1_1_2_1\": 31.42,\n",
    "    \"TU3_3_1_1_2_2\": 31.42,\n",
    "    \"TU3_3_1_2_1_1\": 15.71,\n",
    "    \"TU3_3_1_2_1_2\": 15.71,\n",
    "    \"TU3_3_1_2_2_1\": 31.42,\n",
    "    \"TU3_3_1_2_2_2\": 31.42,\n",
    "    \"TU3_3_1_3_1_1\": 15.71,\n",
    "    \"TU3_3_1_3_1_2\": 15.71,\n",
    "    \"TU3_3_1_3_2_1\": 31.42,\n",
    "    \"TU3_3_1_3_2_2\": 31.42,\n",
    "    \"TU3_3_2_1_1_1\": 50,\n",
    "    \"TU3_3_2_1_1_2\": 50,\n",
    "    \"TU3_3_2_1_2_1\": 100,\n",
    "    \"TU3_3_2_1_2_2\": 100,\n",
    "    \"TU3_3_2_2_1_1\": 50,\n",
    "    \"TU3_3_2_2_1_2\": 50,\n",
    "    \"TU3_3_2_2_2_1\": 100,\n",
    "    \"TU3_3_2_2_2_2\": 100,\n",
    "    \"TU3_3_2_3_1_1\": 50,\n",
    "    \"TU3_3_2_3_1_2\": 50,\n",
    "    \"TU3_3_2_3_2_1\": 100,\n",
    "    \"TU3_3_2_3_2_2\": 100,    \n",
    "}\n",
    "\n",
    "# Dictionary to look up what configuration was used in an experimnet. key: experiment id, value: configuration\n",
    "TU3_configuration_dict = {\n",
    "    \"TU3_1_1_1_1_1\": 1,\n",
    "    \"TU3_1_1_1_1_2\": 2,\n",
    "    \"TU3_1_1_1_2_1\": 3,\n",
    "    \"TU3_1_1_1_2_2\": 4,\n",
    "    \"TU3_1_1_2_1_1\": 5,\n",
    "    \"TU3_1_1_2_1_2\": 6,\n",
    "    \"TU3_1_1_2_2_1\": 7,\n",
    "    \"TU3_1_1_2_2_2\": 8,\n",
    "    \"TU3_1_1_3_1_1\": 9,\n",
    "    \"TU3_1_1_3_1_2\": 10,\n",
    "    \"TU3_1_1_3_2_1\": 11,\n",
    "    \"TU3_1_1_3_2_2\": 12,\n",
    "    \"TU3_1_2_1_1_1\": 13,\n",
    "    \"TU3_1_2_1_1_2\": 14,\n",
    "    \"TU3_1_2_1_2_1\": 15,\n",
    "    \"TU3_1_2_1_2_2\": 16,\n",
    "    \"TU3_1_2_2_1_1\": 17,\n",
    "    \"TU3_1_2_2_1_2\": 18,\n",
    "    \"TU3_1_2_2_2_1\": 19,\n",
    "    \"TU3_1_2_2_2_2\": 20,\n",
    "    \"TU3_1_2_3_1_1\": 21,\n",
    "    \"TU3_1_2_3_1_2\": 22,\n",
    "    \"TU3_1_2_3_2_1\": 23,\n",
    "    \"TU3_1_2_3_2_2\": 24,\n",
    "    \"TU3_2_1_1_1_1\": 1,\n",
    "    \"TU3_2_1_1_1_2\": 2,\n",
    "    \"TU3_2_1_1_2_1\": 3,\n",
    "    \"TU3_2_1_1_2_2\": 4,\n",
    "    \"TU3_2_1_2_1_1\": 5,\n",
    "    \"TU3_2_1_2_1_2\": 6,\n",
    "    \"TU3_2_1_2_2_1\": 7,\n",
    "    \"TU3_2_1_2_2_2\": 8,\n",
    "    \"TU3_2_1_3_1_1\": 9,\n",
    "    \"TU3_2_1_3_1_2\": 10,\n",
    "    \"TU3_2_1_3_2_1\": 11,\n",
    "    \"TU3_2_1_3_2_2\": 12,\n",
    "    \"TU3_2_2_1_1_1\": 13,\n",
    "    \"TU3_2_2_1_1_2\": 14,\n",
    "    \"TU3_2_2_1_2_1\": 15,\n",
    "    \"TU3_2_2_1_2_2\": 16,\n",
    "    \"TU3_2_2_2_1_1\": 17,\n",
    "    \"TU3_2_2_2_1_2\": 18,\n",
    "    \"TU3_2_2_2_2_1\": 19,\n",
    "    \"TU3_2_2_2_2_2\": 20,\n",
    "    \"TU3_2_2_3_1_1\": 21,\n",
    "    \"TU3_2_2_3_1_2\": 22,\n",
    "    \"TU3_2_2_3_2_1\": 23,\n",
    "    \"TU3_2_2_3_2_2\": 24,\n",
    "    \"TU3_3_1_1_1_1\": 1,\n",
    "    \"TU3_3_1_1_1_2\": 2,\n",
    "    \"TU3_3_1_1_2_1\": 3,\n",
    "    \"TU3_3_1_1_2_2\": 4,\n",
    "    \"TU3_3_1_2_1_1\": 5,\n",
    "    \"TU3_3_1_2_1_2\": 6,\n",
    "    \"TU3_3_1_2_2_1\": 7,\n",
    "    \"TU3_3_1_2_2_2\": 8,\n",
    "    \"TU3_3_1_3_1_1\": 9,\n",
    "    \"TU3_3_1_3_1_2\": 10,\n",
    "    \"TU3_3_1_3_2_1\": 11,\n",
    "    \"TU3_3_1_3_2_2\": 12,\n",
    "    \"TU3_3_2_1_1_1\": 13,\n",
    "    \"TU3_3_2_1_1_2\": 14,\n",
    "    \"TU3_3_2_1_2_1\": 15,\n",
    "    \"TU3_3_2_1_2_2\": 16,\n",
    "    \"TU3_3_2_2_1_1\": 17,\n",
    "    \"TU3_3_2_2_1_2\": 18,\n",
    "    \"TU3_3_2_2_2_1\": 19,\n",
    "    \"TU3_3_2_2_2_2\": 20,\n",
    "    \"TU3_3_2_3_1_1\": 21,\n",
    "    \"TU3_3_2_3_1_2\": 22,\n",
    "    \"TU3_3_2_3_2_1\": 23,\n",
    "    \"TU3_3_2_3_2_2\": 24,    \n",
    "}\n",
    "\n",
    "# Dictionary to look up who we are selling the ticket to. key: experiment id, value: buyer\n",
    "TU3_buyer_dict = {\n",
    "    \"TU3_1_1_1_1_1\": \"friend\",\n",
    "    \"TU3_1_1_1_1_2\": \"stranger\",\n",
    "    \"TU3_1_1_1_2_1\": \"friend\",\n",
    "    \"TU3_1_1_1_2_2\": \"stranger\",\n",
    "    \"TU3_1_1_2_1_1\": \"friend\",\n",
    "    \"TU3_1_1_2_1_2\": \"stranger\",\n",
    "    \"TU3_1_1_2_2_1\": \"friend\",\n",
    "    \"TU3_1_1_2_2_2\": \"stranger\",\n",
    "    \"TU3_1_1_3_1_1\": \"friend\",\n",
    "    \"TU3_1_1_3_1_2\": \"stranger\",\n",
    "    \"TU3_1_1_3_2_1\": \"friend\",\n",
    "    \"TU3_1_1_3_2_2\": \"stranger\",\n",
    "    \"TU3_1_2_1_1_1\": \"friend\",\n",
    "    \"TU3_1_2_1_1_2\": \"stranger\",\n",
    "    \"TU3_1_2_1_2_1\": \"friend\",\n",
    "    \"TU3_1_2_1_2_2\": \"stranger\",\n",
    "    \"TU3_1_2_2_1_1\": \"friend\",\n",
    "    \"TU3_1_2_2_1_2\": \"stranger\",\n",
    "    \"TU3_1_2_2_2_1\": \"friend\",\n",
    "    \"TU3_1_2_2_2_2\": \"stranger\",\n",
    "    \"TU3_1_2_3_1_1\": \"friend\",\n",
    "    \"TU3_1_2_3_1_2\": \"stranger\",\n",
    "    \"TU3_1_2_3_2_1\": \"friend\",\n",
    "    \"TU3_1_2_3_2_2\": \"stranger\",\n",
    "    \"TU3_2_1_1_1_1\": \"friend\",\n",
    "    \"TU3_2_1_1_1_2\": \"stranger\",\n",
    "    \"TU3_2_1_1_2_1\": \"friend\",\n",
    "    \"TU3_2_1_1_2_2\": \"stranger\",\n",
    "    \"TU3_2_1_2_1_1\": \"friend\",\n",
    "    \"TU3_2_1_2_1_2\": \"stranger\",\n",
    "    \"TU3_2_1_2_2_1\": \"friend\",\n",
    "    \"TU3_2_1_2_2_2\": \"stranger\",\n",
    "    \"TU3_2_1_3_1_1\": \"friend\",\n",
    "    \"TU3_2_1_3_1_2\": \"stranger\",\n",
    "    \"TU3_2_1_3_2_1\": \"friend\",\n",
    "    \"TU3_2_1_3_2_2\": \"stranger\",\n",
    "    \"TU3_2_2_1_1_1\": \"friend\",\n",
    "    \"TU3_2_2_1_1_2\": \"stranger\",\n",
    "    \"TU3_2_2_1_2_1\": \"friend\",\n",
    "    \"TU3_2_2_1_2_2\": \"stranger\",\n",
    "    \"TU3_2_2_2_1_1\": \"friend\",\n",
    "    \"TU3_2_2_2_1_2\": \"stranger\",\n",
    "    \"TU3_2_2_2_2_1\": \"friend\",\n",
    "    \"TU3_2_2_2_2_2\": \"stranger\",\n",
    "    \"TU3_2_2_3_1_1\": \"friend\",\n",
    "    \"TU3_2_2_3_1_2\": \"stranger\",\n",
    "    \"TU3_2_2_3_2_1\": \"friend\",\n",
    "    \"TU3_2_2_3_2_2\": \"stranger\",\n",
    "    \"TU3_3_1_1_1_1\": \"friend\",\n",
    "    \"TU3_3_1_1_1_2\": \"stranger\",\n",
    "    \"TU3_3_1_1_2_1\": \"friend\",\n",
    "    \"TU3_3_1_1_2_2\": \"stranger\",\n",
    "    \"TU3_3_1_2_1_1\": \"friend\",\n",
    "    \"TU3_3_1_2_1_2\": \"stranger\",\n",
    "    \"TU3_3_1_2_2_1\": \"friend\",\n",
    "    \"TU3_3_1_2_2_2\": \"stranger\",\n",
    "    \"TU3_3_1_3_1_1\": \"friend\",\n",
    "    \"TU3_3_1_3_1_2\": \"stranger\",\n",
    "    \"TU3_3_1_3_2_1\": \"friend\",\n",
    "    \"TU3_3_1_3_2_2\": \"stranger\",\n",
    "    \"TU3_3_2_1_1_1\": \"friend\",\n",
    "    \"TU3_3_2_1_1_2\": \"stranger\",\n",
    "    \"TU3_3_2_1_2_1\": \"friend\",\n",
    "    \"TU3_3_2_1_2_2\": \"stranger\",\n",
    "    \"TU3_3_2_2_1_1\": \"friend\",\n",
    "    \"TU3_3_2_2_1_2\": \"stranger\",\n",
    "    \"TU3_3_2_2_2_1\": \"friend\",\n",
    "    \"TU3_3_2_2_2_2\": \"stranger\",\n",
    "    \"TU3_3_2_3_1_1\": \"friend\",\n",
    "    \"TU3_3_2_3_1_2\": \"stranger\",\n",
    "    \"TU3_3_2_3_2_1\": \"friend\",\n",
    "    \"TU3_3_2_3_2_2\": \"stranger\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect dicionairies and save for use in dashboard\n",
    "TU3_dictionaries = [TU3_experiment_prompts_dict, TU3_model_dict, TU3_prompt_ids_dict, TU3_actual_price_dict,\n",
    "                     TU3_initial_costs_dict, TU3_orientation_price_dict, TU3_configuration_dict, TU3_buyer_dict]\n",
    "#with open('Dashboard/src/data/Input/TU3_dictionaries.pkl', 'wb') as f:\n",
    " #   pickle.dump(TU3_dictionaries, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Setting up functions to repeatedly prompt the LLMs\n",
    "\n",
    "- Helper function to extract dollar amount of given answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dollar_amounts(answers):\n",
    "    # Only return values that start with \"$\"\n",
    "    valid_prices = [item for item in answers if item.startswith(\"$\") and item[1:].replace(',', '').replace('.', '').isdigit()] # check if everything after $ is a digit, exlcuding commas\n",
    "    # Delete the \"$\" from the beginning of each price\n",
    "    prices = [item.replace('$', '') for item in valid_prices]\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times for OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU3_run_experiment(experiment_id, n, progress_bar, temperature):\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = TU3_model_dict[experiment_id], \n",
    "            max_tokens = 2,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer by only giving a single price in dollars and cents without an explanation.\"},        \n",
    "            {\"role\": \"user\", \"content\": \n",
    "             f\"{TU3_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"}\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU3_model_dict[experiment_id], TU3_actual_price_dict[experiment_id], TU3_initial_costs_dict[experiment_id],\n",
    "                TU3_orientation_price_dict[experiment_id], TU3_configuration_dict[experiment_id], n_observations, valid_prices, TU3_buyer_dict[experiment_id]]\n",
    "    \n",
    "\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for Dashboard (returns dataframe right away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU3_run_experiment_dashboard(experiment_id, n, temperature):\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = TU3_model_dict[experiment_id], \n",
    "            max_tokens = 2,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer by only giving a single price in dollars and cents without an explanation.\"},        \n",
    "            {\"role\": \"user\", \"content\": \n",
    "             f\"{TU3_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"}\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = pd.DataFrame([experiment_id, temperature, TU3_model_dict[experiment_id], TU3_actual_price_dict[experiment_id], TU3_initial_costs_dict[experiment_id],\n",
    "                TU3_orientation_price_dict[experiment_id], TU3_configuration_dict[experiment_id], n_observations, f\"{valid_prices}\", TU3_buyer_dict[experiment_id]])\n",
    "    results = results.set_index(pd.Index([\"Experiment_id\", \"Temperature\", \"Model\", \"Actual_price\", \"Initial_cost\", \"Orientation_price\", \"Configuration\", \"Obs.\", \"Answers\", \"Buyer\"]))\n",
    "    results = results.transpose()\n",
    "    \n",
    "\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times (LLama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU3_run_experiment_llama(experiment_id, n, progress_bar, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            TU3_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\":  \"Answer by only giving a single price in dollars and cents without an explanation.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 10, \n",
    "                \"prompt\": f\"{TU3_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    \n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU3_model_dict[experiment_id], TU3_actual_price_dict[experiment_id], TU3_initial_costs_dict[experiment_id],\n",
    "                TU3_orientation_price_dict[experiment_id], TU3_configuration_dict[experiment_id], n_observations, valid_prices, TU3_buyer_dict[experiment_id]]\n",
    "\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for Dashboard (returns dataframe right away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU3_run_experiment_llama_dashboard(experiment_id, n, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            TU3_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\":  \"Answer by only giving a single price in dollars and cents without an explanation.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 10, \n",
    "                \"prompt\": f\"{TU3_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "   \n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = pd.DataFrame([experiment_id, temperature, TU3_model_dict[experiment_id], TU3_actual_price_dict[experiment_id], TU3_initial_costs_dict[experiment_id],\n",
    "                TU3_orientation_price_dict[experiment_id], TU3_configuration_dict[experiment_id], n_observations, f\"{valid_prices}\", TU3_buyer_dict[experiment_id]])\n",
    "    results = results.set_index(pd.Index([\"Experiment_id\", \"Temperature\", \"Model\", \"Actual_price\", \"Initial_cost\", \"Orientation_price\", \"Configuration\", \"Obs.\", \"Answers\", \"Buyer\"]))\n",
    "    results = results.transpose()\n",
    "    \n",
    "\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop run_experiment() over a list of temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU3_temperature_loop(function, experiment_id, temperature_list = [0.01, 0.5, 1, 1.5, 2], n = 50):\n",
    "    \"\"\"\n",
    "    Function to run an experiment with different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty list for storing results\n",
    "    results_list = []\n",
    "\n",
    "    # Initialize progress bar -> used as input for run_experiment()\n",
    "    progress_bar = tqdm(range(n*len(temperature_list)))\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results = function(experiment_id = experiment_id, n = n, temperature = temperature, progress_bar = progress_bar) \n",
    "        results_list.append(results)\n",
    "       \n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index(\n",
    "        [\"Experiment_id\", \"Temperature\", \"Model\", \"Actual_price\", \"Initial_cost\", \"Orientation_price\", \"Configuration\", \"Obs.\", \"Answers\", \"Buyer\"])).transpose()\n",
    "  \n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"In this run, a total of {n*len(temperature_list)} requests were made using {TU3_prompt_ids_dict[experiment_id]}.\"\n",
    "    # Print information about the experiment\n",
    "    print(check)\n",
    " \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model 1: GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of requests per temperature value\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "results_1_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_1_1_1\", n = N)\n",
    "results_1.append(results_1_1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2 = []\n",
    "results_2_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_1_1_2\", n = N)\n",
    "results_2.append(results_2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3 = []\n",
    "results_3_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_1_2_1\", n = N)\n",
    "results_3.append(results_3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4 = []\n",
    "results_4_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_1_2_2\", n = N)\n",
    "results_4.append(results_4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5 = []\n",
    "results_5_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_2_1_1\", n = N)\n",
    "results_5.append(results_5_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6 = []\n",
    "results_6_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_2_1_2\", n = N)\n",
    "results_6.append(results_6_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7 = []\n",
    "results_7_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_2_2_1\", n = N)\n",
    "results_7.append(results_7_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8 = []\n",
    "results_8_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_2_2_2\", n = N)\n",
    "results_8.append(results_8_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9 = []\n",
    "results_9_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_3_1_1\", n = N)\n",
    "results_9.append(results_9_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:03<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10 = []\n",
    "results_10_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_3_1_2\", n = N)\n",
    "results_10.append(results_10_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:08<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11 = []\n",
    "results_11_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_3_2_1\", n = N)\n",
    "results_11.append(results_11_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12 = []\n",
    "results_12_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_1_3_2_2\", n = N)\n",
    "results_12.append(results_12_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[12].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_13 = []\n",
    "results_13_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_1_1_1\", n = N)\n",
    "results_13.append(results_13_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[13].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_14 = []\n",
    "results_14_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_1_1_2\", n = N)\n",
    "results_14.append(results_14_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[14].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_15 = []\n",
    "results_15_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_1_2_1\", n = N)\n",
    "results_15.append(results_15_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:03<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[15].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_16 = []\n",
    "results_16_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_1_2_2\", n = N)\n",
    "results_16.append(results_16_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[16].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_17 = []\n",
    "results_17_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_2_1_1\", n = N)\n",
    "results_17.append(results_17_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[17].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_18 = []\n",
    "results_18_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_2_1_2\", n = N)\n",
    "results_18.append(results_18_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[18].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_19 = []\n",
    "results_19_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_2_2_1\", n = N)\n",
    "results_19.append(results_19_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[19].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_20 = []\n",
    "results_20_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_2_2_2\", n = N)\n",
    "results_20.append(results_20_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[20].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_21 = []\n",
    "results_21_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_3_1_1\", n = N)\n",
    "results_21.append(results_21_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[21].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_22 = []\n",
    "results_22_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_3_1_2\", n = N)\n",
    "results_22.append(results_22_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[22].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_23 = []\n",
    "results_23_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_3_2_1\", n = N)\n",
    "results_23.append(results_23_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[23].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_24 = []\n",
    "results_24_1 = TU3_temperature_loop(TU3_run_experiment, \"TU3_1_2_3_2_2\", n = N)\n",
    "results_24.append(results_24_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU3_gpt35_results = [results_1_1, results_2_1, results_3_1, results_4_1, results_5_1, results_6_1, results_7_1, results_8_1, results_9_1, results_10_1, results_11_1, results_12_1,\n",
    "                      results_13_1, results_14_1, results_15_1, results_16_1, results_17_1, results_18_1, results_19_1, results_20_1, results_21_1, results_22_1, results_23_1, results_24_1]\n",
    "TU3_gpt35_results_df = pd.concat(TU3_gpt35_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model 2: GPT-4-1106-Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of requests per temperature value\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_1_1_1\", n = N)\n",
    "results_1.append(results_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:09<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_1_1_2\", n = N)\n",
    "results_2.append(results_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:10<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_1_2_1\", n = N)\n",
    "results_3.append(results_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:10<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_1_2_2\", n = N)\n",
    "results_4.append(results_4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:09<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_2_1_1\", n = N)\n",
    "results_5.append(results_5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_2_1_2\", n = N)\n",
    "results_6.append(results_6_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:08<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_2_2_1\", n = N)\n",
    "results_7.append(results_7_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_2_2_2\", n = N)\n",
    "results_8.append(results_8_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:26<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_3_1_1\", n = N)\n",
    "results_9.append(results_9_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_3_1_2\", n = N)\n",
    "results_10.append(results_10_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:09<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_3_2_1\", n = N)\n",
    "results_11.append(results_11_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:08<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_1_3_2_2\", n = N)\n",
    "results_12.append(results_12_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[12].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_13_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_1_1_1\", n = N)\n",
    "results_13.append(results_13_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[13].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_14_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_1_1_2\", n = N)\n",
    "results_14.append(results_14_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:12<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[14].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_15_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_1_2_1\", n = N)\n",
    "results_15.append(results_15_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:12<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[15].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_16_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_1_2_2\", n = N)\n",
    "results_16.append(results_16_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:09<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[16].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_17_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_2_1_1\", n = N)\n",
    "results_17.append(results_17_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:06<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[17].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_18_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_2_1_2\", n = N)\n",
    "results_18.append(results_18_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[18].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_19_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_2_2_1\", n = N)\n",
    "results_19.append(results_19_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:09<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[19].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_20_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_2_2_2\", n = N)\n",
    "results_20.append(results_20_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[20].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_21_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_3_1_1\", n = N)\n",
    "results_21.append(results_21_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:09<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[21].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_22_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_3_1_2\", n = N)\n",
    "results_22.append(results_22_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:08<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[22].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_23_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_3_2_1\", n = N)\n",
    "results_23.append(results_23_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[23].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_24_2 = TU3_temperature_loop(TU3_run_experiment, \"TU3_2_2_3_2_2\", n = N)\n",
    "results_24.append(results_24_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU3_gpt4_results = [results_1_2, results_2_2, results_3_2, results_4_2, results_5_2, results_6_2, results_7_2, results_8_2, results_9_2, results_10_2, results_11_2, results_12_2,\n",
    "                        results_13_2, results_14_2, results_15_2, results_16_2, results_17_2, results_18_2, results_19_2, results_20_2, results_21_2, results_22_2, results_23_2, results_24_2]\n",
    "TU3_gpt4_results_df = pd.concat(TU3_gpt4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model 3: LLama-2-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of requests per temperature value\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:32<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_1_1_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_1_1_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_1_2_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:21<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_1_2_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_2_1_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_2_1_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:22<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_2_2_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_2_2_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:34<00:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_3_1_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_3_1_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_3_2_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:20<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_1_3_2_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:11<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[12].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_13_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_1_1_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:24<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[13].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_14_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_1_1_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:11<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[14].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_15_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_1_2_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:26<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[15].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_16_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_1_2_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:16<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[16].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_17_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_2_1_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:11<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[17].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_18_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_2_1_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:11<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[18].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_19_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_2_2_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:14<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[19].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_20_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_2_2_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:11<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[20].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_21_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_3_1_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:11<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[21].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_22_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_3_1_2\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[22].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_23_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_3_2_1\", n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:12<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 10 requests were made using TU3_prompts[23].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_24_3 = TU3_temperature_loop(TU3_run_experiment_llama, \"TU3_3_2_3_2_2\", n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU3_llama_results = [results_1_3, results_2_3, results_3_3, results_4_3, results_5_3, results_6_3, results_7_3, results_8_3, results_9_3, results_10_3, results_11_3, results_12_3,\n",
    "                        results_13_3, results_14_3, results_15_3, results_16_3, results_17_3, results_18_3, results_19_3, results_20_3, results_21_3, results_22_3, results_23_3, results_24_3]\n",
    "TU3_llama_results_df = pd.concat(TU3_llama_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Collect results and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_id</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Actual_price</th>\n",
       "      <th>Initial_cost</th>\n",
       "      <th>Orientation_price</th>\n",
       "      <th>Configuration</th>\n",
       "      <th>Obs.</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Buyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>[125, 125]</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>[125, 125]</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>[125, 125]</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>[125, 125]</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiment_id Temperature          Model Actual_price Initial_cost  \\\n",
       "0   TU3_1_1_1_1_1        0.01  gpt-3.5-turbo        15.71            0   \n",
       "1   TU3_1_1_1_1_1         0.5  gpt-3.5-turbo        15.71            0   \n",
       "2   TU3_1_1_1_1_1         1.0  gpt-3.5-turbo        15.71            0   \n",
       "3   TU3_1_1_1_1_1         1.5  gpt-3.5-turbo        15.71            0   \n",
       "4   TU3_1_1_1_1_1         2.0  gpt-3.5-turbo        15.71            0   \n",
       "..            ...         ...            ...          ...          ...   \n",
       "0   TU3_3_2_3_2_2        0.01    llama-2-70b           50          100   \n",
       "1   TU3_3_2_3_2_2         0.5    llama-2-70b           50          100   \n",
       "2   TU3_3_2_3_2_2         1.0    llama-2-70b           50          100   \n",
       "3   TU3_3_2_3_2_2         1.5    llama-2-70b           50          100   \n",
       "4   TU3_3_2_3_2_2         2.0    llama-2-70b           50          100   \n",
       "\n",
       "   Orientation_price Configuration Obs.     Answers     Buyer  \n",
       "0              15.71             1    2    [15, 15]    friend  \n",
       "1              15.71             1    2    [15, 15]    friend  \n",
       "2              15.71             1    2    [15, 15]    friend  \n",
       "3              15.71             1    1         [0]    friend  \n",
       "4              15.71             1    2    [15, 15]    friend  \n",
       "..               ...           ...  ...         ...       ...  \n",
       "0                100            24    2  [125, 125]  stranger  \n",
       "1                100            24    2  [125, 125]  stranger  \n",
       "2                100            24    2  [125, 125]  stranger  \n",
       "3                100            24    2  [125, 125]  stranger  \n",
       "4                100            24    0          []  stranger  \n",
       "\n",
       "[360 rows x 10 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine results\n",
    "TU3_results = [TU3_gpt35_results_df, TU3_gpt4_results_df, TU3_llama_results_df]\n",
    "TU3_results_df = pd.concat(TU3_results)\n",
    "\n",
    "\n",
    "# Rename LLama model\n",
    "TU3_results_df['Model'] = TU3_results_df['Model'].replace('meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3', \n",
    "                                  'llama-2-70b')\n",
    "\n",
    "# Display results\n",
    "TU3_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "#TU3_results_df.iloc[:,1:].to_csv(\"Dashboard/src/data/Output/TU3_results_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_id</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Actual_price</th>\n",
       "      <th>Initial_cost</th>\n",
       "      <th>Orientation_price</th>\n",
       "      <th>Configuration</th>\n",
       "      <th>Obs.</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Buyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>['15', '15', '15', '15', '15', '15', '15', '15...</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>['15', '15', '15', '15', '15', '15', '15', '15...</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>['15', '15', '15', '15', '15', '15', '15', '15...</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>['15', '15', '15', '15', '15', '15', '15', '15...</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TU3_1_1_1_1_1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>['15', '15', '15', '15', '15', '0', '16', '5',...</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>['125', '125', '125', '125', '125', '125', '12...</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>['125', '125', '125', '125', '125', '125', '12...</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>['125', '125', '125', '125', '125', '125', '12...</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>['125', '125', '125', '125', '125', '125', '12...</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>TU3_3_2_3_2_2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>['125', '125', '125', '125', '125', '125', '12...</td>\n",
       "      <td>stranger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Experiment_id  Temperature          Model  Actual_price  Initial_cost  \\\n",
       "0    TU3_1_1_1_1_1         0.01  gpt-3.5-turbo         15.71           0.0   \n",
       "1    TU3_1_1_1_1_1         0.50  gpt-3.5-turbo         15.71           0.0   \n",
       "2    TU3_1_1_1_1_1         1.00  gpt-3.5-turbo         15.71           0.0   \n",
       "3    TU3_1_1_1_1_1         1.50  gpt-3.5-turbo         15.71           0.0   \n",
       "4    TU3_1_1_1_1_1         2.00  gpt-3.5-turbo         15.71           0.0   \n",
       "..             ...          ...            ...           ...           ...   \n",
       "355  TU3_3_2_3_2_2         0.01    llama-2-70b         50.00         100.0   \n",
       "356  TU3_3_2_3_2_2         0.50    llama-2-70b         50.00         100.0   \n",
       "357  TU3_3_2_3_2_2         1.00    llama-2-70b         50.00         100.0   \n",
       "358  TU3_3_2_3_2_2         1.50    llama-2-70b         50.00         100.0   \n",
       "359  TU3_3_2_3_2_2         2.00    llama-2-70b         50.00         100.0   \n",
       "\n",
       "     Orientation_price  Configuration  Obs.  \\\n",
       "0                15.71              1   100   \n",
       "1                15.71              1   100   \n",
       "2                15.71              1   100   \n",
       "3                15.71              1    91   \n",
       "4                15.71              1    64   \n",
       "..                 ...            ...   ...   \n",
       "355             100.00             24    50   \n",
       "356             100.00             24    50   \n",
       "357             100.00             24    50   \n",
       "358             100.00             24    50   \n",
       "359             100.00             24    45   \n",
       "\n",
       "                                               Answers     Buyer  \n",
       "0    ['15', '15', '15', '15', '15', '15', '15', '15...    friend  \n",
       "1    ['15', '15', '15', '15', '15', '15', '15', '15...    friend  \n",
       "2    ['15', '15', '15', '15', '15', '15', '15', '15...    friend  \n",
       "3    ['15', '15', '15', '15', '15', '15', '15', '15...    friend  \n",
       "4    ['15', '15', '15', '15', '15', '0', '16', '5',...    friend  \n",
       "..                                                 ...       ...  \n",
       "355  ['125', '125', '125', '125', '125', '125', '12...  stranger  \n",
       "356  ['125', '125', '125', '125', '125', '125', '12...  stranger  \n",
       "357  ['125', '125', '125', '125', '125', '125', '12...  stranger  \n",
       "358  ['125', '125', '125', '125', '125', '125', '12...  stranger  \n",
       "359  ['125', '125', '125', '125', '125', '125', '12...  stranger  \n",
       "\n",
       "[360 rows x 10 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TU3_results = pd.read_csv(\"Dashboard/src/data/Output/TU3_results.csv\")\n",
    "TU3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_price = 15.71\n",
    "initial_cost = 15.71\n",
    "orientation_price = 15.71\n",
    "buyer = \"stranger\"\n",
    "model = \"llama-2-70b\"\n",
    "temperature = 2\n",
    "df = TU3_results[(TU3_results[\"Actual_price\"] == actual_price) & (TU3_results[\"Initial_cost\"] == initial_cost) & (TU3_results[\"Orientation_price\"] == orientation_price)\n",
    "                  & (TU3_results[\"Buyer\"] == buyer) & (TU3_results[\"Model\"] == model) & (TU3_results[\"Temperature\"] == temperature)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU3_plot_results(df):\n",
    "\n",
    "    # Transpose for plotting\n",
    "    df = df.transpose()\n",
    "    # Extract model name from the dataframe\n",
    "    model = df.loc[\"Model\"].iloc[0]\n",
    "    if model == \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\":\n",
    "        model = \"llama-2-70b\"\n",
    "\n",
    "    # Get temperature value \n",
    "    temperature = df.loc[\"Temperature\"].iloc[0]\n",
    "    # Get number of observations \n",
    "    n_observations = df.loc[\"Obs.\"].iloc[0]\n",
    "    # Extract model answers\n",
    "    answers = df.loc[\"Answers\"].apply(literal_eval).iloc[0]\n",
    "    sorted_answers = sorted(answers, key=lambda x: float(x))\n",
    "    numeric_answers = [float(answer) for answer in answers]\n",
    "\n",
    "    # Get number of unique answers\n",
    "    num_unique_answers = len(set(answers))\n",
    "    # Get actual ticker price\n",
    "    actual_price = df.loc[\"Actual_price\"].iloc[0]\n",
    "    # Get current market price\n",
    "    current_price = df.loc[\"Orientation_price\"].iloc[0]\n",
    "    # Get price paid\n",
    "    initial_cost = df.loc[\"Initial_cost\"].iloc[0]\n",
    "    # Get buyer \n",
    "    buyer = df.loc[\"Buyer\"].iloc[0].capitalize()\n",
    "    # Compute mean\n",
    "    mean = np.round(np.mean(numeric_answers),2).astype(str)\n",
    "    median = np.round(np.median(numeric_answers),2).astype(str)\n",
    "   \n",
    "\n",
    "    fig = go.Figure(data = [\n",
    "    go.Histogram(x = sorted_answers,\n",
    "                    customdata = [n_observations] * num_unique_answers,\n",
    "                    hovertemplate = \"Price asked: $%{x} <br>Frequency: %{y}<br>Total answers: %{customdata}<br><extra></extra>\",\n",
    "\n",
    "                    marker_color = \"rgb(55, 83, 109)\",\n",
    "                    name = f\"Actual price: ${actual_price}<br>Initial costs: ${initial_cost}<br>Current price: ${current_price}<br>Buyer: {buyer}<br>Mean: ${mean}<br>Median: ${median}\"),\n",
    "    ])\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            title=\"Price asked ($)\",\n",
    "            titlefont_size=18,\n",
    "            tickfont_size=16,\n",
    "            tickformat=\".2f\",\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Frequency\",\n",
    "            titlefont_size=18,\n",
    "            tickfont_size=16,\n",
    "        ),\n",
    "        title=dict(\n",
    "            text=f\"Distribution of {model}'s answers for temperature {temperature}\",\n",
    "            x=0.45,\n",
    "            y=0.95,\n",
    "            font_size=18,\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1.01,  \n",
    "            y=0.9,\n",
    "            font=dict(family='Arial', size=16, color='black'),\n",
    "            bordercolor='black',  \n",
    "            borderwidth=2,           \n",
    "        ),\n",
    "        showlegend=True,\n",
    "        width=1000,\n",
    "        margin=dict(t=60),\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Show the plot\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          10
         ],
         "hovertemplate": "Price asked: $%{x} <br>Frequency: %{y}<br>Total answers: %{customdata}<br><extra></extra>",
         "marker": {
          "color": "rgb(55, 83, 109)"
         },
         "name": "Actual price: $15.71<br>Initial costs: $0<br>Current price: $15.71<br>Buyer: Friend<br>Mean: $15.0<br>Median: $15.0",
         "type": "histogram",
         "x": [
          "15",
          "15",
          "15",
          "15",
          "15",
          "15",
          "15",
          "15",
          "15",
          "15"
         ]
        }
       ],
       "layout": {
        "legend": {
         "bordercolor": "black",
         "borderwidth": 2,
         "font": {
          "color": "black",
          "family": "Arial",
          "size": 16
         },
         "x": 1.01,
         "y": 0.9
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 18
         },
         "text": "Distribution of gpt-3.5-turbo's answers for temperature 0.5",
         "x": 0.45,
         "y": 0.95
        },
        "width": 1000,
        "xaxis": {
         "tickfont": {
          "size": 16
         },
         "tickformat": ".2f",
         "title": {
          "font": {
           "size": 18
          },
          "text": "Price asked ($)"
         }
        },
        "yaxis": {
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 18
          },
          "text": "Frequency"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TU3_plot_results(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
