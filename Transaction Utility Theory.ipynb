{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Utility Theory\n",
    "\n",
    "This notebook aims to recreate some of the empirical findings of Thaler, R. (1985). Mental accounting and consumer choice. Marketing Science, 4(3), 199-214. \n",
    "Specifically we are interested in whether LLMs' responses are similar to the original responses in **section 3** of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "TBD: <br>\n",
    "Show distribution of all experiment answers, or just $0, $5, $10 and label everything else as \"others\"?\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import replicate\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get openAI API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up prompts for the experiment\n",
    "\n",
    "\n",
    "\n",
    "- LLMs used in the experiment:\n",
    "    - GPT-3.5-Turbo         (ID = 1)\n",
    "    - GPT-4-1106-Preview    (ID = 2)\n",
    "    - LLama-70b             (ID = 3)\n",
    "\n",
    "We can differentiate between the following scenario combinations:\n",
    "\n",
    "- Initial ticket price:\n",
    "    - free                  (ID = 1)\n",
    "    - $5 (as on ticket)     (ID = 2)\n",
    "    - $10                   (ID = 3)\n",
    "- Current market price:\n",
    "    - $5                    (ID = 1)\n",
    "    - $10                   (ID = 2)\n",
    "- Selling to:\n",
    "    - Friend                (ID = 1)\n",
    "    - Stranger              (ID = 2)\n",
    "\n",
    "\n",
    "\n",
    "Similar to the Prospect Theory and Decoy Effect notebooks, we will use experiment IDs to run the study. The IDs will be constructed as:\n",
    "\n",
    "TU_model_initialprice_currentprice_buyer\n",
    "\n",
    "Therefore, TU_2_2_1_2 would mean we used GPT-4-1106-Preview, an initial ticket price of $5, a current market price of $5 as well and we are selling to a stranger.\n",
    "\n",
    "We leave out the information of the respondent being a student in all prompts. From experience, the more concise a prompt is, the better the answer quality. \n",
    "Since the job status/education level is not of interest here, we leave out this information in order to formulate clearer prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list of initial costs\n",
    "initial_costs = [\"but you were given your tickets for free by a friend.\", \"which is what you paid for each ticket.\", \"but you paid $10 each for your tickets when you bought them.\"]\n",
    "\n",
    "# Set up list of current ticket prices\n",
    "orientation_prices = [\"$5\", \"$10\"]\n",
    "\n",
    "# Set up list of potential buyers in a scenario\n",
    "potential_buyers = [\"friend?\", \"stranger?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU_prompts = []\n",
    "for costs in initial_costs:\n",
    "    for orientation_price in orientation_prices:\n",
    "        for potential_buyer in potential_buyers:\n",
    "            prompt = f\"\"\"Imagine that you are going to a soldout Cornell hockey playoff game, and you have an extra ticket to sell or give away. The price marked on the ticket is $5 {costs}\n",
    "            You get to the game early to make sure you get rid of the ticket. An informal survey of people selling tickets indicates that the going price is {orientation_price}. \n",
    "            You find someone who wants the ticket and takes out his wallet to pay you. He asks, how much you want for the ticket. \n",
    "            Assume that there is now law against charging a price higher than that marked on the ticket. What price do you ask for, if he is a {potential_buyer}\"\"\"\n",
    "            TU_prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TU_prompts[0]: free, $5, friend  -> 1_1_1 (Configuration 1)\n",
    "- TU_prompts[1]: free, $5, stranger -> 1_1_2 (Configuration 2)\n",
    "- TU_prompts[2]: free, $10, friend -> 1_2_1 (Configuration 3)\n",
    "- TU_prompts[3]: free, $10, stranger -> 1_2_2 (Configuration 4)\n",
    "- TU_prompts[4]: $5, $5, friend -> 2_1_1 (Configuration 5)\n",
    "- TU_prompts[5]: $5, $5, stranger -> 2_1_2 (Configuration 6)\n",
    "- TU_prompts[6]: $5, $10, friend -> 2_2_1 (Configuration 7)\n",
    "- TU_prompts[7]: $5, $10, stranger -> 2_2_2 (Configuration 8)\n",
    "- TU_prompts[8]: $10, $5, friend -> 3_1_1  (Configuration 9)\n",
    "- TU_prompts[9]: $10, $5, stranger -> 3_1_2 (Configuration 10)\n",
    "- TU_prompts[10]: $10, $10, friend -> 3_2_1 (Configuration 11)\n",
    "- TU_prompts[11]: $10, $10, stranger -> 3_2_2 (Configuration 12)\n",
    "\n",
    "The results of the original experiment are:\n",
    "\n",
    "\n",
    "| Configuration   | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   |\n",
    "|------------------|------|------|------|------|------|------|------|------|------|------|------|------|\n",
    "| $0              | 68%  | 6%   | 65%  | 6%   | 14%  | 0%   | 7%   | 0%   | 0%   | 0%   | 0%   | 0%   |\n",
    "| $5              | 26%  | 77%  | 26%  | 16%  | 79%  | 79%  | 79%  | 14%  | 69%  | 42%  | 15%  | 0%   |\n",
    "| $10             | 3%   | 10%  | 6%   | 58%  | 0%   | 7%   | 4%   | 57%  | 23%  | 46%  | 69%  | 73%  |\n",
    "| Other          | 6%   | 6%   | 3%   | 19%  | 7%   | 14%  | 9%   | 29%  | 8%   | 12%  | 15%  | 27%  |\n",
    "| N              | 31   | 31   | 31   | 31   | 28   | 28   | 28   | 28   | 26   | 26   | 26   | 26   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_results = {\n",
    "    \"og_results_1\" : [68, 26, 3, 6],\n",
    "    \"og_results_2\" : [6, 77, 10, 6],\n",
    "    \"og_results_3\" : [65, 26, 6, 3],\n",
    "    \"og_results_4\" : [6, 16, 58, 19],\n",
    "    \"og_results_5\" : [14, 79, 7, 14],\n",
    "    \"og_results_6\" : [0, 79, 7, 14],\n",
    "    \"og_results_7\" : [7, 79, 4, 9],\n",
    "    \"og_results_8\" : [0, 14, 57, 29],\n",
    "    \"og_results_9\" : [0, 69, 23, 8],\n",
    "    \"og_results_10\" : [0, 42, 46, 12],\n",
    "    \"og_results_11\" : [0, 15, 69, 15],\n",
    "    \"og_results_12\" : [0, 0, 73, 27]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting up instructions the model should abide by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Answer by only giving a single price in dollars and cents without an explanation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all experiment IDs\n",
    "experiment_ids =  [\"TU_1_1_1_1\", \"TU_1_1_1_2\", \"TU_1_1_2_1\", \"TU_1_1_2_2\", \"TU_1_2_1_1\", \"TU_1_2_1_2\", \"TU_1_2_2_1\", \"TU_1_2_2_2\", \"TU_1_3_1_1\", \"TU_1_3_1_2\", \"TU_1_3_2_1\", \"TU_1_3_2_2\",\n",
    "                   \"TU_2_1_1_1\", \"TU_2_1_1_2\", \"TU_2_1_2_1\", \"TU_2_1_2_2\", \"TU_2_2_1_1\", \"TU_2_2_1_2\", \"TU_2_2_2_1\", \"TU_2_2_2_2\", \"TU_2_3_1_1\", \"TU_2_3_1_2\", \"TU_2_3_2_1\", \"TU_2_3_2_2\",\n",
    "                   \"TU_3_1_1_1\", \"TU_3_1_1_2\", \"TU_3_1_2_1\", \"TU_3_1_2_2\", \"TU_3_2_1_1\", \"TU_3_2_1_2\", \"TU_3_2_2_1\", \"TU_3_2_2_2\", \"TU_3_3_1_1\", \"TU_3_3_1_2\", \"TU_3_3_2_1\", \"TU_3_3_2_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries to extract information about the different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to look up prompt for a given experiment id. key: experiment id, value: prompt\n",
    "TU_experiment_prompts_dict = {\n",
    "    \"TU_1_1_1_1\": TU_prompts[0],\n",
    "    \"TU_1_1_1_2\": TU_prompts[1],\n",
    "    \"TU_1_1_2_1\": TU_prompts[2],\n",
    "    \"TU_1_1_2_2\": TU_prompts[3],\n",
    "    \"TU_1_2_1_1\": TU_prompts[4],\n",
    "    \"TU_1_2_1_2\": TU_prompts[5],\n",
    "    \"TU_1_2_2_1\": TU_prompts[6],\n",
    "    \"TU_1_2_2_2\": TU_prompts[7],\n",
    "    \"TU_1_3_1_1\": TU_prompts[8],\n",
    "    \"TU_1_3_1_2\": TU_prompts[9],\n",
    "    \"TU_1_3_2_1\": TU_prompts[10],\n",
    "    \"TU_1_3_2_2\": TU_prompts[11],\n",
    "    \"TU_2_1_1_1\": TU_prompts[0],\n",
    "    \"TU_2_1_1_2\": TU_prompts[1],\n",
    "    \"TU_2_1_2_1\": TU_prompts[2],\n",
    "    \"TU_2_1_2_2\": TU_prompts[3],\n",
    "    \"TU_2_2_1_1\": TU_prompts[4],\n",
    "    \"TU_2_2_1_2\": TU_prompts[5],\n",
    "    \"TU_2_2_2_1\": TU_prompts[6],\n",
    "    \"TU_2_2_2_2\": TU_prompts[7],\n",
    "    \"TU_2_3_1_1\": TU_prompts[8],\n",
    "    \"TU_2_3_1_2\": TU_prompts[9],\n",
    "    \"TU_2_3_2_1\": TU_prompts[10],\n",
    "    \"TU_2_3_2_2\": TU_prompts[11],\n",
    "    \"TU_3_1_1_1\": TU_prompts[0],\n",
    "    \"TU_3_1_1_2\": TU_prompts[1],\n",
    "    \"TU_3_1_2_1\": TU_prompts[2],\n",
    "    \"TU_3_1_2_2\": TU_prompts[3],\n",
    "    \"TU_3_2_1_1\": TU_prompts[4],\n",
    "    \"TU_3_2_1_2\": TU_prompts[5],\n",
    "    \"TU_3_2_2_1\": TU_prompts[6],\n",
    "    \"TU_3_2_2_2\": TU_prompts[7],\n",
    "    \"TU_3_3_1_1\": TU_prompts[8],\n",
    "    \"TU_3_3_1_2\": TU_prompts[9],\n",
    "    \"TU_3_3_2_1\": TU_prompts[10],\n",
    "    \"TU_3_3_2_2\": TU_prompts[11],\n",
    "}\n",
    "\n",
    "# Dictionary to look up which model to use for a given experiment id. key: experiment id, value: model name\n",
    "TU_model_dict = {\n",
    "    \"TU_1_1_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_2_1_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_3_1_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up what prompt was used for a given experiment id. key: experiment id, value: prompt variable name\n",
    "TU_prompt_ids_dict = {\n",
    "    \"TU_1_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_1_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_1_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_1_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_1_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_1_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_1_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_1_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_1_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_1_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_1_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_1_3_2_2\": \"TU_prompts[11]\",\n",
    "    \"TU_2_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_2_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_2_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_2_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_2_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_2_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_2_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_2_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_2_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_2_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_2_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_2_3_2_2\": \"TU_prompts[11]\",\n",
    "    \"TU_3_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_3_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_3_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_3_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_3_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_3_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_3_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_3_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_3_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_3_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_3_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_3_3_2_2\": \"TU_prompts[11]\",\n",
    "    }\n",
    "\n",
    "# Dictionary to look up initital ticket cotsts for a given experiment id. key: experiment id, value: initial costs\n",
    "TU_initial_costs_dict = {\n",
    "    \"TU_1_1_1_1\": 0,\n",
    "    \"TU_1_1_1_2\": 0,\n",
    "    \"TU_1_1_2_1\": 0,\n",
    "    \"TU_1_1_2_2\": 0,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 5,\n",
    "    \"TU_1_2_2_1\": 5,\n",
    "    \"TU_1_2_2_2\": 5,\n",
    "    \"TU_1_3_1_1\": 10,\n",
    "    \"TU_1_3_1_2\": 10,\n",
    "    \"TU_1_3_2_1\": 10,\n",
    "    \"TU_1_3_2_2\": 10,\n",
    "    \"TU_2_1_1_1\": 0,\n",
    "    \"TU_2_1_1_2\": 0,\n",
    "    \"TU_2_1_2_1\": 0,\n",
    "    \"TU_2_1_2_2\": 0,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 5,\n",
    "    \"TU_2_2_2_1\": 5,\n",
    "    \"TU_2_2_2_2\": 5,\n",
    "    \"TU_2_3_1_1\": 10,\n",
    "    \"TU_2_3_1_2\": 10,\n",
    "    \"TU_2_3_2_1\": 10,\n",
    "    \"TU_2_3_2_2\": 10,\n",
    "    \"TU_3_1_1_1\": 0,\n",
    "    \"TU_3_1_1_2\": 0,\n",
    "    \"TU_3_1_2_1\": 0,\n",
    "    \"TU_3_1_2_2\": 0,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 5,\n",
    "    \"TU_3_2_2_1\": 5,\n",
    "    \"TU_3_2_2_2\": 5,\n",
    "    \"TU_3_3_1_1\": 10,\n",
    "    \"TU_3_3_1_2\": 10,\n",
    "    \"TU_3_3_2_1\": 10,\n",
    "    \"TU_3_3_2_2\": 10,\n",
    "    }\n",
    "\n",
    "# Dictionary to look up orientation prices for a given experiment id. key: experiment id, value: orientation price\n",
    "TU_orientation_prices_dict = {\n",
    "    \"TU_1_1_1_1\": 5,\n",
    "    \"TU_1_1_1_2\": 5,\n",
    "    \"TU_1_1_2_1\": 10,\n",
    "    \"TU_1_1_2_2\": 10,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 5,\n",
    "    \"TU_1_2_2_1\": 10,\n",
    "    \"TU_1_2_2_2\": 10,\n",
    "    \"TU_1_3_1_1\": 5,\n",
    "    \"TU_1_3_1_2\": 5,\n",
    "    \"TU_1_3_2_1\": 10,\n",
    "    \"TU_1_3_2_2\": 10,\n",
    "    \"TU_2_1_1_1\": 5,\n",
    "    \"TU_2_1_1_2\": 5,\n",
    "    \"TU_2_1_2_1\": 10,\n",
    "    \"TU_2_1_2_2\": 10,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 5,\n",
    "    \"TU_2_2_2_1\": 10,\n",
    "    \"TU_2_2_2_2\": 10,\n",
    "    \"TU_2_3_1_1\": 5,\n",
    "    \"TU_2_3_1_2\": 5,\n",
    "    \"TU_2_3_2_1\": 10,\n",
    "    \"TU_2_3_2_2\": 10,\n",
    "    \"TU_3_1_1_1\": 5,\n",
    "    \"TU_3_1_1_2\": 5,\n",
    "    \"TU_3_1_2_1\": 10,\n",
    "    \"TU_3_1_2_2\": 10,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 5,\n",
    "    \"TU_3_2_2_1\": 10,\n",
    "    \"TU_3_2_2_2\": 10,\n",
    "    \"TU_3_3_1_1\": 5,\n",
    "    \"TU_3_3_1_2\": 5,\n",
    "    \"TU_3_3_2_1\": 10,\n",
    "    \"TU_3_3_2_2\": 10,\n",
    "    }   \n",
    "\n",
    "# Dictionary to look up potential buyers for a given experiment id. key: experiment id, value: potential buyer\n",
    "TU_buyers_dict = {\n",
    "    \"TU_1_1_1_1\": \"friend\",\n",
    "    \"TU_1_1_1_2\": \"stranger\",\n",
    "    \"TU_1_1_2_1\": \"friend\",\n",
    "    \"TU_1_1_2_2\": \"stranger\",\n",
    "    \"TU_1_2_1_1\": \"friend\",\n",
    "    \"TU_1_2_1_2\": \"stranger\",\n",
    "    \"TU_1_2_2_1\": \"friend\",\n",
    "    \"TU_1_2_2_2\": \"stranger\",\n",
    "    \"TU_1_3_1_1\": \"friend\",\n",
    "    \"TU_1_3_1_2\": \"stranger\",\n",
    "    \"TU_1_3_2_1\": \"friend\",\n",
    "    \"TU_1_3_2_2\": \"stranger\",\n",
    "    \"TU_2_1_1_1\": \"friend\",\n",
    "    \"TU_2_1_1_2\": \"stranger\",\n",
    "    \"TU_2_1_2_1\": \"friend\",\n",
    "    \"TU_2_1_2_2\": \"stranger\",\n",
    "    \"TU_2_2_1_1\": \"friend\",\n",
    "    \"TU_2_2_1_2\": \"stranger\",\n",
    "    \"TU_2_2_2_1\": \"friend\",\n",
    "    \"TU_2_2_2_2\": \"stranger\",\n",
    "    \"TU_2_3_1_1\": \"friend\",\n",
    "    \"TU_2_3_1_2\": \"stranger\",\n",
    "    \"TU_2_3_2_1\": \"friend\",\n",
    "    \"TU_2_3_2_2\": \"stranger\",\n",
    "    \"TU_3_1_1_1\": \"friend\",\n",
    "    \"TU_3_1_1_2\": \"stranger\",\n",
    "    \"TU_3_1_2_1\": \"friend\",\n",
    "    \"TU_3_1_2_2\": \"stranger\",\n",
    "    \"TU_3_2_1_1\": \"friend\",\n",
    "    \"TU_3_2_1_2\": \"stranger\",\n",
    "    \"TU_3_2_2_1\": \"friend\",\n",
    "    \"TU_3_2_2_2\": \"stranger\",\n",
    "    \"TU_3_3_1_1\": \"friend\",\n",
    "    \"TU_3_3_1_2\": \"stranger\",\n",
    "    \"TU_3_3_2_1\": \"friend\",\n",
    "    \"TU_3_3_2_2\": \"stranger\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up original results for a given experiment id. key: experiment id, value: original results\n",
    "TU_results_dict = {\n",
    "    \"TU_1_1_1_1\": [68, 26, 3, 6],\n",
    "    \"TU_1_1_1_2\": [6, 77, 10, 6],\n",
    "    \"TU_1_1_2_1\": [65, 26, 6, 3],\n",
    "    \"TU_1_1_2_2\": [6, 16, 58, 19],\n",
    "    \"TU_1_2_1_1\": [14, 79, 7, 14],\n",
    "    \"TU_1_2_1_2\": [0, 79, 7, 14],\n",
    "    \"TU_1_2_2_1\": [7, 79, 4, 9],\n",
    "    \"TU_1_2_2_2\": [0, 14, 57, 29],\n",
    "    \"TU_1_3_1_1\": [0, 69, 23, 8],\n",
    "    \"TU_1_3_1_2\": [0, 42, 46, 12],\n",
    "    \"TU_1_3_2_1\": [0, 15, 69, 15],\n",
    "    \"TU_1_3_2_2\": [0, 0, 73, 27],\n",
    "    \"TU_2_1_1_1\": [68, 26, 3, 6],\n",
    "    \"TU_2_1_1_2\": [6, 77, 10, 6],\n",
    "    \"TU_2_1_2_1\": [65, 26, 6, 3],\n",
    "    \"TU_2_1_2_2\": [6, 16, 58, 19],\n",
    "    \"TU_2_2_1_1\": [14, 79, 7, 14],\n",
    "    \"TU_2_2_1_2\": [0, 79, 7, 14],\n",
    "    \"TU_2_2_2_1\": [7, 79, 4, 9],\n",
    "    \"TU_2_2_2_2\": [0, 14, 57, 29],\n",
    "    \"TU_2_3_1_1\": [0, 69, 23, 8],\n",
    "    \"TU_2_3_1_2\": [0, 42, 46, 12],\n",
    "    \"TU_2_3_2_1\": [0, 15, 69, 15],\n",
    "    \"TU_2_3_2_2\": [0, 0, 73, 27],\n",
    "    \"TU_3_1_1_1\": [68, 26, 3, 6],\n",
    "    \"TU_3_1_1_2\": [6, 77, 10, 6],\n",
    "    \"TU_3_1_2_1\": [65, 26, 6, 3],\n",
    "    \"TU_3_1_2_2\": [6, 16, 58, 19],\n",
    "    \"TU_3_2_1_1\": [14, 79, 7, 14],\n",
    "    \"TU_3_2_1_2\": [0, 79, 7, 14],\n",
    "    \"TU_3_2_2_1\": [7, 79, 4, 9],\n",
    "    \"TU_3_2_2_2\": [0, 14, 57, 29],\n",
    "    \"TU_3_3_1_1\": [0, 69, 23, 8],\n",
    "    \"TU_3_3_1_2\": [0, 42, 46, 12],\n",
    "    \"TU_3_3_2_1\": [0, 15, 69, 15],\n",
    "    \"TU_3_3_2_2\": [0, 0, 73, 27],\n",
    "}\n",
    "\n",
    "# Dictionary to look configuration given experiment id. key: experiment id, value: configuration (0-12)\n",
    "TU_configurations_dict = {\n",
    "    \"TU_1_1_1_1\": 1,\n",
    "    \"TU_1_1_1_2\": 2,\n",
    "    \"TU_1_1_2_1\": 3,\n",
    "    \"TU_1_1_2_2\": 4,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 6,\n",
    "    \"TU_1_2_2_1\": 7,\n",
    "    \"TU_1_2_2_2\": 8,\n",
    "    \"TU_1_3_1_1\": 9,\n",
    "    \"TU_1_3_1_2\": 10,\n",
    "    \"TU_1_3_2_1\": 11,\n",
    "    \"TU_1_3_2_2\": 12,\n",
    "    \"TU_2_1_1_1\": 1,\n",
    "    \"TU_2_1_1_2\": 2,\n",
    "    \"TU_2_1_2_1\": 3,\n",
    "    \"TU_2_1_2_2\": 4,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 6,\n",
    "    \"TU_2_2_2_1\": 7,\n",
    "    \"TU_2_2_2_2\": 8,\n",
    "    \"TU_2_3_1_1\": 9,\n",
    "    \"TU_2_3_1_2\": 10,\n",
    "    \"TU_2_3_2_1\": 11,\n",
    "    \"TU_2_3_2_2\": 12,\n",
    "    \"TU_3_1_1_1\": 1,\n",
    "    \"TU_3_1_1_2\": 2,\n",
    "    \"TU_3_1_2_1\": 3,\n",
    "    \"TU_3_1_2_2\": 4,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 6,\n",
    "    \"TU_3_2_2_1\": 7,\n",
    "    \"TU_3_2_2_2\": 8,\n",
    "    \"TU_3_3_1_1\": 9,\n",
    "    \"TU_3_3_1_2\": 10,\n",
    "    \"TU_3_3_2_1\": 11,\n",
    "    \"TU_3_3_2_2\": 10\n",
    "}\n",
    "\n",
    "# Dictionary to look up experiment id as string for a given experiment id. key: experiment id, value: experiment id as string\n",
    "TU_experiment_ids_dict = {\n",
    "    \"TU_1_1_1_1\": \"TU_1_1_1_1\",\n",
    "    \"TU_1_1_1_2\": \"TU_1_1_1_2\",\n",
    "    \"TU_1_1_2_1\": \"TU_1_1_2_1\",\n",
    "    \"TU_1_1_2_2\": \"TU_1_1_2_2\",\n",
    "    \"TU_1_2_1_1\": \"TU_1_2_1_1\",\n",
    "    \"TU_1_2_1_2\": \"TU_1_2_1_2\",\n",
    "    \"TU_1_2_2_1\": \"TU_1_2_2_1\",\n",
    "    \"TU_1_2_2_2\": \"TU_1_2_2_2\",\n",
    "    \"TU_1_3_1_1\": \"TU_1_3_1_1\",\n",
    "    \"TU_1_3_1_2\": \"TU_1_3_1_2\",\n",
    "    \"TU_1_3_2_1\": \"TU_1_3_2_1\",\n",
    "    \"TU_1_3_2_2\": \"TU_1_3_2_2\",\n",
    "    \"TU_2_1_1_1\": \"TU_2_1_1_1\",\n",
    "    \"TU_2_1_1_2\": \"TU_2_1_1_2\",\n",
    "    \"TU_2_1_2_1\": \"TU_2_1_2_1\",\n",
    "    \"TU_2_1_2_2\": \"TU_2_1_2_2\",\n",
    "    \"TU_2_2_1_1\": \"TU_2_2_1_1\",\n",
    "    \"TU_2_2_1_2\": \"TU_2_2_1_2\",\n",
    "    \"TU_2_2_2_1\": \"TU_2_2_2_1\",\n",
    "    \"TU_2_2_2_2\": \"TU_2_2_2_2\",\n",
    "    \"TU_2_3_1_1\": \"TU_2_3_1_1\",\n",
    "    \"TU_2_3_1_2\": \"TU_2_3_1_2\",\n",
    "    \"TU_2_3_2_1\": \"TU_2_3_2_1\",\n",
    "    \"TU_2_3_2_2\": \"TU_2_3_2_2\",\n",
    "    \"TU_3_1_1_1\": \"TU_3_1_1_1\",\n",
    "    \"TU_3_1_1_2\": \"TU_3_1_1_2\",\n",
    "    \"TU_3_1_2_1\": \"TU_3_1_2_1\",\n",
    "    \"TU_3_1_2_2\": \"TU_3_1_2_2\",\n",
    "    \"TU_3_2_1_1\": \"TU_3_2_1_1\",\n",
    "    \"TU_3_2_1_2\": \"TU_3_2_1_2\",\n",
    "    \"TU_3_2_2_1\": \"TU_3_2_2_1\",\n",
    "    \"TU_3_2_2_2\": \"TU_3_2_2_2\",\n",
    "    \"TU_3_3_1_1\": \"TU_3_3_1_1\",\n",
    "    \"TU_3_3_1_2\": \"TU_3_3_1_2\",\n",
    "    \"TU_3_3_2_1\": \"TU_3_3_2_1\",\n",
    "    \"TU_3_3_2_2\": \"TU_3_3_2_2\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up functions to repeatedly prompt the LLMs\n",
    "\n",
    "- Helper function to extract dollar amount of given answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the dollar amount of the answer from LLMs\n",
    "def extract_dollar_amounts(answers):\n",
    "    # Only return values that start with \"$\"\n",
    "    valid_prices = [item for item in answers if item.startswith(\"$\")]\n",
    "    # Delete the \"$\" from the beginning of each price\n",
    "    prices = [item.replace('$', '') for item in valid_prices]\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times for OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment(experiment_id, n, progress_bar, temperature):\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = TU_model_dict[experiment_id], \n",
    "            max_tokens = 2,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer by only giving a single price in dollars and cents without an explanation.\"},        \n",
    "            {\"role\": \"user\", \"content\": \n",
    "             f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"}\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id],\n",
    "                TU_buyers_dict[experiment_id], answers, n_observations, TU_configurations_dict[experiment_id], TU_results_dict[experiment_id]]\n",
    "\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for dashboard  (returns dataframe right away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment_dashboard(experiment_id, n, progress_bar, temperature):\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = TU_model_dict[experiment_id], \n",
    "            max_tokens = 2,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer by only giving a single price in dollars and cents without an explanation.\"},        \n",
    "            {\"role\": \"user\", \"content\": \n",
    "             f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"}\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id],\n",
    "                TU_buyers_dict[experiment_id], answers, n_observations, TU_configurations_dict[experiment_id], TU_results_dict[experiment_id]]\n",
    "    # Set index\n",
    "    results = pd.DataFrame(results).set_index(pd.Index(\n",
    "        [\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\", \"configuration\", \"original\"]))\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times (LLama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment_llama(experiment_id, n, progress_bar, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            TU_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\":  \"Answer by only giving a single price in dollars and cents without an explanation.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 5, \n",
    "                \"prompt\": f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    \n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id],\n",
    "               TU_buyers_dict[experiment_id], answers, n_observations, TU_configurations_dict[experiment_id], TU_results_dict[experiment_id]]\n",
    "    \n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for dashboard (returns dataframe right away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment_llama_dashboard(experiment_id, n, progress_bar, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            TU_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\":  \"Answer by only giving a single price in dollars and cents without an explanation.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 5, \n",
    "                \"prompt\": f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    \n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id],\n",
    "               TU_buyers_dict[experiment_id], answers, n_observations, TU_configurations_dict[experiment_id], TU_results_dict[experiment_id]]\n",
    "    # Set index\n",
    "    results = pd.DataFrame(results).set_index(pd.Index(\n",
    "        [\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\", \"configuration\", \"original\"]))\n",
    "    \n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop run_experiment() over a list of temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_temperature_loop(function, experiment_id, temperature_list = [0.5, 1, 1.5], n = 50):\n",
    "    \"\"\"\n",
    "    Function to run an experiment with different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty list for storing results\n",
    "    results_list = []\n",
    "\n",
    "    # Initialize progress bar -> used as input for run_experiment()\n",
    "    progress_bar = tqdm(range(n*len(temperature_list)))\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results = function(experiment_id = experiment_id, n = n, temperature = temperature, progress_bar = progress_bar) \n",
    "        results_list.append(results)\n",
    "       \n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index(\n",
    "        [\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\", \"configuration\", \"original\"]))\n",
    "  \n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"In this run, a total of {n*len(temperature_list)} requests were made using {TU_prompt_ids_dict[experiment_id]}.\"\n",
    "    # Print information about the experiment\n",
    "    print(check)\n",
    " \n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GPT-3.5-turbo we make 100 requests per prompt & temperature value\n",
    "# Also, we will focus on lower temperature values to get more consise answers. For higher temperature values, the \n",
    "# answers almost always contain the same information, but come with an unnecessary explanation (e.g. \"I would ask for $10, because that is the price that everyone else is asking for.\")\n",
    "N = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<02:08,  2.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:12<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "results_1_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_1.append(results_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:09<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2 = []\n",
    "results_2_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_2.append(results_2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:43<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3 = []\n",
    "results_3_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_3.append(results_3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:15<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4 = []\n",
    "results_4_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_4.append(results_4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:21<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5 = []\n",
    "results_5_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_5.append(results_5_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:19<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6 = []\n",
    "results_6_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_6.append(results_6_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:13<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7 = []\n",
    "results_7_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_7.append(results_7_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:20<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8 = []\n",
    "results_8_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_8.append(results_8_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:58<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9 = []\n",
    "results_9_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_9.append(results_9_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:04<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10 = []\n",
    "results_10_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_10.append(results_10_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:13<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11 = []\n",
    "results_11_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_11.append(results_11_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:11<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using TU_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12 = []\n",
    "results_12_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_12.append(results_12_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: GPT-4-1106-Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:07<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_1.append(results_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:11<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_2.append(results_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:03<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_3.append(results_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:50<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_4.append(results_4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:06<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_5.append(results_5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:56<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_6.append(results_6_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:02<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_7.append(results_7_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_8.append(results_8_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_9.append(results_9_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:57<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_10.append(results_10_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:16<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_11.append(results_11_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:57<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_12.append(results_12_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: LLama-2-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:08<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_1.append(results_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [04:15<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_2.append(results_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [05:36<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_3.append(results_3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [05:47<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_4.append(results_4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:20<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_5.append(results_5_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [04:55<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_6.append(results_6_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:35<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_7.append(results_7_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:29<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_8.append(results_8_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:55<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_9.append(results_9_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:53<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_10.append(results_10_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:20<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_11.append(results_11_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:27<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using TU_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_12.append(results_12_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather all results and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>model</th>\n",
       "      <th>initial_cost</th>\n",
       "      <th>orientation_price</th>\n",
       "      <th>buyer</th>\n",
       "      <th>answers</th>\n",
       "      <th>Obs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $5, $10, $10, $5, $5, $5, $5, $5,...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU_2_1_1_1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$0, $0, $0, $0, $0, $0, $0, $0, $0, $0, $0, $...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU_2_1_1_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$0, $0, $0, $0, $5, $0, $5, $0, $0, $0, $0, $...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU_2_3_2_2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$10, $10, $10, $10, $10, $10, $10, $10, $10, ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU_2_3_2_2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$10, $10, $10, $10, $10, $10, $10, $10, $10, ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_id temperature               model initial_cost  \\\n",
       "0     TU_1_1_1_1         0.5       gpt-3.5-turbo            0   \n",
       "1     TU_1_1_1_1         1.0       gpt-3.5-turbo            0   \n",
       "2     TU_1_1_1_1         1.5       gpt-3.5-turbo            0   \n",
       "0     TU_2_1_1_1         0.5  gpt-4-1106-preview            0   \n",
       "1     TU_2_1_1_1         1.0  gpt-4-1106-preview            0   \n",
       "..           ...         ...                 ...          ...   \n",
       "1     TU_2_3_2_2         1.0  gpt-4-1106-preview           10   \n",
       "2     TU_2_3_2_2         1.5  gpt-4-1106-preview           10   \n",
       "0     TU_3_3_2_2         0.5         llama-2-70b           10   \n",
       "1     TU_3_3_2_2         1.0         llama-2-70b           10   \n",
       "2     TU_3_3_2_2         1.5         llama-2-70b           10   \n",
       "\n",
       "   orientation_price     buyer  \\\n",
       "0                  5    friend   \n",
       "1                  5    friend   \n",
       "2                  5    friend   \n",
       "0                  5    friend   \n",
       "1                  5    friend   \n",
       "..               ...       ...   \n",
       "1                 10  stranger   \n",
       "2                 10  stranger   \n",
       "0                 10  stranger   \n",
       "1                 10  stranger   \n",
       "2                 10  stranger   \n",
       "\n",
       "                                              answers Obs.  \n",
       "0   [$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...  100  \n",
       "1   [$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...  100  \n",
       "2   [$5, $5, $5, $5, $10, $10, $5, $5, $5, $5, $5,...   97  \n",
       "0   [$0, $0, $0, $0, $0, $0, $0, $0, $0, $0, $0, $...   50  \n",
       "1   [$0, $0, $0, $0, $5, $0, $5, $0, $0, $0, $0, $...   50  \n",
       "..                                                ...  ...  \n",
       "1   [$10, $10, $10, $10, $10, $10, $10, $10, $10, ...   50  \n",
       "2   [$10, $10, $10, $10, $10, $10, $10, $10, $10, ...   50  \n",
       "0   [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50  \n",
       "1   [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50  \n",
       "2   [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50  \n",
       "\n",
       "[108 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate results\n",
    "results_1_df = pd.concat(results_1, axis = 1).transpose()\n",
    "results_2_df = pd.concat(results_2, axis = 1).transpose()\n",
    "results_3_df = pd.concat(results_3, axis = 1).transpose()\n",
    "results_4_df = pd.concat(results_4, axis = 1).transpose()\n",
    "results_5_df = pd.concat(results_5, axis = 1).transpose()\n",
    "results_6_df = pd.concat(results_6, axis = 1).transpose()\n",
    "results_7_df = pd.concat(results_7, axis = 1).transpose()\n",
    "results_8_df = pd.concat(results_8, axis = 1).transpose()\n",
    "results_9_df = pd.concat(results_9, axis = 1).transpose()\n",
    "results_10_df = pd.concat(results_10, axis = 1).transpose()\n",
    "results_11_df = pd.concat(results_11, axis = 1).transpose()\n",
    "results_12_df = pd.concat(results_12, axis = 1).transpose()\n",
    "\n",
    "# Concatenate all results\n",
    "TU_results = pd.concat([results_1_df, results_2_df, results_3_df, results_4_df, results_5_df,\n",
    "                         results_6_df, results_7_df, results_8_df, results_9_df, results_10_df, results_11_df, results_12_df], axis = 0)\n",
    "\n",
    "# Rename LLama model\n",
    "TU_results['model'] = TU_results['model'].replace('meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3', \n",
    "                                  'llama-2-70b')\n",
    "\n",
    "# Display results\n",
    "TU_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename LLama model\n",
    "TU_results['model'] = TU_results['model'].replace('meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3', \n",
    "                                  'llama-2-70b')\n",
    "\n",
    "# Save results\n",
    "TU_results.to_csv(\"Output/TU_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU_results = pd.read_csv(\"Output/TU_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_plot_results(results: pd.DataFrame):\n",
    "    # Grab experiment id from dataframe\n",
    "    experiment_id = results[\"experiment_id\"].iloc[0]\n",
    "    model = results[\"model\"].iloc[0]\n",
    "    # Get original answers (not as strings)\n",
    "    og_answers = results[\"original\"].apply(literal_eval).iloc[0]\n",
    "    # Grab answers column\n",
    "    answers = results[\"answers\"]\n",
    "    # Get number of observations\n",
    "    n = results[\"Obs.\"].iloc[0]\n",
    "\n",
    "    # Convert to list (not as strings)\n",
    "    answers = answers.apply(literal_eval).iloc[0]\n",
    "    # Extract dollar amounts\n",
    "    prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute percentage of $0:\n",
    "    percent_0 = (prices.count(\"0\")/n)*100\n",
    "    # Compute percentage of $5:\n",
    "    percent_5 = (prices.count(\"5\")/n)*100\n",
    "    # Compute percentage of $10:\n",
    "    percent_10 = (prices.count(\"10\")/n)*100\n",
    "    # Compute percentage of other answers:\n",
    "    percent_other = 100-percent_0-percent_5-percent_10\n",
    "    \n",
    "    # Draw barplot of results\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Define x-axis positions for the bars\n",
    "    x_positions_model = np.arange(4)\n",
    "    x_positions_original = x_positions_model + 0.4  # to avoid stacked bars\n",
    "\n",
    "    # Bar width\n",
    "    bar_width = 0.4\n",
    "\n",
    "    # Draw the bars\n",
    "    ax.bar(x_positions_model, [percent_0, percent_5, percent_10, percent_other], width=bar_width, color=\"cornflowerblue\", label=\"Model answers\")\n",
    "    ax.bar(x_positions_original, [og_answers[0], og_answers[1], og_answers[2], og_answers[3]], width=bar_width, color=\"lightblue\", label=\"Original answers\")\n",
    "\n",
    "    # Set x-axis labels and tick positions\n",
    "    ax.set_xticks(x_positions_model + bar_width / 2)\n",
    "    ax.set_xticklabels([\"$0\", \"$5\", \"$10\", \"Other\"])\n",
    "\n",
    "    ax.set_xlabel(\"Price\")\n",
    "    ax.set_ylabel(\"Percentage\")\n",
    "    ax.set_title(f\"Answers for experiment {TU_experiment_ids_dict[experiment_id]}, using {model}\")\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TU_plot_results(TU_results[(TU_results[\"experiment_id\"] == \"TU_3_2_2_1\") & (TU_results[\"temperature\"] == 0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
