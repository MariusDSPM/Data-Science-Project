{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Utility Theory\n",
    "\n",
    "This notebook aims to recreate some of the empirical findings of Thaler, R. (1985). Mental accounting and consumer choice. Marketing Science, 4(3), 199-214. \n",
    "Specifically we are interested in whether LLMs' responses are similar to the original responses in **section 3** of the paper, regarding the Hockey Ticket Question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "TBD: <br>\n",
    "Show distribution of all experiment answers, or just $0, $5, $10 and label everything else as \"others\"?\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import replicate\n",
    "from ast import literal_eval\n",
    "import plotly.graph_objects as go\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get openAI API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up prompts for the experiment\n",
    "\n",
    "\n",
    "\n",
    "- LLMs used in the experiment:\n",
    "    - GPT-3.5-Turbo         (ID = 1)\n",
    "    - GPT-4-1106-Preview    (ID = 2)\n",
    "    - LLama-70b             (ID = 3)\n",
    "\n",
    "We can differentiate between the following scenario combinations:\n",
    "\n",
    "- Initial ticket price:\n",
    "    - free                  (ID = 1)\n",
    "    - $5 (as on ticket)     (ID = 2)\n",
    "    - $10                   (ID = 3)\n",
    "- Current market price:\n",
    "    - $5                    (ID = 1)\n",
    "    - $10                   (ID = 2)\n",
    "- Selling to:\n",
    "    - Friend                (ID = 1)\n",
    "    - Stranger              (ID = 2)\n",
    "\n",
    "\n",
    "\n",
    "Similar to the Prospect Theory and Decoy Effect notebooks, we will use experiment IDs to run the study. The IDs will be constructed as:\n",
    "\n",
    "*TU_model_initialprice_currentprice_buyer*\n",
    "\n",
    "Therefore, TU_2_2_1_2 would mean we used GPT-4-1106-Preview, an initial ticket price of $5, a current market price of $5 as well and we are selling to a stranger.\n",
    "\n",
    "We leave out the information of the respondent being a student in all prompts. From experience, the more concise a prompt is, the better the answer quality. \n",
    "Since the job status/education level is not of interest here, we leave out this information in order to formulate clearer prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list of initial costs\n",
    "initial_costs = [\"but you were given your tickets for free by a friend.\", \"which is what you paid for each ticket.\", \"but you paid $10 each for your tickets when you bought them.\"]\n",
    "\n",
    "# Set up list of current ticket prices\n",
    "orientation_prices = [\"$5\", \"$10\"]\n",
    "\n",
    "# Set up list of potential buyers in a scenario\n",
    "potential_buyers = [\"friend?\", \"stranger?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU_prompts = []\n",
    "for costs in initial_costs:\n",
    "    for orientation_price in orientation_prices:\n",
    "        for potential_buyer in potential_buyers:\n",
    "            prompt = f\"\"\"Imagine that you are going to a soldout Cornell hockey playoff game, and you have an extra ticket to sell or give away. The price marked on the ticket is $5 {costs}\n",
    "            You get to the game early to make sure you get rid of the ticket. An informal survey of people selling tickets indicates that the going price is {orientation_price}. \n",
    "            You find someone who wants the ticket and takes out his wallet to pay you. He asks, how much you want for the ticket. \n",
    "            Assume that there is no law against charging a price higher than that marked on the ticket. What price do you ask for, if he is a {potential_buyer}\"\"\"\n",
    "            TU_prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prompts for use in Dashboard\n",
    "with open(\"Output/TU_prompts.pkl\", \"wb\") as file:\n",
    "    pickle.dump(TU_prompts, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TU_prompts[0]: free, $5, friend  -> 1_1_1 (Configuration 1)\n",
    "- TU_prompts[1]: free, $5, stranger -> 1_1_2 (Configuration 2)\n",
    "- TU_prompts[2]: free, $10, friend -> 1_2_1 (Configuration 3)\n",
    "- TU_prompts[3]: free, $10, stranger -> 1_2_2 (Configuration 4)\n",
    "- TU_prompts[4]: $5, $5, friend -> 2_1_1 (Configuration 5)\n",
    "- TU_prompts[5]: $5, $5, stranger -> 2_1_2 (Configuration 6)\n",
    "- TU_prompts[6]: $5, $10, friend -> 2_2_1 (Configuration 7)\n",
    "- TU_prompts[7]: $5, $10, stranger -> 2_2_2 (Configuration 8)\n",
    "- TU_prompts[8]: $10, $5, friend -> 3_1_1  (Configuration 9)\n",
    "- TU_prompts[9]: $10, $5, stranger -> 3_1_2 (Configuration 10)\n",
    "- TU_prompts[10]: $10, $10, friend -> 3_2_1 (Configuration 11)\n",
    "- TU_prompts[11]: $10, $10, stranger -> 3_2_2 (Configuration 12)\n",
    "\n",
    "The results of the original experiment are:\n",
    "\n",
    "\n",
    "| Configuration   | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   |\n",
    "|------------------|------|------|------|------|------|------|------|------|------|------|------|------|\n",
    "| $0              | 68%  | 6%   | 65%  | 6%   | 14%  | 0%   | 7%   | 0%   | 0%   | 0%   | 0%   | 0%   |\n",
    "| $5              | 26%  | 77%  | 26%  | 16%  | 79%  | 79%  | 79%  | 14%  | 69%  | 42%  | 15%  | 0%   |\n",
    "| $10             | 3%   | 10%  | 6%   | 58%  | 0%   | 7%   | 4%   | 57%  | 23%  | 46%  | 69%  | 73%  |\n",
    "| Other          | 6%   | 6%   | 3%   | 19%  | 7%   | 14%  | 9%   | 29%  | 8%   | 12%  | 15%  | 27%  |\n",
    "| N              | 31   | 31   | 31   | 31   | 28   | 28   | 28   | 28   | 26   | 26   | 26   | 26   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_results = {\n",
    "    \"og_results_1\" : [68, 26, 3, 6],\n",
    "    \"og_results_2\" : [6, 77, 10, 6],\n",
    "    \"og_results_3\" : [65, 26, 6, 3],\n",
    "    \"og_results_4\" : [6, 16, 58, 19],\n",
    "    \"og_results_5\" : [14, 79, 7, 14],\n",
    "    \"og_results_6\" : [0, 79, 7, 14],\n",
    "    \"og_results_7\" : [7, 79, 4, 9],\n",
    "    \"og_results_8\" : [0, 14, 57, 29],\n",
    "    \"og_results_9\" : [0, 69, 23, 8],\n",
    "    \"og_results_10\" : [0, 42, 46, 12],\n",
    "    \"og_results_11\" : [0, 15, 69, 15],\n",
    "    \"og_results_12\" : [0, 0, 73, 27]\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting up instructions the model should abide by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Answer by only giving a single price in dollars and cents without an explanation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all experiment IDs\n",
    "experiment_ids =  [\"TU_1_1_1_1\", \"TU_1_1_1_2\", \"TU_1_1_2_1\", \"TU_1_1_2_2\", \"TU_1_2_1_1\", \"TU_1_2_1_2\", \"TU_1_2_2_1\", \"TU_1_2_2_2\", \"TU_1_3_1_1\", \"TU_1_3_1_2\", \"TU_1_3_2_1\", \"TU_1_3_2_2\",\n",
    "                   \"TU_2_1_1_1\", \"TU_2_1_1_2\", \"TU_2_1_2_1\", \"TU_2_1_2_2\", \"TU_2_2_1_1\", \"TU_2_2_1_2\", \"TU_2_2_2_1\", \"TU_2_2_2_2\", \"TU_2_3_1_1\", \"TU_2_3_1_2\", \"TU_2_3_2_1\", \"TU_2_3_2_2\",\n",
    "                   \"TU_3_1_1_1\", \"TU_3_1_1_2\", \"TU_3_1_2_1\", \"TU_3_1_2_2\", \"TU_3_2_1_1\", \"TU_3_2_1_2\", \"TU_3_2_2_1\", \"TU_3_2_2_2\", \"TU_3_3_1_1\", \"TU_3_3_1_2\", \"TU_3_3_2_1\", \"TU_3_3_2_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries to extract information about the different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to look up prompt for a given experiment id. key: experiment id, value: prompt\n",
    "TU_experiment_prompts_dict = {\n",
    "    \"TU_1_1_1_1\": TU_prompts[0],\n",
    "    \"TU_1_1_1_2\": TU_prompts[1],\n",
    "    \"TU_1_1_2_1\": TU_prompts[2],\n",
    "    \"TU_1_1_2_2\": TU_prompts[3],\n",
    "    \"TU_1_2_1_1\": TU_prompts[4],\n",
    "    \"TU_1_2_1_2\": TU_prompts[5],\n",
    "    \"TU_1_2_2_1\": TU_prompts[6],\n",
    "    \"TU_1_2_2_2\": TU_prompts[7],\n",
    "    \"TU_1_3_1_1\": TU_prompts[8],\n",
    "    \"TU_1_3_1_2\": TU_prompts[9],\n",
    "    \"TU_1_3_2_1\": TU_prompts[10],\n",
    "    \"TU_1_3_2_2\": TU_prompts[11],\n",
    "    \"TU_2_1_1_1\": TU_prompts[0],\n",
    "    \"TU_2_1_1_2\": TU_prompts[1],\n",
    "    \"TU_2_1_2_1\": TU_prompts[2],\n",
    "    \"TU_2_1_2_2\": TU_prompts[3],\n",
    "    \"TU_2_2_1_1\": TU_prompts[4],\n",
    "    \"TU_2_2_1_2\": TU_prompts[5],\n",
    "    \"TU_2_2_2_1\": TU_prompts[6],\n",
    "    \"TU_2_2_2_2\": TU_prompts[7],\n",
    "    \"TU_2_3_1_1\": TU_prompts[8],\n",
    "    \"TU_2_3_1_2\": TU_prompts[9],\n",
    "    \"TU_2_3_2_1\": TU_prompts[10],\n",
    "    \"TU_2_3_2_2\": TU_prompts[11],\n",
    "    \"TU_3_1_1_1\": TU_prompts[0],\n",
    "    \"TU_3_1_1_2\": TU_prompts[1],\n",
    "    \"TU_3_1_2_1\": TU_prompts[2],\n",
    "    \"TU_3_1_2_2\": TU_prompts[3],\n",
    "    \"TU_3_2_1_1\": TU_prompts[4],\n",
    "    \"TU_3_2_1_2\": TU_prompts[5],\n",
    "    \"TU_3_2_2_1\": TU_prompts[6],\n",
    "    \"TU_3_2_2_2\": TU_prompts[7],\n",
    "    \"TU_3_3_1_1\": TU_prompts[8],\n",
    "    \"TU_3_3_1_2\": TU_prompts[9],\n",
    "    \"TU_3_3_2_1\": TU_prompts[10],\n",
    "    \"TU_3_3_2_2\": TU_prompts[11],\n",
    "}\n",
    "\n",
    "# Dictionary to look up which model to use for a given experiment id. key: experiment id, value: model name\n",
    "TU_model_dict = {\n",
    "    \"TU_1_1_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_2_1_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_3_1_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up what prompt was used for a given experiment id. key: experiment id, value: prompt variable name\n",
    "TU_prompt_ids_dict = {\n",
    "    \"TU_1_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_1_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_1_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_1_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_1_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_1_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_1_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_1_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_1_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_1_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_1_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_1_3_2_2\": \"TU_prompts[11]\",\n",
    "    \"TU_2_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_2_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_2_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_2_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_2_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_2_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_2_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_2_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_2_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_2_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_2_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_2_3_2_2\": \"TU_prompts[11]\",\n",
    "    \"TU_3_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_3_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_3_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_3_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_3_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_3_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_3_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_3_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_3_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_3_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_3_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_3_3_2_2\": \"TU_prompts[11]\",\n",
    "    }\n",
    "\n",
    "# Dictionary to look up initital ticket cotsts for a given experiment id. key: experiment id, value: initial costs\n",
    "TU_initial_costs_dict = {\n",
    "    \"TU_1_1_1_1\": 0,\n",
    "    \"TU_1_1_1_2\": 0,\n",
    "    \"TU_1_1_2_1\": 0,\n",
    "    \"TU_1_1_2_2\": 0,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 5,\n",
    "    \"TU_1_2_2_1\": 5,\n",
    "    \"TU_1_2_2_2\": 5,\n",
    "    \"TU_1_3_1_1\": 10,\n",
    "    \"TU_1_3_1_2\": 10,\n",
    "    \"TU_1_3_2_1\": 10,\n",
    "    \"TU_1_3_2_2\": 10,\n",
    "    \"TU_2_1_1_1\": 0,\n",
    "    \"TU_2_1_1_2\": 0,\n",
    "    \"TU_2_1_2_1\": 0,\n",
    "    \"TU_2_1_2_2\": 0,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 5,\n",
    "    \"TU_2_2_2_1\": 5,\n",
    "    \"TU_2_2_2_2\": 5,\n",
    "    \"TU_2_3_1_1\": 10,\n",
    "    \"TU_2_3_1_2\": 10,\n",
    "    \"TU_2_3_2_1\": 10,\n",
    "    \"TU_2_3_2_2\": 10,\n",
    "    \"TU_3_1_1_1\": 0,\n",
    "    \"TU_3_1_1_2\": 0,\n",
    "    \"TU_3_1_2_1\": 0,\n",
    "    \"TU_3_1_2_2\": 0,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 5,\n",
    "    \"TU_3_2_2_1\": 5,\n",
    "    \"TU_3_2_2_2\": 5,\n",
    "    \"TU_3_3_1_1\": 10,\n",
    "    \"TU_3_3_1_2\": 10,\n",
    "    \"TU_3_3_2_1\": 10,\n",
    "    \"TU_3_3_2_2\": 10,\n",
    "    }\n",
    "\n",
    "# Dictionary to look up orientation prices for a given experiment id. key: experiment id, value: orientation price\n",
    "TU_orientation_prices_dict = {\n",
    "    \"TU_1_1_1_1\": 5,\n",
    "    \"TU_1_1_1_2\": 5,\n",
    "    \"TU_1_1_2_1\": 10,\n",
    "    \"TU_1_1_2_2\": 10,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 5,\n",
    "    \"TU_1_2_2_1\": 10,\n",
    "    \"TU_1_2_2_2\": 10,\n",
    "    \"TU_1_3_1_1\": 5,\n",
    "    \"TU_1_3_1_2\": 5,\n",
    "    \"TU_1_3_2_1\": 10,\n",
    "    \"TU_1_3_2_2\": 10,\n",
    "    \"TU_2_1_1_1\": 5,\n",
    "    \"TU_2_1_1_2\": 5,\n",
    "    \"TU_2_1_2_1\": 10,\n",
    "    \"TU_2_1_2_2\": 10,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 5,\n",
    "    \"TU_2_2_2_1\": 10,\n",
    "    \"TU_2_2_2_2\": 10,\n",
    "    \"TU_2_3_1_1\": 5,\n",
    "    \"TU_2_3_1_2\": 5,\n",
    "    \"TU_2_3_2_1\": 10,\n",
    "    \"TU_2_3_2_2\": 10,\n",
    "    \"TU_3_1_1_1\": 5,\n",
    "    \"TU_3_1_1_2\": 5,\n",
    "    \"TU_3_1_2_1\": 10,\n",
    "    \"TU_3_1_2_2\": 10,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 5,\n",
    "    \"TU_3_2_2_1\": 10,\n",
    "    \"TU_3_2_2_2\": 10,\n",
    "    \"TU_3_3_1_1\": 5,\n",
    "    \"TU_3_3_1_2\": 5,\n",
    "    \"TU_3_3_2_1\": 10,\n",
    "    \"TU_3_3_2_2\": 10,\n",
    "    }   \n",
    "\n",
    "# Dictionary to look up potential buyers for a given experiment id. key: experiment id, value: potential buyer\n",
    "TU_buyers_dict = {\n",
    "    \"TU_1_1_1_1\": \"friend\",\n",
    "    \"TU_1_1_1_2\": \"stranger\",\n",
    "    \"TU_1_1_2_1\": \"friend\",\n",
    "    \"TU_1_1_2_2\": \"stranger\",\n",
    "    \"TU_1_2_1_1\": \"friend\",\n",
    "    \"TU_1_2_1_2\": \"stranger\",\n",
    "    \"TU_1_2_2_1\": \"friend\",\n",
    "    \"TU_1_2_2_2\": \"stranger\",\n",
    "    \"TU_1_3_1_1\": \"friend\",\n",
    "    \"TU_1_3_1_2\": \"stranger\",\n",
    "    \"TU_1_3_2_1\": \"friend\",\n",
    "    \"TU_1_3_2_2\": \"stranger\",\n",
    "    \"TU_2_1_1_1\": \"friend\",\n",
    "    \"TU_2_1_1_2\": \"stranger\",\n",
    "    \"TU_2_1_2_1\": \"friend\",\n",
    "    \"TU_2_1_2_2\": \"stranger\",\n",
    "    \"TU_2_2_1_1\": \"friend\",\n",
    "    \"TU_2_2_1_2\": \"stranger\",\n",
    "    \"TU_2_2_2_1\": \"friend\",\n",
    "    \"TU_2_2_2_2\": \"stranger\",\n",
    "    \"TU_2_3_1_1\": \"friend\",\n",
    "    \"TU_2_3_1_2\": \"stranger\",\n",
    "    \"TU_2_3_2_1\": \"friend\",\n",
    "    \"TU_2_3_2_2\": \"stranger\",\n",
    "    \"TU_3_1_1_1\": \"friend\",\n",
    "    \"TU_3_1_1_2\": \"stranger\",\n",
    "    \"TU_3_1_2_1\": \"friend\",\n",
    "    \"TU_3_1_2_2\": \"stranger\",\n",
    "    \"TU_3_2_1_1\": \"friend\",\n",
    "    \"TU_3_2_1_2\": \"stranger\",\n",
    "    \"TU_3_2_2_1\": \"friend\",\n",
    "    \"TU_3_2_2_2\": \"stranger\",\n",
    "    \"TU_3_3_1_1\": \"friend\",\n",
    "    \"TU_3_3_1_2\": \"stranger\",\n",
    "    \"TU_3_3_2_1\": \"friend\",\n",
    "    \"TU_3_3_2_2\": \"stranger\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up original results for a given experiment id. key: experiment id, value: original results\n",
    "TU_results_dict = {\n",
    "    \"TU_1_1_1_1\": [68, 26, 3, 6],\n",
    "    \"TU_1_1_1_2\": [6, 77, 10, 6],\n",
    "    \"TU_1_1_2_1\": [65, 26, 6, 3],\n",
    "    \"TU_1_1_2_2\": [6, 16, 58, 19],\n",
    "    \"TU_1_2_1_1\": [14, 79, 7, 14],\n",
    "    \"TU_1_2_1_2\": [0, 79, 7, 14],\n",
    "    \"TU_1_2_2_1\": [7, 79, 4, 9],\n",
    "    \"TU_1_2_2_2\": [0, 14, 57, 29],\n",
    "    \"TU_1_3_1_1\": [0, 69, 23, 8],\n",
    "    \"TU_1_3_1_2\": [0, 42, 46, 12],\n",
    "    \"TU_1_3_2_1\": [0, 15, 69, 15],\n",
    "    \"TU_1_3_2_2\": [0, 0, 73, 27],\n",
    "    \"TU_2_1_1_1\": [68, 26, 3, 6],\n",
    "    \"TU_2_1_1_2\": [6, 77, 10, 6],\n",
    "    \"TU_2_1_2_1\": [65, 26, 6, 3],\n",
    "    \"TU_2_1_2_2\": [6, 16, 58, 19],\n",
    "    \"TU_2_2_1_1\": [14, 79, 7, 14],\n",
    "    \"TU_2_2_1_2\": [0, 79, 7, 14],\n",
    "    \"TU_2_2_2_1\": [7, 79, 4, 9],\n",
    "    \"TU_2_2_2_2\": [0, 14, 57, 29],\n",
    "    \"TU_2_3_1_1\": [0, 69, 23, 8],\n",
    "    \"TU_2_3_1_2\": [0, 42, 46, 12],\n",
    "    \"TU_2_3_2_1\": [0, 15, 69, 15],\n",
    "    \"TU_2_3_2_2\": [0, 0, 73, 27],\n",
    "    \"TU_3_1_1_1\": [68, 26, 3, 6],\n",
    "    \"TU_3_1_1_2\": [6, 77, 10, 6],\n",
    "    \"TU_3_1_2_1\": [65, 26, 6, 3],\n",
    "    \"TU_3_1_2_2\": [6, 16, 58, 19],\n",
    "    \"TU_3_2_1_1\": [14, 79, 7, 14],\n",
    "    \"TU_3_2_1_2\": [0, 79, 7, 14],\n",
    "    \"TU_3_2_2_1\": [7, 79, 4, 9],\n",
    "    \"TU_3_2_2_2\": [0, 14, 57, 29],\n",
    "    \"TU_3_3_1_1\": [0, 69, 23, 8],\n",
    "    \"TU_3_3_1_2\": [0, 42, 46, 12],\n",
    "    \"TU_3_3_2_1\": [0, 15, 69, 15],\n",
    "    \"TU_3_3_2_2\": [0, 0, 73, 27],\n",
    "}\n",
    "\n",
    "# Dictionary to look up number of original answers. key: experiment id, value: number of original answers\n",
    "TU_answercount_dict = {\n",
    "    \"TU_1_1_1_1\": 31,\n",
    "    \"TU_1_1_1_2\": 31,\n",
    "    \"TU_1_1_2_1\": 31,\n",
    "    \"TU_1_1_2_2\": 31,\n",
    "    \"TU_1_2_1_1\": 28,\n",
    "    \"TU_1_2_1_2\": 28,\n",
    "    \"TU_1_2_2_1\": 28,\n",
    "    \"TU_1_2_2_2\": 28,\n",
    "    \"TU_1_3_1_1\": 26,\n",
    "    \"TU_1_3_1_2\": 26,\n",
    "    \"TU_1_3_2_1\": 26,\n",
    "    \"TU_1_3_2_2\": 26,\n",
    "    \"TU_2_1_1_1\": 31,\n",
    "    \"TU_2_1_1_2\": 31,\n",
    "    \"TU_2_1_2_1\": 31,\n",
    "    \"TU_2_1_2_2\": 31,\n",
    "    \"TU_2_2_1_1\": 28,\n",
    "    \"TU_2_2_1_2\": 28,\n",
    "    \"TU_2_2_2_1\": 28,\n",
    "    \"TU_2_2_2_2\": 28,\n",
    "    \"TU_2_3_1_1\": 26,\n",
    "    \"TU_2_3_1_2\": 26,\n",
    "    \"TU_2_3_2_1\": 26,\n",
    "    \"TU_2_3_2_2\": 26,\n",
    "    \"TU_3_1_1_1\": 31,\n",
    "    \"TU_3_1_1_2\": 31,\n",
    "    \"TU_3_1_2_1\": 31,\n",
    "    \"TU_3_1_2_2\": 31,\n",
    "    \"TU_3_2_1_1\": 28,\n",
    "    \"TU_3_2_1_2\": 28,\n",
    "    \"TU_3_2_2_1\": 28,\n",
    "    \"TU_3_2_2_2\": 28,\n",
    "    \"TU_3_3_1_1\": 26,\n",
    "    \"TU_3_3_1_2\": 26,\n",
    "    \"TU_3_3_2_1\": 26,\n",
    "    \"TU_3_3_2_2\": 26\n",
    "}\n",
    "\n",
    "# Dictionary to look configuration given experiment id. key: experiment id, value: configuration (0-12)\n",
    "TU_configurations_dict = {\n",
    "    \"TU_1_1_1_1\": 1,\n",
    "    \"TU_1_1_1_2\": 2,\n",
    "    \"TU_1_1_2_1\": 3,\n",
    "    \"TU_1_1_2_2\": 4,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 6,\n",
    "    \"TU_1_2_2_1\": 7,\n",
    "    \"TU_1_2_2_2\": 8,\n",
    "    \"TU_1_3_1_1\": 9,\n",
    "    \"TU_1_3_1_2\": 10,\n",
    "    \"TU_1_3_2_1\": 11,\n",
    "    \"TU_1_3_2_2\": 12,\n",
    "    \"TU_2_1_1_1\": 1,\n",
    "    \"TU_2_1_1_2\": 2,\n",
    "    \"TU_2_1_2_1\": 3,\n",
    "    \"TU_2_1_2_2\": 4,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 6,\n",
    "    \"TU_2_2_2_1\": 7,\n",
    "    \"TU_2_2_2_2\": 8,\n",
    "    \"TU_2_3_1_1\": 9,\n",
    "    \"TU_2_3_1_2\": 10,\n",
    "    \"TU_2_3_2_1\": 11,\n",
    "    \"TU_2_3_2_2\": 12,\n",
    "    \"TU_3_1_1_1\": 1,\n",
    "    \"TU_3_1_1_2\": 2,\n",
    "    \"TU_3_1_2_1\": 3,\n",
    "    \"TU_3_1_2_2\": 4,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 6,\n",
    "    \"TU_3_2_2_1\": 7,\n",
    "    \"TU_3_2_2_2\": 8,\n",
    "    \"TU_3_3_1_1\": 9,\n",
    "    \"TU_3_3_1_2\": 10,\n",
    "    \"TU_3_3_2_1\": 11,\n",
    "    \"TU_3_3_2_2\": 10\n",
    "}\n",
    "\n",
    "# Dictionary to look up experiment id as string for a given experiment id. key: experiment id, value: experiment id as string\n",
    "TU_experiment_ids_dict = {\n",
    "    \"TU_1_1_1_1\": \"TU_1_1_1_1\",\n",
    "    \"TU_1_1_1_2\": \"TU_1_1_1_2\",\n",
    "    \"TU_1_1_2_1\": \"TU_1_1_2_1\",\n",
    "    \"TU_1_1_2_2\": \"TU_1_1_2_2\",\n",
    "    \"TU_1_2_1_1\": \"TU_1_2_1_1\",\n",
    "    \"TU_1_2_1_2\": \"TU_1_2_1_2\",\n",
    "    \"TU_1_2_2_1\": \"TU_1_2_2_1\",\n",
    "    \"TU_1_2_2_2\": \"TU_1_2_2_2\",\n",
    "    \"TU_1_3_1_1\": \"TU_1_3_1_1\",\n",
    "    \"TU_1_3_1_2\": \"TU_1_3_1_2\",\n",
    "    \"TU_1_3_2_1\": \"TU_1_3_2_1\",\n",
    "    \"TU_1_3_2_2\": \"TU_1_3_2_2\",\n",
    "    \"TU_2_1_1_1\": \"TU_2_1_1_1\",\n",
    "    \"TU_2_1_1_2\": \"TU_2_1_1_2\",\n",
    "    \"TU_2_1_2_1\": \"TU_2_1_2_1\",\n",
    "    \"TU_2_1_2_2\": \"TU_2_1_2_2\",\n",
    "    \"TU_2_2_1_1\": \"TU_2_2_1_1\",\n",
    "    \"TU_2_2_1_2\": \"TU_2_2_1_2\",\n",
    "    \"TU_2_2_2_1\": \"TU_2_2_2_1\",\n",
    "    \"TU_2_2_2_2\": \"TU_2_2_2_2\",\n",
    "    \"TU_2_3_1_1\": \"TU_2_3_1_1\",\n",
    "    \"TU_2_3_1_2\": \"TU_2_3_1_2\",\n",
    "    \"TU_2_3_2_1\": \"TU_2_3_2_1\",\n",
    "    \"TU_2_3_2_2\": \"TU_2_3_2_2\",\n",
    "    \"TU_3_1_1_1\": \"TU_3_1_1_1\",\n",
    "    \"TU_3_1_1_2\": \"TU_3_1_1_2\",\n",
    "    \"TU_3_1_2_1\": \"TU_3_1_2_1\",\n",
    "    \"TU_3_1_2_2\": \"TU_3_1_2_2\",\n",
    "    \"TU_3_2_1_1\": \"TU_3_2_1_1\",\n",
    "    \"TU_3_2_1_2\": \"TU_3_2_1_2\",\n",
    "    \"TU_3_2_2_1\": \"TU_3_2_2_1\",\n",
    "    \"TU_3_2_2_2\": \"TU_3_2_2_2\",\n",
    "    \"TU_3_3_1_1\": \"TU_3_3_1_1\",\n",
    "    \"TU_3_3_1_2\": \"TU_3_3_1_2\",\n",
    "    \"TU_3_3_2_1\": \"TU_3_3_2_1\",\n",
    "    \"TU_3_3_2_2\": \"TU_3_3_2_2\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up functions to repeatedly prompt the LLMs\n",
    "\n",
    "- Helper function to extract dollar amount of given answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dollar_amounts(answers):\n",
    "    # Only return values that start with \"$\"\n",
    "    valid_prices = [item for item in answers if item.startswith(\"$\") and item[1:].replace(',', '').replace('.', '').isdigit()] # check if everything after $ is a digit, exlcuding commas\n",
    "    # Delete the \"$\" from the beginning of each price\n",
    "    prices = [item.replace('$', '') for item in valid_prices]\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times for OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment(experiment_id, n, progress_bar, temperature):\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = TU_model_dict[experiment_id], \n",
    "            max_tokens = 2,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer by only giving a single price in dollars and cents without an explanation.\"},        \n",
    "            {\"role\": \"user\", \"content\": \n",
    "             f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"}\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id],\n",
    "                TU_buyers_dict[experiment_id], answers, n_observations, TU_configurations_dict[experiment_id], TU_results_dict[experiment_id], TU_answercount_dict[experiment_id]]\n",
    "\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times (LLama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment_llama(experiment_id, n, progress_bar, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            TU_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\":  \"Answer by only giving a single price in dollars and cents without an explanation.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 10, \n",
    "                \"prompt\": f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    \n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id],\n",
    "               TU_buyers_dict[experiment_id], answers, n_observations, TU_configurations_dict[experiment_id], TU_results_dict[experiment_id], TU_answercount_dict[experiment_id]]\n",
    "    \n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop run_experiment() over a list of temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_temperature_loop(function, experiment_id, temperature_list = [0.5, 1, 1.5], n = 50):\n",
    "    \"\"\"\n",
    "    Function to run an experiment with different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty list for storing results\n",
    "    results_list = []\n",
    "\n",
    "    # Initialize progress bar -> used as input for run_experiment()\n",
    "    progress_bar = tqdm(range(n*len(temperature_list)))\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results = function(experiment_id = experiment_id, n = n, temperature = temperature, progress_bar = progress_bar) \n",
    "        results_list.append(results)\n",
    "       \n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index(\n",
    "        [\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\", \"configuration\", \"original\", \"original_count\"]))\n",
    "  \n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"In this run, a total of {n*len(temperature_list)} requests were made using {TU_prompt_ids_dict[experiment_id]}.\"\n",
    "    # Print information about the experiment\n",
    "    print(check)\n",
    " \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GPT-3.5-turbo we make 100 requests per prompt & temperature value\n",
    "N = 100\n",
    "# List of temperature values to loop over\n",
    "temperature_list = [0.01, 0.5, 1, 1.5, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [14:10<00:00,  1.70s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1 = []\n",
    "results_1_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_1.append(results_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:41<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2 = []\n",
    "results_2_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_2.append(results_2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:38<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3 = []\n",
    "results_3_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_3.append(results_3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:42<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4 = []\n",
    "results_4_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_4.append(results_4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:54<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5 = []\n",
    "results_5_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_5.append(results_5_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:37<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6 = []\n",
    "results_6_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_6.append(results_6_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [13:45<00:00,  1.65s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7 = []\n",
    "results_7_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_7.append(results_7_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:41<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8 = []\n",
    "results_8_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_8.append(results_8_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:39<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9 = []\n",
    "results_9_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_9.append(results_9_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:47<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10 = []\n",
    "results_10_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_10.append(results_10_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:37<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11 = []\n",
    "results_11_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_11.append(results_11_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [23:45<00:00,  2.85s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 500 requests were made using TU_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12 = []\n",
    "results_12_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_12.append(results_12_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: GPT-4-1106-Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_1.append(results_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:39<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_2.append(results_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:19<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_3.append(results_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [23:19<00:00,  5.60s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_4.append(results_4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:10<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_5.append(results_5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [04:51<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_6.append(results_6_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [13:03<00:00,  3.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_7.append(results_7_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:04<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_8.append(results_8_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:12<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_9.append(results_9_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:34<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_10.append(results_10_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_11.append(results_11_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:03<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_12.append(results_12_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: LLama-2-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [07:33<00:00,  1.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_1.append(results_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [09:06<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_2.append(results_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:41<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_3_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_3.append(results_3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [08:28<00:00,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_4_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_4.append(results_4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [06:22<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_5.append(results_5_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:41<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_6_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_6.append(results_6_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [06:07<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_7_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_7.append(results_7_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:01<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_8_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_8.append(results_8_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_9_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_1_1\", temperature_list = temperature_list, n = N)\n",
    "results_9.append(results_9_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [07:49<00:00,  1.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[9].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_10_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_1_2\", temperature_list = temperature_list, n = N)\n",
    "results_10.append(results_10_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:46<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[10].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_11_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_2_1\", temperature_list = temperature_list, n = N)\n",
    "results_11.append(results_11_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [07:45<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 250 requests were made using TU_prompts[11].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_12_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_2_2\", temperature_list = temperature_list, n = N)\n",
    "results_12.append(results_12_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather all results and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_id</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Initial_cost</th>\n",
       "      <th>Orientation_price</th>\n",
       "      <th>Buyer</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Obs.</th>\n",
       "      <th>Configuration</th>\n",
       "      <th>Original</th>\n",
       "      <th>Original_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 26, 3, 6]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 26, 3, 6]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 26, 3, 6]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, $5, $10, The price, $5, $5, $5, $5, $...</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 26, 3, 6]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TU_1_1_1_1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>friend</td>\n",
       "      <td>[$5, $5, 98 dollars, Can |, Technical tools, $...</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>[68, 26, 3, 6]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 73, 27]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 73, 27]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 73, 27]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[$15, $15, $15, $15, $15, $15, $15, $15, $15, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 73, 27]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TU_3_3_2_2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>llama-2-70b</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>stranger</td>\n",
       "      <td>[Sure! I would ask for $15, $15, $15, $15, $15...</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 73, 27]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment_id Temperature          Model Initial_cost Orientation_price  \\\n",
       "0     TU_1_1_1_1        0.01  gpt-3.5-turbo            0                 5   \n",
       "1     TU_1_1_1_1         0.5  gpt-3.5-turbo            0                 5   \n",
       "2     TU_1_1_1_1         1.0  gpt-3.5-turbo            0                 5   \n",
       "3     TU_1_1_1_1         1.5  gpt-3.5-turbo            0                 5   \n",
       "4     TU_1_1_1_1         2.0  gpt-3.5-turbo            0                 5   \n",
       "..           ...         ...            ...          ...               ...   \n",
       "0     TU_3_3_2_2        0.01    llama-2-70b           10                10   \n",
       "1     TU_3_3_2_2         0.5    llama-2-70b           10                10   \n",
       "2     TU_3_3_2_2         1.0    llama-2-70b           10                10   \n",
       "3     TU_3_3_2_2         1.5    llama-2-70b           10                10   \n",
       "4     TU_3_3_2_2         2.0    llama-2-70b           10                10   \n",
       "\n",
       "       Buyer                                            Answers Obs.  \\\n",
       "0     friend  [$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...  100   \n",
       "1     friend  [$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...  100   \n",
       "2     friend  [$5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $5, $...  100   \n",
       "3     friend  [$5, $5, $5, $10, The price, $5, $5, $5, $5, $...   95   \n",
       "4     friend  [$5, $5, 98 dollars, Can |, Technical tools, $...   68   \n",
       "..       ...                                                ...  ...   \n",
       "0   stranger  [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50   \n",
       "1   stranger  [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50   \n",
       "2   stranger  [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50   \n",
       "3   stranger  [$15, $15, $15, $15, $15, $15, $15, $15, $15, ...   50   \n",
       "4   stranger  [Sure! I would ask for $15, $15, $15, $15, $15...   39   \n",
       "\n",
       "   Configuration        Original Original_count  \n",
       "0              1  [68, 26, 3, 6]             31  \n",
       "1              1  [68, 26, 3, 6]             31  \n",
       "2              1  [68, 26, 3, 6]             31  \n",
       "3              1  [68, 26, 3, 6]             31  \n",
       "4              1  [68, 26, 3, 6]             31  \n",
       "..           ...             ...            ...  \n",
       "0             10  [0, 0, 73, 27]             26  \n",
       "1             10  [0, 0, 73, 27]             26  \n",
       "2             10  [0, 0, 73, 27]             26  \n",
       "3             10  [0, 0, 73, 27]             26  \n",
       "4             10  [0, 0, 73, 27]             26  \n",
       "\n",
       "[180 rows x 11 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate results\n",
    "results_1_df = pd.concat(results_1, axis = 1).transpose()\n",
    "results_2_df = pd.concat(results_2, axis = 1).transpose()\n",
    "results_3_df = pd.concat(results_3, axis = 1).transpose()\n",
    "results_4_df = pd.concat(results_4, axis = 1).transpose()\n",
    "results_5_df = pd.concat(results_5, axis = 1).transpose()\n",
    "results_6_df = pd.concat(results_6, axis = 1).transpose()\n",
    "results_7_df = pd.concat(results_7, axis = 1).transpose()\n",
    "results_8_df = pd.concat(results_8, axis = 1).transpose()\n",
    "results_9_df = pd.concat(results_9, axis = 1).transpose()\n",
    "results_10_df = pd.concat(results_10, axis = 1).transpose()\n",
    "results_11_df = pd.concat(results_11, axis = 1).transpose()\n",
    "results_12_df = pd.concat(results_12, axis = 1).transpose()\n",
    "\n",
    "# Concatenate all results\n",
    "TU_results = pd.concat([results_1_df, results_2_df, results_3_df, results_4_df, results_5_df,\n",
    "                         results_6_df, results_7_df, results_8_df, results_9_df, results_10_df, results_11_df, results_12_df], axis = 0)\n",
    "\n",
    "# Rename LLama model\n",
    "TU_results['model'] = TU_results['model'].replace('meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3', \n",
    "                                  'llama-2-70b')\n",
    "\n",
    "# Capitalize first letter of column names\n",
    "TU_results.columns = TU_results.columns.str.capitalize()\n",
    "\n",
    "# Display results\n",
    "TU_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "TU_results.to_csv(\"Output/TU_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU_results = pd.read_csv(\"Output/TU_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_plot_results(model, temperature, initial_cost, orientation_price, buyer, df):\n",
    "    # Select requested subset of results\n",
    "    df = df[(df[\"Model\"] == model) & (df[\"Temperature\"] == temperature) & (df[\"Initial_cost\"] == initial_cost) & (df[\"Orientation_price\"] == orientation_price) & (df[\"Buyer\"] == buyer)]\n",
    "    # Transpose for plotting\n",
    "    df = df.transpose()\n",
    "    # Get original and model answers\n",
    "    og_answers = df.loc[\"Original\"].apply(literal_eval).iloc[0]\n",
    "    # Apply literal_eval to convert string to list\n",
    "    answers = df.loc[\"Answers\"].apply(literal_eval).iloc[0]\n",
    "    # Get number of observations \n",
    "    n_observations = df.loc[\"Obs.\"].iloc[0] \n",
    "    # Get number of original answers\n",
    "    n_original = df.loc[\"Original_count\"].iloc[0]\n",
    "    # Get stated WTP\n",
    "    prices = extract_dollar_amounts(answers)\n",
    "    # Get temperature value \n",
    "    temperature = temperature\n",
    "\n",
    "    # Compute percentage of $0:\n",
    "    percent_0 = (prices.count(\"0\")/n_observations)*100\n",
    "    # Compute percentage of $5:\n",
    "    percent_5 = (prices.count(\"5\")/n_observations)*100\n",
    "    # Compute percentage of $10:\n",
    "    percent_10 = (prices.count(\"10\")/n_observations)*100\n",
    "    # Compute percentage of $15:\n",
    "    percent_15 = (prices.count(\"15\")/n_observations)*100\n",
    "    # Compute percentage of other answers:\n",
    "    percent_other = 100-percent_0-percent_5-percent_10-percent_15\n",
    "\n",
    "    fig = go.Figure(data = [\n",
    "        go.Bar(\n",
    "            name = \"Model answers\",\n",
    "            x = [\"$0\", \"$5\", \"$10\", \"$15\", \"Other\"],\n",
    "            y = [percent_0, percent_5, percent_10, percent_15, percent_other],\n",
    "            customdata = [n_observations, n_observations, n_observations, n_observations, n_observations], \n",
    "            hovertemplate = \"Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>\",\n",
    "            marker_color = \"rgb(55, 83, 109)\"\n",
    "        ),\n",
    "        go.Bar(\n",
    "            name = \"Original answers\",\n",
    "            x = [\"$0\", \"$5\", \"$10\", \"$15\", \"Other\"],\n",
    "            y = [og_answers[0], og_answers[1], og_answers[2], 0, og_answers[3]], # 0 because no-one answered $15, but model did \n",
    "            customdata = [n_original, n_original, n_original, n_original, n_original],\n",
    "            hovertemplate = \"Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>\",\n",
    "            marker_color = \"rgb(26, 118, 255)\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Style figure and add labels \n",
    "    fig.update_layout(\n",
    "    barmode = \"group\",\n",
    "     xaxis = dict(\n",
    "            title = \"Price\",\n",
    "            titlefont_size = 18,\n",
    "            tickfont_size = 16,\n",
    "     ),\n",
    "    yaxis = dict(\n",
    "        title = \"Percentage\",\n",
    "        titlefont_size = 18,\n",
    "        tickfont_size = 16,\n",
    "    ),\n",
    "    title = dict(\n",
    "    text =  f\"Distribution of answers for temperature {temperature}, using model {model}\",\n",
    "    x = 0.5, \n",
    "    y = 0.95,\n",
    "    font_size = 18,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=1.01,  # Adjust the position of the legend\n",
    "        y=0.9,\n",
    "        font=dict(family='Arial', size=12, color='black'),\n",
    "        bordercolor='black',  # Set the legend border color\n",
    "        borderwidth=2,  # Set the legend border width\n",
    "    ),\n",
    "    width = 1000,\n",
    "    margin=dict(t=60)\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          47,
          47,
          47,
          47,
          47
         ],
         "hovertemplate": "Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>",
         "marker": {
          "color": "rgb(55, 83, 109)"
         },
         "name": "Model answers",
         "type": "bar",
         "x": [
          "$0",
          "$5",
          "$10",
          "$15",
          "Other"
         ],
         "y": [
          0,
          0,
          0,
          100,
          0
         ]
        },
        {
         "customdata": [
          28,
          28,
          28,
          28,
          28
         ],
         "hovertemplate": "Percentage: %{y:.2f}%<br>Number of observations: %{customdata}<extra></extra>",
         "marker": {
          "color": "rgb(26, 118, 255)"
         },
         "name": "Original answers",
         "type": "bar",
         "x": [
          "$0",
          "$5",
          "$10",
          "$15",
          "Other"
         ],
         "y": [
          7,
          79,
          4,
          0,
          9
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "legend": {
         "bordercolor": "black",
         "borderwidth": 2,
         "font": {
          "color": "black",
          "family": "Arial",
          "size": 12
         },
         "x": 1.01,
         "y": 0.9
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 18
         },
         "text": "Distribution of answers for temperature 2, using model llama-2-70b",
         "x": 0.5,
         "y": 0.95
        },
        "width": 1000,
        "xaxis": {
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 18
          },
          "text": "Price"
         }
        },
        "yaxis": {
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 18
          },
          "text": "Percentage"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = TU_results\n",
    "model = \"llama-2-70b\"\n",
    "temperature = 2\n",
    "initial_costs = 5\n",
    "orientation_price = 10\n",
    "buyer = \"friend\"\n",
    "TU_plot_results(model, temperature, initial_costs, orientation_price, buyer, df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
