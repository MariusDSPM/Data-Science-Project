{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Utility Theory\n",
    "\n",
    "This notebook aims to recreate some of the empirical findings of Thaler, R. (1985). Mental accounting and consumer choice. Marketing Science, 4(3), 199-214. \n",
    "Specifically we are interested in whether LLMs' responses are similar to the original responses in **section 3** of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get openAI API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up prompts for the experiment\n",
    "\n",
    "\n",
    "\n",
    "- LLMs used in the experiment:\n",
    "    - GPT-3.5-Turbo         (ID = 1)\n",
    "    - GPT-4-1106-Preview    (ID = 2)\n",
    "    - LLama-70b             (ID = 3)\n",
    "\n",
    "We can differentiate between the following scenario combinations:\n",
    "\n",
    "- Initial ticket price:\n",
    "    - free                  (ID = 1)\n",
    "    - $5 (as on ticket)     (ID = 2)\n",
    "    - $10                   (ID = 3)\n",
    "- Current market price:\n",
    "    - $5                    (ID = 1)\n",
    "    - $10                   (ID = 2)\n",
    "- Selling to:\n",
    "    - Friend                (ID = 1)\n",
    "    - Stranger              (ID = 2)\n",
    "\n",
    "\n",
    "\n",
    "Similar to the Prospect Theory and Decoy Effect notebooks, we will use experiment IDs to run the study. The IDs will be constructed as:\n",
    "\n",
    "TU_model_initialprice_currentprice_buyer\n",
    "\n",
    "Therefore, TU_2_2_1_2 would mean we used GPT-4-1106-Preview, an initial ticket price of $5, a current market price of $5 as well and we are selling to a stranger.\n",
    "\n",
    "We leave out the information of the respondent being a student in all prompts. From experience, the more concise a prompt is, the better the answer quality. \n",
    "Since the job status/education level is not of interest here, we leave out this information in order to formulate clearer prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list of initial costs\n",
    "initial_costs = [\"but you were given your tickets for free by a friend.\", \"which is what you paid for each ticket.\", \"but you paid $10 each for your tickets when you bought them.\"]\n",
    "\n",
    "# Set up list of current ticket prices\n",
    "orientation_prices = [\"$5\", \"$10\"]\n",
    "\n",
    "# Set up list of potential buyers in a scenario\n",
    "potential_buyers = [\"friend?\", \"stranger?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU_prompts = []\n",
    "for costs in initial_costs:\n",
    "    for orientation_price in orientation_prices:\n",
    "        for potential_buyer in potential_buyers:\n",
    "            prompt = f\"\"\"Imagine that you are going to a soldout Cornell hockey playoff game, and you have an extra ticket to sell or give away. The price marked on the ticket is $5 {costs}\n",
    "            You get to the game early to make sure you get rid of the ticket. An informal survey of people selling tickets indicates that the going price is {orientation_price}. \n",
    "            You find someone who wants the ticket and takes out his wallet to pay you. He asks, how much you want for the ticket. \n",
    "            Assume that there is now law against charging a price higher than that marked on the ticket. What price do you ask for, if he is a {potential_buyer}\"\"\"\n",
    "            TU_prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prompts[0]: free, $5, friend  -> 1_1_1 (Configuration 1)\n",
    "- prompts[1]: free, $5, stranger -> 1_1_2 (Configuration 2)\n",
    "- prompts[2]: free, $10, friend -> 1_2_1 (Configuration 3)\n",
    "- prompts[3]: free, $10, stranger -> 1_2_2 (Configuration 4)\n",
    "- prompts[4]: $5, $5, friend -> 2_1_1 (Configuration 5)\n",
    "- prompts[5]: $5, $5, stranger -> 2_1_2 (Configuration 6)\n",
    "- prompts[6]: $5, $10, friend -> 2_2_1 (Configuration 7)\n",
    "- prompts[7]: $5, $10, stranger -> 2_2_2 (Configuration 8)\n",
    "- prompts[8]: $10, $5, friend -> 3_1_1  (Configuration 9)\n",
    "- prompts[9]: $10, $5, stranger -> 3_1_2 (Configuration 10)\n",
    "- prompts[10]: $10, $10, friend -> 3_2_1 (Configuration 11)\n",
    "- prompts[11]: $10, $10, stranger -> 3_2_2 (Configuration 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting up instructions the model should abide by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Answer by only giving a single price in dollars and cents without an explanation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries to extract information about the different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to look up prompt for a given experiment id. key: experiment id, value: prompt\n",
    "TU_experiment_prompts_dict = {\n",
    "    \"TU_1_1_1_1\": TU_prompts[0],\n",
    "    \"TU_1_1_1_2\": TU_prompts[1],\n",
    "    \"TU_1_1_2_1\": TU_prompts[2],\n",
    "    \"TU_1_1_2_2\": TU_prompts[3],\n",
    "    \"TU_1_2_1_1\": TU_prompts[4],\n",
    "    \"TU_1_2_1_2\": TU_prompts[5],\n",
    "    \"TU_1_2_2_1\": TU_prompts[6],\n",
    "    \"TU_1_2_2_2\": TU_prompts[7],\n",
    "    \"TU_1_3_1_1\": TU_prompts[8],\n",
    "    \"TU_1_3_1_2\": TU_prompts[9],\n",
    "    \"TU_1_3_2_1\": TU_prompts[10],\n",
    "    \"TU_1_3_2_2\": TU_prompts[11],\n",
    "    \"TU_2_1_1_1\": TU_prompts[0],\n",
    "    \"TU_2_1_1_2\": TU_prompts[1],\n",
    "    \"TU_2_1_2_1\": TU_prompts[2],\n",
    "    \"TU_2_1_2_2\": TU_prompts[3],\n",
    "    \"TU_2_2_1_1\": TU_prompts[4],\n",
    "    \"TU_2_2_1_2\": TU_prompts[5],\n",
    "    \"TU_2_2_2_1\": TU_prompts[6],\n",
    "    \"TU_2_2_2_2\": TU_prompts[7],\n",
    "    \"TU_2_3_1_1\": TU_prompts[8],\n",
    "    \"TU_2_3_1_2\": TU_prompts[9],\n",
    "    \"TU_2_3_2_1\": TU_prompts[10],\n",
    "    \"TU_2_3_2_2\": TU_prompts[11],\n",
    "    \"TU_3_1_1_1\": TU_prompts[0],\n",
    "    \"TU_3_1_1_2\": TU_prompts[1],\n",
    "    \"TU_3_1_2_1\": TU_prompts[2],\n",
    "    \"TU_3_1_2_2\": TU_prompts[3],\n",
    "    \"TU_3_2_1_1\": TU_prompts[4],\n",
    "    \"TU_3_2_1_2\": TU_prompts[5],\n",
    "    \"TU_3_2_2_1\": TU_prompts[6],\n",
    "    \"TU_3_2_2_2\": TU_prompts[7],\n",
    "    \"TU_3_3_1_1\": TU_prompts[8],\n",
    "    \"TU_3_3_1_2\": TU_prompts[9],\n",
    "    \"TU_3_3_2_1\": TU_prompts[10],\n",
    "    \"TU_3_3_2_2\": TU_prompts[11],\n",
    "}\n",
    "\n",
    "# Dictionary to look up which model to use for a given experiment id. key: experiment id, value: model name\n",
    "TU_model_dict = {\n",
    "    \"TU_1_1_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_1_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_2_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_2_1\": \"gpt-3.5-turbo\",\n",
    "    \"TU_1_3_2_2\": \"gpt-3.5-turbo\",\n",
    "    \"TU_2_1_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_1_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_2_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_1_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_1_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"TU_2_3_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"TU_3_1_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_1_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_2_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_1_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_1_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_2_1\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    \"TU_3_3_2_2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up what prompt was used for a given experiment id. key: experiment id, value: prompt variable name\n",
    "TU_prompt_ids_dict = {\n",
    "    \"TU_1_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_1_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_1_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_1_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_1_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_1_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_1_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_1_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_1_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_1_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_1_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_1_3_2_2\": \"TU_prompts[11]\",\n",
    "    \"TU_2_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_2_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_2_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_2_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_2_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_2_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_2_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_2_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_2_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_2_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_2_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_2_3_2_2\": \"TU_prompts[11]\",\n",
    "    \"TU_3_1_1_1\": \"TU_prompts[0]\",\n",
    "    \"TU_3_1_1_2\": \"TU_prompts[1]\",\n",
    "    \"TU_3_1_2_1\": \"TU_prompts[2]\",\n",
    "    \"TU_3_1_2_2\": \"TU_prompts[3]\",\n",
    "    \"TU_3_2_1_1\": \"TU_prompts[4]\",\n",
    "    \"TU_3_2_1_2\": \"TU_prompts[5]\",\n",
    "    \"TU_3_2_2_1\": \"TU_prompts[6]\",\n",
    "    \"TU_3_2_2_2\": \"TU_prompts[7]\",\n",
    "    \"TU_3_3_1_1\": \"TU_prompts[8]\",\n",
    "    \"TU_3_3_1_2\": \"TU_prompts[9]\",\n",
    "    \"TU_3_3_2_1\": \"TU_prompts[10]\",\n",
    "    \"TU_3_3_2_2\": \"TU_prompts[11]\",\n",
    "    }\n",
    "\n",
    "# Dictionary to look up initital ticket cotsts for a given experiment id. key: experiment id, value: initial costs\n",
    "TU_initial_costs_dict = {\n",
    "    \"TU_1_1_1_1\": 0,\n",
    "    \"TU_1_1_1_2\": 0,\n",
    "    \"TU_1_1_2_1\": 0,\n",
    "    \"TU_1_1_2_2\": 0,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 5,\n",
    "    \"TU_1_2_2_1\": 5,\n",
    "    \"TU_1_2_2_2\": 5,\n",
    "    \"TU_1_3_1_1\": 10,\n",
    "    \"TU_1_3_1_2\": 10,\n",
    "    \"TU_1_3_2_1\": 10,\n",
    "    \"TU_1_3_2_2\": 10,\n",
    "    \"TU_2_1_1_1\": 0,\n",
    "    \"TU_2_1_1_2\": 0,\n",
    "    \"TU_2_1_2_1\": 0,\n",
    "    \"TU_2_1_2_2\": 0,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 5,\n",
    "    \"TU_2_2_2_1\": 5,\n",
    "    \"TU_2_2_2_2\": 5,\n",
    "    \"TU_2_3_1_1\": 10,\n",
    "    \"TU_2_3_1_2\": 10,\n",
    "    \"TU_2_3_2_1\": 10,\n",
    "    \"TU_2_3_2_2\": 10,\n",
    "    \"TU_3_1_1_1\": 0,\n",
    "    \"TU_3_1_1_2\": 0,\n",
    "    \"TU_3_1_2_1\": 0,\n",
    "    \"TU_3_1_2_2\": 0,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 5,\n",
    "    \"TU_3_2_2_1\": 5,\n",
    "    \"TU_3_2_2_2\": 5,\n",
    "    \"TU_3_3_1_1\": 10,\n",
    "    \"TU_3_3_1_2\": 10,\n",
    "    \"TU_3_3_2_1\": 10,\n",
    "    \"TU_3_3_2_2\": 10,\n",
    "    }\n",
    "\n",
    "# Dictionary to look up orientation prices for a given experiment id. key: experiment id, value: orientation price\n",
    "TU_orientation_prices_dict = {\n",
    "    \"TU_1_1_1_1\": 5,\n",
    "    \"TU_1_1_1_2\": 5,\n",
    "    \"TU_1_1_2_1\": 10,\n",
    "    \"TU_1_1_2_2\": 10,\n",
    "    \"TU_1_2_1_1\": 5,\n",
    "    \"TU_1_2_1_2\": 5,\n",
    "    \"TU_1_2_2_1\": 10,\n",
    "    \"TU_1_2_2_2\": 10,\n",
    "    \"TU_1_3_1_1\": 5,\n",
    "    \"TU_1_3_1_2\": 5,\n",
    "    \"TU_1_3_2_1\": 10,\n",
    "    \"TU_1_3_2_2\": 10,\n",
    "    \"TU_2_1_1_1\": 5,\n",
    "    \"TU_2_1_1_2\": 5,\n",
    "    \"TU_2_1_2_1\": 10,\n",
    "    \"TU_2_1_2_2\": 10,\n",
    "    \"TU_2_2_1_1\": 5,\n",
    "    \"TU_2_2_1_2\": 5,\n",
    "    \"TU_2_2_2_1\": 10,\n",
    "    \"TU_2_2_2_2\": 10,\n",
    "    \"TU_2_3_1_1\": 5,\n",
    "    \"TU_2_3_1_2\": 5,\n",
    "    \"TU_2_3_2_1\": 10,\n",
    "    \"TU_2_3_2_2\": 10,\n",
    "    \"TU_3_1_1_1\": 5,\n",
    "    \"TU_3_1_1_2\": 5,\n",
    "    \"TU_3_1_2_1\": 10,\n",
    "    \"TU_3_1_2_2\": 10,\n",
    "    \"TU_3_2_1_1\": 5,\n",
    "    \"TU_3_2_1_2\": 5,\n",
    "    \"TU_3_2_2_1\": 10,\n",
    "    \"TU_3_2_2_2\": 10,\n",
    "    \"TU_3_3_1_1\": 5,\n",
    "    \"TU_3_3_1_2\": 5,\n",
    "    \"TU_3_3_2_1\": 10,\n",
    "    \"TU_3_3_2_2\": 10,\n",
    "    }   \n",
    "\n",
    "# Dictionary to look up potential buyers for a given experiment id. key: experiment id, value: potential buyer\n",
    "TU_buyers_dict = {\n",
    "    \"TU_1_1_1_1\": \"friend\",\n",
    "    \"TU_1_1_1_2\": \"stranger\",\n",
    "    \"TU_1_1_2_1\": \"friend\",\n",
    "    \"TU_1_1_2_2\": \"stranger\",\n",
    "    \"TU_1_2_1_1\": \"friend\",\n",
    "    \"TU_1_2_1_2\": \"stranger\",\n",
    "    \"TU_1_2_2_1\": \"friend\",\n",
    "    \"TU_1_2_2_2\": \"stranger\",\n",
    "    \"TU_1_3_1_1\": \"friend\",\n",
    "    \"TU_1_3_1_2\": \"stranger\",\n",
    "    \"TU_1_3_2_1\": \"friend\",\n",
    "    \"TU_1_3_2_2\": \"stranger\",\n",
    "    \"TU_2_1_1_1\": \"friend\",\n",
    "    \"TU_2_1_1_2\": \"stranger\",\n",
    "    \"TU_2_1_2_1\": \"friend\",\n",
    "    \"TU_2_1_2_2\": \"stranger\",\n",
    "    \"TU_2_2_1_1\": \"friend\",\n",
    "    \"TU_2_2_1_2\": \"stranger\",\n",
    "    \"TU_2_2_2_1\": \"friend\",\n",
    "    \"TU_2_2_2_2\": \"stranger\",\n",
    "    \"TU_2_3_1_1\": \"friend\",\n",
    "    \"TU_2_3_1_2\": \"stranger\",\n",
    "    \"TU_2_3_2_1\": \"friend\",\n",
    "    \"TU_2_3_2_2\": \"stranger\",\n",
    "    \"TU_3_1_1_1\": \"friend\",\n",
    "    \"TU_3_1_1_2\": \"stranger\",\n",
    "    \"TU_3_1_2_1\": \"friend\",\n",
    "    \"TU_3_1_2_2\": \"stranger\",\n",
    "    \"TU_3_2_1_1\": \"friend\",\n",
    "    \"TU_3_2_1_2\": \"stranger\",\n",
    "    \"TU_3_2_2_1\": \"friend\",\n",
    "    \"TU_3_2_2_2\": \"stranger\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up functions to repeatedly prompt the LLMs\n",
    "\n",
    "- Helper function to extract dollar amount of given answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the dollar amount of the answer from LLMs\n",
    "def extract_dollar_amounts(answers):\n",
    "    # Only return values that start with \"$\"\n",
    "    valid_prices = [item for item in answers if item.startswith(\"$\")]\n",
    "    # Delete the \"$\" from the beginning of each price\n",
    "    prices = [item.replace('$', '') for item in valid_prices]\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times for OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment(experiment_id, n, progress_bar, temperature):\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = TU_model_dict[experiment_id], \n",
    "            max_tokens = 2,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer by only giving a single price in dollars and cents without an explanation.\"},        \n",
    "            {\"role\": \"user\", \"content\": \n",
    "             f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"}\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], TU_orientation_prices_dict[experiment_id], TU_buyers_dict[experiment_id], answers, n_observations]\n",
    "    #results = pd.DataFrame(results).set_index(pd.Index([\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\"]))\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for dashboard  (returns dataframe right away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to query 1 prompt n times (LLama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_run_experiment_llama(experiment_id, n, progress_bar, temperature):\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        response = replicate.run(\n",
    "            TU_model_dict[experiment_id],\n",
    "            input = {\n",
    "                \"system_prompt\":  \"Answer by only giving a single price in dollars and cents.\",\n",
    "                \"temperature\": temperature,\n",
    "                \"max_new_tokens\": 3, \n",
    "                \"prompt\": f\"{TU_experiment_prompts_dict[experiment_id]} Answer by only giving a single price in dollars and cents without an explanation.\"\n",
    "            }\n",
    "        )\n",
    "        # Grab answer and append to list\n",
    "        answer = \"\" # Set to empty string, otherwise it would append the previous answer to the new one\n",
    "        for item in response:\n",
    "            answer = answer + item\n",
    "        answers.append(answer.strip())\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    \n",
    "    # Extract valid prices from answers\n",
    "    valid_prices = extract_dollar_amounts(answers)\n",
    "\n",
    "    # Compute number of valid answers\n",
    "    n_observations = len(valid_prices)\n",
    "\n",
    "    # Collect results \n",
    "    results = [experiment_id, temperature, TU_model_dict[experiment_id], TU_initial_costs_dict[experiment_id], \n",
    "               TU_orientation_prices_dict[experiment_id], TU_buyers_dict[experiment_id], answers, n_observations]\n",
    "    #results = pd.DataFrame(results).set_index(pd.Index([\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\"]))\n",
    "    # Give out results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjusted function for dashboard (returns dataframe right away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "results = TU_run_experiment_llama(\"TU_3_1_1_1\", 10, tqdm(total=10), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop run_experiment() over a list of temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TU_3_1_1_1',\n",
       " 0.5,\n",
       " 'meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3',\n",
       " 0,\n",
       " 5,\n",
       " 'friend',\n",
       " ['$1', '$1', '$1', '$1', '$1', '$1', '$1', '$1', '$1', '$1'],\n",
       " 10]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TU_temperature_loop(function, experiment_id, temperature_list = [0.5, 1, 1.5], n = 50):\n",
    "    \"\"\"\n",
    "    Function to run an experiment with different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty list for storing results\n",
    "    results_list = []\n",
    "\n",
    "    # Initialize progress bar -> used as input for run_experiment()\n",
    "    progress_bar = tqdm(range(n*len(temperature_list)))\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results = function(experiment_id = experiment_id, n = n, temperature = temperature, progress_bar = progress_bar) \n",
    "        results_list.append(results)\n",
    "       \n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index([\"experiment_id\", \"temperature\", \"model\", \"initial_cost\", \"orientation_price\", \"buyer\", \"answers\", \"Obs.\"]))\n",
    "  \n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"In this run, a total of {n*len(temperature_list)} requests were made using {TU_prompt_ids_dict[experiment_id]}.\"\n",
    "    # Print information about the experiment\n",
    "    print(check)\n",
    " \n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GPT-3.5-turbo we make 100 requests per prompt & temperature value\n",
    "# Also, we will focus on lower temperature values to get more consise answers. For higher temperature values, the \n",
    "# answers almost always contain the same information, but come with an unnecessary explanation (e.g. \"I would ask for $10, because that is the price that everyone else is asking for.\")\n",
    "N = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_1_1\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = results_1.loc[\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results_1.loc[\"answers\"], bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_1_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_2_1\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_4 = TU_temperature_loop(TU_run_experiment, \"TU_1_1_2_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_1_1\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_6 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_1_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_7 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_2_1\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_8 = TU_temperature_loop(TU_run_experiment, \"TU_1_2_2_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_9 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_1_1\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_1_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_11 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_2_1\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_12 = TU_temperature_loop(TU_run_experiment, \"TU_1_3_2_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: GPT-4-1106-Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_1.append(results_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_2.append(results_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_3.append(results_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_4_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_1_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_4.append(results_4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_5.append(results_5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_6_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_6.append(results_6_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_7_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_7.append(results_7_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_8_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_2_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_8.append(results_8_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_9_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_9.append(results_9_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_1_2\", temperature_list = [0.5, 1, 1.5], n = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_11_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_11.append(results_11_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_12_2 = TU_temperature_loop(TU_run_experiment, \"TU_2_3_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_12.append(results_12_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: LLama-2-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_1.append(results_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_2.append(results_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_3.append(results_3_3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_4_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_1_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_4.append(results_4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_5.append(results_5_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_6_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_6.append(results_6_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_7_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_7.append(results_7_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_8_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_2_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_8.append(results_8_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_9_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_1_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_9.append(results_9_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_1_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_10.append(results_10_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_11_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_2_1\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_11.append(results_11_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_12_3 = TU_temperature_loop(TU_run_experiment_llama, \"TU_3_3_2_2\", temperature_list = [0.5, 1, 1.5], n = N)\n",
    "results_12.append(results_12_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather all results and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not yet sure if this works or has to be transposed etc..\n",
    "\n",
    "TU_results = pd.concat([results_1, results_2, results_3, results_4, results_5, results_6, results_7, results_8, results_9, results_10, results_11, results_12], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
