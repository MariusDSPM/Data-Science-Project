{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prospect Theory 2.0\n",
    "\n",
    "This notebook is a continuation of the previous notebook, where we will research how the concrete numbers of gains/losses in the prompts influence the model's response. \n",
    "\n",
    "In the *Decoy Effect* notebook we could see, that renaming the answer options does indeed have an effect on the distribution of survey replys. We therefore stick to the principle of using uncommon letters instead of the typical survey design of A:, B:, C:. This enables us to isolate the effect of changing the monetary values, free of possible biases e.g. the \"A-Bias\".\n",
    "\n",
    "In all the scenarios we described, the sum of money both described individuals have as exactly the same at the end of the day.\n",
    "Therefore, we first take a look at how survey replies change, if one individuum is in fact better off money-wise.\n",
    "\n",
    "Secondly, we take a look at how the magnitude of gains/and losses affect the responses. For this, we simply scale every number in a given prompt by the same factor.\n",
    "\n",
    "Since we previously established that, for practical purposes, the minimum temperature value of 0, as well as the maximum value of 2 do not really provide us with insightful results, we will now only focus on the values [0.5, 1, 1.5]. Also, the aspect of priming the models will not be regarded here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get API key (previously saved as environmental variable)\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set client\n",
    "client = OpenAI()\n",
    "\n",
    "# Set global plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set plots to be displayed in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"Mr. A was given tickets involving the World Series. He won 50$ in one lottery and $25 in the other. \n",
    "          Mr. B was given a ticket to a single, larger World Series lottery. He won $75. Based solely on this information, Who is happier? \n",
    "          A: Mister A\n",
    "          B: Mister B\n",
    "          C: No difference.         \n",
    "          Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Who is happier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = f\"\"\"Mr. A received a letter from the IRS saying that he made a minor arithmetical mistake on his tax return and owed $100. \n",
    "         He received a similar letter the same day from his state income tax authority saying he owed $50. There were no other repercussions from either mistake. \n",
    "         Mr. B received a letter from the IRS saying that he made a minor arithmetical mistake on his tax return and owed $150. There were no other repercussions from his mistake. \n",
    "         Based solely on this information, who was more upset? \n",
    "         A: Mister A\n",
    "         B: Mister B\n",
    "         C: No difference.\n",
    "         Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Who is more upset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = f\"\"\"Mr. A bought his first New York State lottery ticket and won $100. Also, in a freak accident, he damaged the rug in his apartment and had to pay the landlord $80.\n",
    "         Mr. B bought his first New York State lottery ticket and won $20. Based solely on this information, who is happier? \n",
    "         A: Mister A\n",
    "         B: Mister B\n",
    "         C: No difference.\n",
    "         Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Who is happier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = f\"\"\"Mr. A's car was damaged in a parking lot. He had to spend $200 to repair the damage. The same day the car was damaged, he won $25 in the office football pool.\n",
    "         Mr. B's car was damaged in a parking lot. He had to spend $175 to repair the damage. Based solely on this information, who is more upset?\n",
    "         A: Mister A\n",
    "         B: Mister B\n",
    "         C: No difference.\n",
    "         Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "\n",
    "# Who is more upset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modifying the monetary values inside the prompts\n",
    "\n",
    "The Prospect Theory value function explains why individuals tend to assess the perceived value of e.g. a sum of multiple gains as larger, than one individual sum of the same amount. Since Large Language Models are trained on human data, including for example customer reviews on sales platforms, they might reflect these patterns. \n",
    "But how do LLMs react, if in the given scenarios, one individual is financially clearly better off than the other? And what if we did not deal with small, even numbers, but rather large and odd ones? \n",
    "Another key concept of prospect theory is decreasing sensitivity. A loss of 50$ subtracted from a total amount of 1000$ will not hurt as much, as if we initially only had 100$, hence losing 50% of our total possession. \n",
    "\n",
    "In order to research these 2 aspects, we adapted our original prompts as follows:\n",
    "\n",
    "For every scenario (1-4) we created:\n",
    "- 2 prompts in which A and B have the same amount of money, but the numbers are odd and larger than before (scaled by Pi * 100 or 42 respectively) \n",
    "- 2 prompts in which A is better off (25$ vs. 50$)\n",
    "- 2 prompts in which B is better off (25$ vs. 50$)\n",
    "\n",
    "In the configurations, in which one individual is better off, we did not simply increase/decrease the same number in the prompt, but rather distributed the changes in gains/losses along the prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make our results comparable to the original study, we compute original answer probabilities\n",
    "p_scenario1 = [f\"p(A): {round((56/(56+16+15)*100), 2)}%\", f\"p(B): {round((16/(56+16+15)*100), 2)}%\", f\"p(C): {round((15/(56+16+15)*100), 2)}%\"]\n",
    "p_scenario2 = [f\"p(A): {round((66/(66+14+7)*100), 2)}%\", f\"p(B): {round((14/(66+14+7)*100), 2)}%\", f\"p(C): {round((7/(66+14+7)*100), 2)}%\"]\n",
    "p_scenario3 = [f\"p(A): {round((22/(22+61+4)*100), 2)}%\", f\"p(B): {round((61/(22+61+4)*100), 2)}%\", f\"p(C): {round((4/(22+61+4)*100), 2)}%\"]\n",
    "p_scenario4 = [f\"p(A): {round((19/(19+63+5)*100), 2)}%\", f\"p(B): {round((63/(19+63+5)*100), 2)}%\", f\"p(C): {round((5/(19+63+5)*100), 2)}%\"]\n",
    "\n",
    "# Setting up new monetary values to be used in our prompts, they do not really reflect prices, but will be named as such for simplicity\n",
    "prices_1_og = np.array([50, 25, 75]) # A won 50+25, B won 75\n",
    "prices_2_og = np.array([100, 50, 150]) # A lost 100+50, B lost 150\n",
    "prices_3_og = np.array([100, 80, 20]) # A won 100, lost 80, B won 20\n",
    "prices_4_og = np.array([200, 25, 175]) # A lost 200, won 25, B lost 175\n",
    "\n",
    "# New, rather odd-numbered values, but sum for A&B is the same\n",
    "prices_1_odd = np.round(prices_1_og.copy() * np.pi * 100, 2)\n",
    "prices_2_odd = np.round(prices_2_og.copy() * np.pi * 100, 2)\n",
    "prices_3_odd = np.round(prices_3_og.copy() * np.pi * 100, 2)\n",
    "prices_4_odd = np.round(prices_4_og.copy() * np.pi * 100, 2)\n",
    "\n",
    "prices_1_odd2 = np.round(prices_1_og.copy() * np.pi * 42, 2)\n",
    "prices_2_odd2 = np.round(prices_2_og.copy() * np.pi * 42, 2)\n",
    "prices_3_odd2 = np.round(prices_3_og.copy() * np.pi * 42, 2)\n",
    "prices_4_odd2 = np.round(prices_4_og.copy() * np.pi * 42, 2)\n",
    "\n",
    "# Prices, so that A is always better off (labeled as prices_(original scenario)_(who is better off))\n",
    "# We do not simply always increase the first mentioned gain/decrease the first mentioned loss, but rather try and \"distribute\" the changes \n",
    "# Per prompt, only the same number will be changed, but over all prompts, the changes will be distributed\n",
    "\n",
    "# A always better off by 25$\n",
    "prices_1_a25 = prices_1_og.copy() \n",
    "prices_1_a25[0] += 25\n",
    "prices_2_a25 = prices_2_og.copy()\n",
    "prices_2_a25[1] += -25\n",
    "prices_3_a25 = prices_3_og.copy()\n",
    "prices_3_a25[1] += -25\n",
    "prices_4_a25 = prices_4_og.copy()\n",
    "prices_4_a25[2] += +25\n",
    "\n",
    "# A always better off by 50$\n",
    "prices_1_a50 = prices_1_og.copy()\n",
    "prices_1_a50[0] += 50\n",
    "prices_2_a50 = prices_2_og.copy()\n",
    "prices_2_a50[1] += -50\n",
    "prices_3_a50 = prices_3_og.copy()\n",
    "prices_3_a50[1] += -50\n",
    "prices_4_a50 = prices_4_og.copy()\n",
    "prices_4_a50[2] += +50\n",
    "\n",
    "# B always better off by 25$\n",
    "prices_1_b25 = prices_1_og.copy()\n",
    "prices_1_b25[0] += -25\n",
    "prices_2_b25 = prices_2_og.copy()\n",
    "prices_2_b25[1] += +25\n",
    "prices_3_b25 = prices_3_og.copy()\n",
    "prices_3_b25[1] += 25\n",
    "prices_4_b25 = prices_4_og.copy()\n",
    "prices_4_b25[2] += -25\n",
    "\n",
    "# B always better off by 50$\n",
    "prices_1_b50 = prices_1_og.copy()\n",
    "prices_1_b50[0] += -50\n",
    "prices_2_b50 = prices_2_og.copy()\n",
    "prices_2_b50[1] += +50\n",
    "prices_3_b50 = prices_3_og.copy()\n",
    "prices_3_b50[1] += 50\n",
    "prices_4_b50 = prices_4_og.copy()\n",
    "prices_4_b50[2] += -50\n",
    "\n",
    "# Pretty sure there is an easier way, but this is at least robust and easily controllable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set up new prompts with modified numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts for scenario 1\n",
    "prompts_1 = []\n",
    "\n",
    "for prices in [prices_1_odd, prices_1_odd2, prices_1_a25, prices_1_a50, prices_1_b25, prices_1_b50]:\n",
    "    prompt = f\"\"\"Mr. A was given tickets involving the World Series. He won {prices[0]}$ in one lottery and {prices[1]}$ in the other. \n",
    "          Mr. B was given a ticket to a single, larger World Series lottery. He won {prices[2]}$. Based solely on this information, Who is happier? \n",
    "          A: Mister A\n",
    "          B: Mister B\n",
    "          C: No difference.         \n",
    "          Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "    prompts_1.append(prompt)\n",
    "# Who is happier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts for scenario 2\n",
    "prompts_2 = []\n",
    "\n",
    "for prices in [prices_2_odd, prices_2_odd2, prices_2_a25, prices_2_a50, prices_2_b25, prices_2_b50]:\n",
    "    prompt = f\"\"\"Mr. A received a letter from the IRS saying that he made a minor arithmetical mistake on his tax return and owed ${prices[0]}. \n",
    "         He received a similar letter the same day from his state income tax authority saying he owed ${prices[1]}. There were no other repercussions from either mistake. \n",
    "         Mr. B received a letter from the IRS saying that he made a minor arithmetical mistake on his tax return and owed ${prices[2]}. There were no other repercussions from his mistake. \n",
    "         Based solely on this information, who was more upset? \n",
    "         A: Mister A\n",
    "         B: Mister B\n",
    "         C: No difference.\n",
    "         Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "    prompts_2.append(prompt)\n",
    "\n",
    "# Who is more upset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts for scenario 3\n",
    "prompts_3 = []\n",
    "\n",
    "for prices in [prices_3_odd, prices_3_odd2, prices_3_a25, prices_3_a50, prices_3_b25, prices_3_b50]:\n",
    "    prompt = f\"\"\"Mr. A bought his first New York State lottery ticket and won ${prices[0]}. Also, in a freak accident, he damaged the rug in his apartment and had to pay the landlord ${prices[1]}.\n",
    "         Mr. B bought his first New York State lottery ticket and won ${prices[2]}. Based solely on this information, who is happier? \n",
    "         A: Mister A\n",
    "         B: Mister B\n",
    "         C: No difference.\n",
    "         Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "    prompts_3.append(prompt)\n",
    "\n",
    "# Who is happier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts for scenario 4\n",
    "prompts_4 = []\n",
    "\n",
    "for prices in [prices_4_odd, prices_4_odd2, prices_4_a25, prices_4_a50, prices_4_b25, prices_4_b50]:\n",
    "    prompt = f\"\"\"Mr. A's car was damaged in a parking lot. He had to spend ${prices[0]} to repair the damage. The same day the car was damaged, he won ${prices[1]} in the office football pool.\n",
    "         Mr. B's car was damaged in a parking lot. He had to spend ${prices[2]} to repair the damage. Based solely on this information, who is more upset?\n",
    "         A: Mister A\n",
    "         B: Mister B\n",
    "         C: No difference.\n",
    "         Which option would you choose? Please answer by only giving the letter of the alternative you would choose without any reasoning.\"\"\"\n",
    "    prompts_4.append(prompt)\n",
    "# Who is more upset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the notebook, we use experiment IDs, that help us extract prompts and price vectors used for the experiments. We construct them as follows:\n",
    "\n",
    "- scenario_model_configuration\n",
    "\n",
    "The model attribute refers to the Language Model we are using, namely:\n",
    "- 1: GPT-3.5-Turbo\n",
    "- 2: GPT-4-1106-Preview\n",
    "\n",
    "Configuration refers to the price vector used in this experiment. We number them as follows:\n",
    "- 1: Odd prices 1 (Original * Pi * 100)\n",
    "- 2: Odd prices 2 (Original * Pi * 42 )\n",
    "- 3: A is better off by 25$\n",
    "- 4: A is better off by 50$\n",
    "- 5: B is better off by 25$\n",
    "- 6: B is better off by 50$\n",
    "\n",
    "Experiment id 2_2_4 therefore reads as: Scenario 2, using GPT-4-1106-Preview, where A is better off by 50$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to look up prompt for a given experiment id. key: experiment id, value: prompt\n",
    "experiment_prompts_dict = {\n",
    "    \"1_1_1\": prompts_1[0],\n",
    "    \"1_1_2\": prompts_1[1],\n",
    "    \"1_1_3\": prompts_1[2],\n",
    "    \"1_1_4\": prompts_1[3],\n",
    "    \"1_1_5\": prompts_1[4],\n",
    "    \"1_1_6\": prompts_1[5],\n",
    "    \"2_1_1\": prompts_2[0],\n",
    "    \"2_1_2\": prompts_2[1],\n",
    "    \"2_1_3\": prompts_2[2],\n",
    "    \"2_1_4\": prompts_2[3],\n",
    "    \"2_1_5\": prompts_2[4],\n",
    "    \"2_1_6\": prompts_2[5],\n",
    "    \"3_1_1\": prompts_3[0],\n",
    "    \"3_1_2\": prompts_3[1],\n",
    "    \"3_1_3\": prompts_3[2],\n",
    "    \"3_1_4\": prompts_3[3],\n",
    "    \"3_1_5\": prompts_3[4],\n",
    "    \"3_1_6\": prompts_3[5],\n",
    "    \"4_1_1\": prompts_4[0],\n",
    "    \"4_1_2\": prompts_4[1],\n",
    "    \"4_1_3\": prompts_4[2],\n",
    "    \"4_1_4\": prompts_4[3],\n",
    "    \"4_1_5\": prompts_4[4],\n",
    "    \"4_1_6\": prompts_4[5],\n",
    "    \"1_2_1\": prompts_1[0],\n",
    "    \"1_2_2\": prompts_1[1],\n",
    "    \"1_2_3\": prompts_1[2],\n",
    "    \"1_2_4\": prompts_1[3],\n",
    "    \"1_2_5\": prompts_1[4],\n",
    "    \"1_2_6\": prompts_1[5],\n",
    "    \"2_2_1\": prompts_2[0],\n",
    "    \"2_2_2\": prompts_2[1],\n",
    "    \"2_2_3\": prompts_2[2],\n",
    "    \"2_2_4\": prompts_2[3],\n",
    "    \"2_2_5\": prompts_2[4],\n",
    "    \"2_2_6\": prompts_2[5],\n",
    "    \"3_2_1\": prompts_3[0],\n",
    "    \"3_2_2\": prompts_3[1],\n",
    "    \"3_2_3\": prompts_3[2],\n",
    "    \"3_2_4\": prompts_3[3],\n",
    "    \"3_2_5\": prompts_3[4],\n",
    "    \"3_2_6\": prompts_3[5],\n",
    "    \"4_2_1\": prompts_4[0],\n",
    "    \"4_2_2\": prompts_4[1],\n",
    "    \"4_2_3\": prompts_4[2],\n",
    "    \"4_2_4\": prompts_4[3],\n",
    "    \"4_2_5\": prompts_4[4],\n",
    "    \"4_2_6\": prompts_4[5],\n",
    "}\n",
    "\n",
    "# Dictionary to look up price vector used for experiment id. key: experiment id, value: price vector\n",
    "prices_dict = {\n",
    "    \"1_1_1\": prices_1_odd,\n",
    "    \"1_1_2\": prices_1_odd2,\n",
    "    \"1_1_3\": prices_1_a25,\n",
    "    \"1_1_4\": prices_1_a50,\n",
    "    \"1_1_5\": prices_1_b25,\n",
    "    \"1_1_6\": prices_1_b50,\n",
    "    \"2_1_1\": prices_2_odd,\n",
    "    \"2_1_2\": prices_2_odd2,\n",
    "    \"2_1_3\": prices_2_a25,\n",
    "    \"2_1_4\": prices_2_a50,\n",
    "    \"2_1_5\": prices_2_b25,\n",
    "    \"2_1_6\": prices_2_b50,\n",
    "    \"3_1_1\": prices_3_odd,\n",
    "    \"3_1_2\": prices_3_odd2,\n",
    "    \"3_1_3\": prices_3_a25,\n",
    "    \"3_1_4\": prices_3_a50,\n",
    "    \"3_1_5\": prices_3_b25,\n",
    "    \"3_1_6\": prices_3_b50,\n",
    "    \"4_1_1\": prices_4_odd,\n",
    "    \"4_1_2\": prices_4_odd2,\n",
    "    \"4_1_3\": prices_4_a25,\n",
    "    \"4_1_4\": prices_4_a50,\n",
    "    \"4_1_5\": prices_4_b25,\n",
    "    \"4_1_6\": prices_4_b50,\n",
    "    \"1_2_1\": prices_1_odd,\n",
    "    \"1_2_2\": prices_1_odd2,\n",
    "    \"1_2_3\": prices_1_a25,\n",
    "    \"1_2_4\": prices_1_a50,\n",
    "    \"1_2_5\": prices_1_b25,\n",
    "    \"1_2_6\": prices_1_b50,\n",
    "    \"2_2_1\": prices_2_odd,\n",
    "    \"2_2_2\": prices_2_odd2,\n",
    "    \"2_2_3\": prices_2_a25,\n",
    "    \"2_2_4\": prices_2_a50,\n",
    "    \"2_2_5\": prices_2_b25,\n",
    "    \"2_2_6\": prices_2_b50,\n",
    "    \"3_2_1\": prices_3_odd,\n",
    "    \"3_2_2\": prices_3_odd2,\n",
    "    \"3_2_3\": prices_3_a25,\n",
    "    \"3_2_4\": prices_3_a50,\n",
    "    \"3_2_5\": prices_3_b25,\n",
    "    \"3_2_6\": prices_3_b50,\n",
    "    \"4_2_1\": prices_4_odd,\n",
    "    \"4_2_2\": prices_4_odd2,\n",
    "    \"4_2_3\": prices_4_a25,\n",
    "    \"4_2_4\": prices_4_a50,\n",
    "    \"4_2_5\": prices_4_b25,\n",
    "    \"4_2_6\": prices_4_b50,\n",
    "}\n",
    "\n",
    "# Dictionary to look up the original results for a given experiment id. key: experiment id, value: original answer probabilities\n",
    "results_dict = {\n",
    "    \"1_1_1\": p_scenario1,\n",
    "    \"1_1_2\": p_scenario1,\n",
    "    \"1_1_3\": p_scenario1,\n",
    "    \"1_1_4\": p_scenario1,\n",
    "    \"1_1_5\": p_scenario1,\n",
    "    \"1_1_6\": p_scenario1,\n",
    "    \"2_1_1\": p_scenario2,\n",
    "    \"2_1_2\": p_scenario2,\n",
    "    \"2_1_3\": p_scenario2,\n",
    "    \"2_1_4\": p_scenario2,\n",
    "    \"2_1_5\": p_scenario2,\n",
    "    \"2_1_6\": p_scenario2,\n",
    "    \"3_1_1\": p_scenario3,\n",
    "    \"3_1_2\": p_scenario3,\n",
    "    \"3_1_3\": p_scenario3,\n",
    "    \"3_1_4\": p_scenario3,\n",
    "    \"3_1_5\": p_scenario3,\n",
    "    \"3_1_6\": p_scenario3,\n",
    "    \"4_1_1\": p_scenario4,\n",
    "    \"4_1_2\": p_scenario4,\n",
    "    \"4_1_3\": p_scenario4,\n",
    "    \"4_1_4\": p_scenario4,\n",
    "    \"4_1_5\": p_scenario4,\n",
    "    \"4_1_6\": p_scenario4,\n",
    "    \"1_2_1\": p_scenario1,\n",
    "    \"1_2_2\": p_scenario1,\n",
    "    \"1_2_3\": p_scenario1,\n",
    "    \"1_2_4\": p_scenario1,\n",
    "    \"1_2_5\": p_scenario1,\n",
    "    \"1_2_6\": p_scenario1,\n",
    "    \"2_2_1\": p_scenario2,\n",
    "    \"2_2_2\": p_scenario2,\n",
    "    \"2_2_3\": p_scenario2,\n",
    "    \"2_2_4\": p_scenario2,\n",
    "    \"2_2_5\": p_scenario2,\n",
    "    \"2_2_6\": p_scenario2,\n",
    "    \"3_2_1\": p_scenario3,\n",
    "    \"3_2_2\": p_scenario3,\n",
    "    \"3_2_3\": p_scenario3,\n",
    "    \"3_2_4\": p_scenario3,\n",
    "    \"3_2_5\": p_scenario3,\n",
    "    \"3_2_6\": p_scenario3,\n",
    "    \"4_2_1\": p_scenario4,\n",
    "    \"4_2_2\": p_scenario4,\n",
    "    \"4_2_3\": p_scenario4,\n",
    "    \"4_2_4\": p_scenario4,\n",
    "    \"4_2_5\": p_scenario4,\n",
    "    \"4_2_6\": p_scenario4,\n",
    "}\n",
    "\n",
    "# Dictionary to look up which model to use for a given experiment id. key: experiment id, value: model name\n",
    "model_dict = {\n",
    "    \"1_1_1\": \"gpt-3.5-turbo\",  \n",
    "    \"1_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"1_1_3\": \"gpt-3.5-turbo\",\n",
    "    \"1_1_4\": \"gpt-3.5-turbo\",\n",
    "    \"1_1_5\": \"gpt-3.5-turbo\",\n",
    "    \"1_1_6\": \"gpt-3.5-turbo\",\n",
    "    \"2_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"2_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"2_1_3\": \"gpt-3.5-turbo\",\n",
    "    \"2_1_4\": \"gpt-3.5-turbo\",\n",
    "    \"2_1_5\": \"gpt-3.5-turbo\",\n",
    "    \"2_1_6\": \"gpt-3.5-turbo\",\n",
    "    \"3_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"3_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"3_1_3\": \"gpt-3.5-turbo\",\n",
    "    \"3_1_4\": \"gpt-3.5-turbo\",\n",
    "    \"3_1_5\": \"gpt-3.5-turbo\",\n",
    "    \"3_1_6\": \"gpt-3.5-turbo\",\n",
    "    \"4_1_1\": \"gpt-3.5-turbo\",\n",
    "    \"4_1_2\": \"gpt-3.5-turbo\",\n",
    "    \"4_1_3\": \"gpt-3.5-turbo\",\n",
    "    \"4_1_4\": \"gpt-3.5-turbo\",\n",
    "    \"4_1_5\": \"gpt-3.5-turbo\",\n",
    "    \"4_1_6\": \"gpt-3.5-turbo\",\n",
    "    \"1_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"1_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"1_2_3\": \"gpt-4-1106-preview\",\n",
    "    \"1_2_4\": \"gpt-4-1106-preview\",\n",
    "    \"1_2_5\": \"gpt-4-1106-preview\",\n",
    "    \"1_2_6\": \"gpt-4-1106-preview\",\n",
    "    \"2_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"2_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"2_2_3\": \"gpt-4-1106-preview\",\n",
    "    \"2_2_4\": \"gpt-4-1106-preview\",\n",
    "    \"2_2_5\": \"gpt-4-1106-preview\",\n",
    "    \"2_2_6\": \"gpt-4-1106-preview\",\n",
    "    \"3_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"3_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"3_2_3\": \"gpt-4-1106-preview\",\n",
    "    \"3_2_4\": \"gpt-4-1106-preview\",\n",
    "    \"3_2_5\": \"gpt-4-1106-preview\",\n",
    "    \"3_2_6\": \"gpt-4-1106-preview\",\n",
    "    \"4_2_1\": \"gpt-4-1106-preview\",\n",
    "    \"4_2_2\": \"gpt-4-1106-preview\",\n",
    "    \"4_2_3\": \"gpt-4-1106-preview\",\n",
    "    \"4_2_4\": \"gpt-4-1106-preview\",\n",
    "    \"4_2_5\": \"gpt-4-1106-preview\",\n",
    "    \"4_2_6\": \"gpt-4-1106-preview\",\n",
    "    }\n",
    "\n",
    "# Dictionary to look up what prompt was used for a given experiment id. key: experiment id, value: prompt variable name\n",
    "prompt_ids_dict = {\n",
    "    \"1_1_1\": \"prompts_1[0]\",\n",
    "    \"1_1_2\": \"prompts_1[1]\",\n",
    "    \"1_1_3\": \"prompts_1[2]\",\n",
    "    \"1_1_4\": \"prompts_1[3]\",\n",
    "    \"1_1_5\": \"prompts_1[4]\",\n",
    "    \"1_1_6\": \"prompts_1[5]\",\n",
    "    \"2_1_1\": \"prompts_2[0]\",\n",
    "    \"2_1_2\": \"prompts_2[1]\",\n",
    "    \"2_1_3\": \"prompts_2[2]\",\n",
    "    \"2_1_4\": \"prompts_2[3]\",\n",
    "    \"2_1_5\": \"prompts_2[4]\",\n",
    "    \"2_1_6\": \"prompts_2[5]\",\n",
    "    \"3_1_1\": \"prompts_3[0]\",\n",
    "    \"3_1_2\": \"prompts_3[1]\",\n",
    "    \"3_1_3\": \"prompts_3[2]\",\n",
    "    \"3_1_4\": \"prompts_3[3]\",\n",
    "    \"3_1_5\": \"prompts_3[4]\",\n",
    "    \"3_1_6\": \"prompts_3[5]\",\n",
    "    \"4_1_1\": \"prompts_4[0]\",\n",
    "    \"4_1_2\": \"prompts_4[1]\",\n",
    "    \"4_1_3\": \"prompts_4[2]\",\n",
    "    \"4_1_4\": \"prompts_4[3]\",\n",
    "    \"4_1_5\": \"prompts_4[4]\",\n",
    "    \"4_1_6\": \"prompts_4[5]\",\n",
    "    \"1_2_1\": \"prompts_1[0]\",\n",
    "    \"1_2_2\": \"prompts_1[1]\",\n",
    "    \"1_2_3\": \"prompts_1[2]\",\n",
    "    \"1_2_4\": \"prompts_1[3]\",\n",
    "    \"1_2_5\": \"prompts_1[4]\",\n",
    "    \"1_2_6\": \"prompts_1[5]\",\n",
    "    \"2_2_1\": \"prompts_2[0]\",\n",
    "    \"2_2_2\": \"prompts_2[1]\",\n",
    "    \"2_2_3\": \"prompts_2[2]\",\n",
    "    \"2_2_4\": \"prompts_2[3]\",\n",
    "    \"2_2_5\": \"prompts_2[4]\",\n",
    "    \"2_2_6\": \"prompts_2[5]\",\n",
    "    \"3_2_1\": \"prompts_3[0]\",\n",
    "    \"3_2_2\": \"prompts_3[1]\",\n",
    "    \"3_2_3\": \"prompts_3[2]\",\n",
    "    \"3_2_4\": \"prompts_3[3]\",\n",
    "    \"3_2_5\": \"prompts_3[4]\",\n",
    "    \"3_2_6\": \"prompts_3[5]\",\n",
    "    \"4_2_1\": \"prompts_4[0]\",\n",
    "    \"4_2_2\": \"prompts_4[1]\",\n",
    "    \"4_2_3\": \"prompts_4[2]\",\n",
    "    \"4_2_4\": \"prompts_4[3]\",\n",
    "    \"4_2_5\": \"prompts_4[4]\",\n",
    "    \"4_2_6\": \"prompts_4[5]\",\n",
    "}\n",
    "\n",
    "# Dictionary to look up scenario number for a given experiment id. key: experiment id, value: scenario number\n",
    "scenario_dict = {\n",
    "    \"1_1_1\": 1,\n",
    "    \"1_1_2\": 1,\n",
    "    \"1_1_3\": 1,\n",
    "    \"1_1_4\": 1,\n",
    "    \"1_1_5\": 1,\n",
    "    \"1_1_6\": 1,\n",
    "    \"2_1_1\": 2,\n",
    "    \"2_1_2\": 2,\n",
    "    \"2_1_3\": 2,\n",
    "    \"2_1_4\": 2,\n",
    "    \"2_1_5\": 2,\n",
    "    \"2_1_6\": 2,\n",
    "    \"3_1_1\": 3,\n",
    "    \"3_1_2\": 3,\n",
    "    \"3_1_3\": 3,\n",
    "    \"3_1_4\": 3,\n",
    "    \"3_1_5\": 3,\n",
    "    \"3_1_6\": 3,\n",
    "    \"4_1_1\": 4,\n",
    "    \"4_1_2\": 4,\n",
    "    \"4_1_3\": 4,\n",
    "    \"4_1_4\": 4,\n",
    "    \"4_1_5\": 4,\n",
    "    \"4_1_6\": 4,\n",
    "    \"1_2_1\": 1,\n",
    "    \"1_2_2\": 1,\n",
    "    \"1_2_3\": 1,\n",
    "    \"1_2_4\": 1,\n",
    "    \"1_2_5\": 1,\n",
    "    \"1_2_6\": 1,\n",
    "    \"2_2_1\": 2,\n",
    "    \"2_2_2\": 2, \n",
    "    \"2_2_3\": 2,\n",
    "    \"2_2_4\": 2,\n",
    "    \"2_2_5\": 2,\n",
    "    \"2_2_6\": 2,\n",
    "    \"3_2_1\": 3,\n",
    "    \"3_2_2\": 3,\n",
    "    \"3_2_3\": 3,\n",
    "    \"3_2_4\": 3,\n",
    "    \"3_2_5\": 3,\n",
    "    \"3_2_6\": 3,\n",
    "    \"4_2_1\": 4,\n",
    "    \"4_2_2\": 4,\n",
    "    \"4_2_3\": 4,\n",
    "    \"4_2_4\": 4,\n",
    "    \"4_2_5\": 4,\n",
    "    \"4_2_6\": 4,\n",
    "}\n",
    "\n",
    "# Dictionary to look up scenario configuration based on experiment id. key: experiment id, value: scenario configuration\n",
    "configuration_dict = {\n",
    "    \"1_1_1\": 1,\n",
    "    \"1_1_2\": 2,\n",
    "    \"1_1_3\": 3,\n",
    "    \"1_1_4\": 4,\n",
    "    \"1_1_5\": 5,\n",
    "    \"1_1_6\": 6,\n",
    "    \"2_1_1\": 1,\n",
    "    \"2_1_2\": 2,\n",
    "    \"2_1_3\": 3,\n",
    "    \"2_1_4\": 4,\n",
    "    \"2_1_5\": 5,\n",
    "    \"2_1_6\": 6,\n",
    "    \"3_1_1\": 1,\n",
    "    \"3_1_2\": 2,\n",
    "    \"3_1_3\": 3,\n",
    "    \"3_1_4\": 4,\n",
    "    \"3_1_5\": 5,\n",
    "    \"3_1_6\": 6,\n",
    "    \"4_1_1\": 1,\n",
    "    \"4_1_2\": 2,\n",
    "    \"4_1_3\": 3,\n",
    "    \"4_1_4\": 4,\n",
    "    \"4_1_5\": 5,\n",
    "    \"4_1_6\": 6,\n",
    "    \"1_2_1\": 1,\n",
    "    \"1_2_2\": 2,\n",
    "    \"1_2_3\": 3,\n",
    "    \"1_2_4\": 4,\n",
    "    \"1_2_5\": 5,\n",
    "    \"1_2_6\": 6,\n",
    "    \"2_2_1\": 1,\n",
    "    \"2_2_2\": 2,\n",
    "    \"2_2_3\": 3,\n",
    "    \"2_2_4\": 4,\n",
    "    \"2_2_5\": 5,\n",
    "    \"2_2_6\": 6,\n",
    "    \"3_2_1\": 1,\n",
    "    \"3_2_2\": 2,\n",
    "    \"3_2_3\": 3,\n",
    "    \"3_2_4\": 4,\n",
    "    \"3_2_5\": 5,\n",
    "    \"3_2_6\": 6,\n",
    "    \"4_2_1\": 1,\n",
    "    \"4_2_2\": 2,\n",
    "    \"4_2_3\": 3,\n",
    "    \"4_2_4\": 4,\n",
    "    \"4_2_5\": 5,\n",
    "    \"4_2_6\": 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up functions to repeatedly prompt ChatGPT\n",
    "\n",
    "- Functions to query 1 prompt n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_id, n, progress_bar, temperature):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT multiple times with a survey having answers designed as: A, B, C.\n",
    "    \n",
    "    Args:\n",
    "        experiment_id (str): ID of the experiment to be run. Contains info about prompt and model\n",
    "        n (int): Number of queries to be made\n",
    "        temperature (int): Degree of randomness with range 0 (deterministic) to 2 (random)\n",
    "        max_tokens (int): Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results (list): List containing count of answers for each option, also containing experiment_id, temperature and number of observations\n",
    "        probs (list): List containing probability of each option being chosen, also containing experiment_id, temeperature and number of observations\n",
    "    \"\"\"\n",
    "    \n",
    "    answers = []\n",
    "    for _ in range(n): \n",
    "        response = client.chat.completions.create(\n",
    "            model = model_dict[experiment_id], \n",
    "            max_tokens = 1,\n",
    "            temperature = temperature, # range is 0 to 2\n",
    "            messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Only answer with 1 letter.\"},        \n",
    "            {\"role\": \"user\", \"content\": experiment_prompts_dict[experiment_id]},\n",
    "                   ])\n",
    "\n",
    "        # Store the answer in the list\n",
    "        answer = response.choices[0].message.content\n",
    "        answers.append(answer.strip())\n",
    "        # Update progress bar (given from either temperature loop, or set locally)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Counting results\n",
    "    A = answers.count(\"A\") # set to Q\n",
    "    B = answers.count(\"B\") # set to X\n",
    "    C = answers.count(\"C\") # set to Y\n",
    "\n",
    "    # Count of \"correct\" answers, sums over indicator function thack checks if answer is either A, B or C\n",
    "    len_correct = sum(1 for ans in answers if ans in [\"A\", \"B\", \"C\"])\n",
    "\n",
    "    # Collecting results in a list\n",
    "    results = [experiment_id, temperature, A, B, C, len_correct, model_dict[experiment_id], scenario_dict[experiment_id], configuration_dict[experiment_id]]\n",
    "\n",
    "    # Getting percentage each answer\n",
    "    p_a = f\"{(A / len_correct) * 100:.2f}%\"\n",
    "    p_b = f\"{(B / len_correct) * 100:.2f}%\"\n",
    "    p_c = f\"{(C / len_correct) * 100:.2f}%\"\n",
    "\n",
    "    # Collect probabilities in a dataframe\n",
    "    probs = [experiment_id, temperature, p_a, p_b, p_c, len_correct, model_dict[experiment_id], scenario_dict[experiment_id], configuration_dict[experiment_id]]\n",
    "    \n",
    "    # Give out results\n",
    "    return results, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to loop run_experiment() over a list of temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_loop(function, experiment_id, temperature_list = [0.5, 1, 1.5], n = 50):\n",
    "    \"\"\"\n",
    "    Function to run an experiment with different temperature values.\n",
    "    \n",
    "    Args:\n",
    "        function (function): Function to be used for querying ChatGPT i.e. run_experiment()\n",
    "        experiment_id (str): ID of th e experiment to be run. Contains info about prompt and model\n",
    "        temperature_list (list): List of temperature values to be looped over\n",
    "        n: Number of requests for each prompt per temperature value\n",
    "        max_tokens: Maximum number of tokens in response object\n",
    "        \n",
    "    Returns:\n",
    "        results_df: Dataframe with experiment results\n",
    "        probs_df: Dataframe with answer probabilities\n",
    "    \"\"\"    \n",
    "    # Empty lists for storing results\n",
    "    results_list = []\n",
    "    probs_list = []\n",
    "    # Initialize progress bar -> used as input for run_experiment()\n",
    "    progress_bar = tqdm(range(n*len(temperature_list)))\n",
    "\n",
    "    # Loop over different temperature values, calling the input function n times each (i.e. queriyng ChatGPT n times)\n",
    "    for temperature in temperature_list:\n",
    "        results, probs = function(experiment_id = experiment_id, n = n, temperature = temperature, progress_bar = progress_bar) \n",
    "        results_list.append(results)\n",
    "        probs_list.append(probs)\n",
    "\n",
    "    # Horizontally concatenate the results, transpose, and set index\n",
    "    results_df = pd.DataFrame(results_list).transpose().set_index(pd.Index([\"Experiment\", \"Temp\", \"p(A)\", \"p(B)\", \"p(C)\", \"Obs.\", \"Model\", \"Scenario\", \"Configuration\"]))\n",
    "    probs_df = pd.DataFrame(probs_list).transpose().set_index(pd.Index([\"Experiment\", \"Temp\", \"p(A)\", \"p(B)\", \"p(C)\", \"Obs.\", \"Model\", \"Scenario\", \"Configuration\"]))\n",
    "   \n",
    "    # Return some information about the experiment as a check\n",
    "    check = f\"In this run, a total of {n*len(temperature_list)} requests were made using {prompt_ids_dict[experiment_id]}.\"\n",
    "    # Print information about the experiment\n",
    "    print(check)\n",
    "    # Print original results \n",
    "    # print(f\"The original results were {results_dict[experiment_id]}.\")\n",
    "\n",
    "    return results_df, probs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_results, test_probs = temperature_loop(run_experiment, \"1_1_1\", temperature_list = [0.5, 1, 1.5], n = 5)\n",
    "#test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_results2, test_probs2 = temperature_loop(run_experiment, \"1_1_2\", temperature_list = [0.5, 1, 1.5], n = 5)\n",
    "#test_probs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GPT-3.5-turbo we make 100 requests per prompt & temperature value\n",
    "N = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:03<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_1[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:27<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_1[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:24<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_1[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:30<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_1[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:58<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_1[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:26<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_1[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probs_scenario1 = []\n",
    "for experiment_id in [\"1_1_1\", \"1_1_2\", \"1_1_3\", \"1_1_4\", \"1_1_5\", \"1_1_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario1.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>1_1_1</td>\n",
       "      <td>1_1_1</td>\n",
       "      <td>1_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(A)</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>20.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(B)</th>\n",
       "      <td>60.00%</td>\n",
       "      <td>40.00%</td>\n",
       "      <td>60.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p(C)</th>\n",
       "      <td>40.00%</td>\n",
       "      <td>40.00%</td>\n",
       "      <td>40.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scenaro</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Configuration</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0              1              2\n",
       "Experiment             1_1_1          1_1_1          1_1_1\n",
       "Temp                     0.5            1.0            1.5\n",
       "p(A)                   0.00%         20.00%          0.00%\n",
       "p(B)                  60.00%         40.00%         60.00%\n",
       "p(C)                  40.00%         40.00%         40.00%\n",
       "Obs.                       5              5              5\n",
       "Model          gpt-3.5-turbo  gpt-3.5-turbo  gpt-3.5-turbo\n",
       "Scenaro                    1              1              1\n",
       "Configuration              1              1              1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probs1 = pd.concat(probs_scenario1_test, axis = 1)\n",
    "#probs1.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:25<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_2[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_2[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:27<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_2[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:19<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_2[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:38<00:00,  1.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_2[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:32<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_2[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probs_scenario2 = []\n",
    "for experiment_id in [\"2_1_1\", \"2_1_2\", \"2_1_3\", \"2_1_4\", \"2_1_5\", \"2_1_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario2.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:25<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_3[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:27<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_3[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:27<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_3[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:24<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_3[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:31<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_3[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:38<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_3[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probs_scenario3 = []\n",
    "for experiment_id in [\"3_1_1\", \"3_1_2\", \"3_1_3\", \"3_1_4\", \"3_1_5\", \"3_1_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario3.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:32<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_4[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:25<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_4[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:19<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_4[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:27<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_4[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_4[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:29<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 300 requests were made using prompts_4[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probs_scenario4 = []\n",
    "for experiment_id in [\"4_1_1\", \"4_1_2\", \"4_1_3\", \"4_1_4\", \"4_1_5\", \"4_1_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario4.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: GPT-4-1106-Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since GPT-4 is a much more expensive model, we only make 50 requests per prompt & temperature value\n",
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:42<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_1[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:31<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_1[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:05<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_1[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:42<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_1[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:34<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_1[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:29<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_1[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment_id in [\"1_2_1\", \"1_2_2\", \"1_2_3\", \"1_2_4\", \"1_2_5\", \"1_2_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario1.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:40<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_2[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:31<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_2[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:38<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_2[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:11<00:00,  1.28s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_2[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:41<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_2[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:39<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_2[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment_id in [\"2_2_1\", \"2_2_2\", \"2_2_3\", \"2_2_4\", \"2_2_5\", \"2_2_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario2.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:34<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_3[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [04:40<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_3[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:32<00:00,  4.62s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_3[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:36<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_3[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [21:39<00:00,  8.67s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_3[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:34<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_3[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment_id in [\"3_2_1\", \"3_2_2\", \"3_2_3\", \"3_2_4\", \"3_2_5\", \"3_2_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario3.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:48<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_4[0].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:31<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_4[1].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:32<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_4[2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:30<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_4[3].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:06<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_4[4].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:40<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this run, a total of 150 requests were made using prompts_4[5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment_id in [\"4_2_1\", \"4_2_2\", \"4_2_3\", \"4_2_4\", \"4_2_5\", \"4_2_6\"]:\n",
    "    results, probs = temperature_loop(run_experiment, experiment_id, temperature_list = [0.5, 1, 1.5], n = N)\n",
    "    probs_scenario4.append(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_scenario1 = pd.concat(probs_scenario1, axis = 1).transpose()\n",
    "probs_scenario2 = pd.concat(probs_scenario2, axis = 1).transpose()\n",
    "probs_scenario3 = pd.concat(probs_scenario3, axis = 1).transpose()\n",
    "probs_scenario4 = pd.concat(probs_scenario4, axis = 1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT2_probs = pd.concat([probs_scenario1, probs_scenario2, probs_scenario3, probs_scenario4], axis = 0)\n",
    "PT2_probs.to_csv(\"Output/PT2_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Temp</th>\n",
       "      <th>p(A)</th>\n",
       "      <th>p(B)</th>\n",
       "      <th>p(C)</th>\n",
       "      <th>Obs.</th>\n",
       "      <th>Model</th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1_1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>62.00%</td>\n",
       "      <td>36.00%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.00%</td>\n",
       "      <td>44.00%</td>\n",
       "      <td>7.00%</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1_1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45.00%</td>\n",
       "      <td>32.00%</td>\n",
       "      <td>23.00%</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1_2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>56.00%</td>\n",
       "      <td>42.00%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1_2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.00%</td>\n",
       "      <td>48.00%</td>\n",
       "      <td>6.00%</td>\n",
       "      <td>100</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4_2_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4_2_5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4_2_6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4_2_6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4_2_6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment Temp    p(A)    p(B)     p(C) Obs.               Model Scenario  \\\n",
       "0       1_1_1  0.5  62.00%  36.00%    2.00%  100       gpt-3.5-turbo        1   \n",
       "1       1_1_1  1.0  49.00%  44.00%    7.00%  100       gpt-3.5-turbo        1   \n",
       "2       1_1_1  1.5  45.00%  32.00%   23.00%  100       gpt-3.5-turbo        1   \n",
       "0       1_1_2  0.5  56.00%  42.00%    2.00%  100       gpt-3.5-turbo        1   \n",
       "1       1_1_2  1.0  46.00%  48.00%    6.00%  100       gpt-3.5-turbo        1   \n",
       "..        ...  ...     ...     ...      ...  ...                 ...      ...   \n",
       "1       4_2_5  1.0   0.00%   0.00%  100.00%   50  gpt-4-1106-preview        4   \n",
       "2       4_2_5  1.5   0.00%   0.00%  100.00%   50  gpt-4-1106-preview        4   \n",
       "0       4_2_6  0.5   0.00%   0.00%  100.00%   50  gpt-4-1106-preview        4   \n",
       "1       4_2_6  1.0   0.00%   0.00%  100.00%   50  gpt-4-1106-preview        4   \n",
       "2       4_2_6  1.5   0.00%   0.00%  100.00%   50  gpt-4-1106-preview        4   \n",
       "\n",
       "   Configuration  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "0              2  \n",
       "1              2  \n",
       "..           ...  \n",
       "1              5  \n",
       "2              5  \n",
       "0              6  \n",
       "1              6  \n",
       "2              6  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT2_probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
